{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc; gc.enable()\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from GridSearcher import data_loader, model_loader, fit_params, get_oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_mean_enc_lgb_oof_test_pred.csv',\n",
       " 'all_mean_enc_lgb_oof_val_pred.csv',\n",
       " 'all_mean_enc_user_feat2_lgb_oof_test_pred.csv',\n",
       " 'all_mean_enc_user_feat2_lgb_oof_val_pred.csv',\n",
       " 'all_mean_enc_user_feat_lgb_oof_test_pred.csv',\n",
       " 'all_mean_enc_user_feat_lgb_oof_val_pred.csv',\n",
       " 'alpha_0001_oof_test_pred.csv',\n",
       " 'alpha_0001_oof_val_pred.csv',\n",
       " 'alpha_10_oof_test_pred.csv',\n",
       " 'alpha_10_oof_val_pred.csv',\n",
       " 'alpha_160_oof_test_pred.csv',\n",
       " 'alpha_160_oof_val_pred.csv',\n",
       " 'alpha_320_oof_test_pred.csv',\n",
       " 'alpha_320_oof_val_pred.csv',\n",
       " 'baseline_xgb_oof_test_pred.csv',\n",
       " 'baseline_xgb_oof_val_pred.csv',\n",
       " 'catboost1_without_text_oof_test_pred',\n",
       " 'catboost1_without_text_oof_test_pred.csv',\n",
       " 'catboost1_without_text_oof_val_pred',\n",
       " 'catboost1_without_text_oof_val_pred.csv',\n",
       " 'catboost_oof_test_pred.csv',\n",
       " 'catboost_oof_val_pred.csv',\n",
       " 'cat_interact_lgb_oof_test_pred.csv',\n",
       " 'cat_interact_lgb_oof_val_pred.csv',\n",
       " 'cgb_with_categorical_oof_test_pred.csv',\n",
       " 'cgb_with_categorical_oof_val_pred.csv',\n",
       " 'cls05_lgb_oof_test_pred.csv',\n",
       " 'cls05_lgb_oof_val_pred.csv',\n",
       " 'cls0_lgb_oof_test_pred.csv',\n",
       " 'cls0_lgb_oof_val_pred.csv',\n",
       " 'drive-download-20180616T163303Z-001.zip',\n",
       " 'fused_text_lgb_oof_test_pred.csv',\n",
       " 'fused_text_lgb_oof_val_pred.csv',\n",
       " 'img_meta_nima_fm_lgb_oof_test_pred.csv',\n",
       " 'img_meta_nima_fm_lgb_oof_val_pred.csv',\n",
       " 'img_meta_nima_xgb_oof_test_pred.csv',\n",
       " 'img_meta_nima_xgb_oof_val_pred.csv',\n",
       " 'img_meta_xgb_oof_test_pred.csv',\n",
       " 'img_meta_xgb_oof_val_pred.csv',\n",
       " 'lgb411_dart_tune_oof_test_pred.csv',\n",
       " 'lgb411_dart_tune_oof_val_pred.csv',\n",
       " 'lgb411_goss_tune2_oof_test_pred.csv',\n",
       " 'lgb411_goss_tune2_oof_val_pred.csv',\n",
       " 'lgb411_goss_tune_oof_test_pred.csv',\n",
       " 'lgb411_goss_tune_oof_val_pred.csv',\n",
       " 'lgb411_tune_oof_test_pred.csv',\n",
       " 'lgb411_tune_oof_val_pred.csv',\n",
       " 'lr_l1_05_oof_test_pred.csv',\n",
       " 'lr_l1_05_oof_val_pred.csv',\n",
       " 'lr_l1_1_oof_test_pred.csv',\n",
       " 'lr_l1_1_oof_val_pred.csv',\n",
       " 'lr_l2_01_oof_test_pred.csv',\n",
       " 'lr_l2_01_oof_val_pred.csv',\n",
       " 'lr_l2_1_oof_test_pred.csv',\n",
       " 'lr_l2_1_oof_val_pred.csv',\n",
       " 'marcus_lgb_oof_test_pred.csv',\n",
       " 'marcus_lgb_oof_val_pred.csv',\n",
       " 'mcl_cgb_oof_test_pred.csv',\n",
       " 'mcl_cgb_oof_val_pred.csv',\n",
       " 'mean_enc_lgb_oof_test_pred.csv',\n",
       " 'mean_enc_lgb_oof_val_pred.csv',\n",
       " 'mixed_features_text_proprocessing_lgb_oof_test_pred.csv',\n",
       " 'mixed_features_text_proprocessing_lgb_oof_val_pred.csv',\n",
       " 'mlp_oof_test_pred.csv',\n",
       " 'mlp_oof_val_pred.csv',\n",
       " 'multiclass3_lgb_oof_test_pred.csv',\n",
       " 'multiclass3_lgb_oof_val_pred.csv',\n",
       " 'multiclass_lgb_oof_test_pred.csv',\n",
       " 'multiclass_lgb_oof_val_pred.csv',\n",
       " 'nima_features_xgb_oof_test_pred.csv',\n",
       " 'nima_features_xgb_oof_val_pred.csv',\n",
       " 'plants_lgb_oof_test_pred.csv',\n",
       " 'plants_lgb_oof_val_pred.csv',\n",
       " 'plants_with_img_meta_nima_fm_geo_active_lgb_oof_test_pred.csv',\n",
       " 'plants_with_img_meta_nima_fm_geo_active_lgb_oof_val_pred.csv',\n",
       " 'plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb_oof_test_pred.csv',\n",
       " 'plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb_oof_val_pred.csv',\n",
       " 'poisson_lgb_oof_test_pred.csv',\n",
       " 'poisson_lgb_oof_val_pred.csv',\n",
       " 'poisson_small_lr_lgb_oof_test_pred.csv',\n",
       " 'poisson_small_lr_lgb_oof_val_pred.csv',\n",
       " 'pretrained_2gru_rnn_oof_test_pred.csv',\n",
       " 'pretrained_2gru_rnn_oof_val_pred.csv',\n",
       " 'pretrained_bigru_attention_rnn_oof_test_pred.csv',\n",
       " 'pretrained_bigru_attention_rnn_oof_val_pred.csv',\n",
       " 'pretrained_bigru_cv1d_rnn_oof_test_pred.csv',\n",
       " 'pretrained_bigru_cv1d_rnn_oof_val_pred.csv',\n",
       " 'ranking_xgb_oof_test_pred.csv',\n",
       " 'ranking_xgb_oof_val_pred.csv',\n",
       " 'rf_411_7000_leaves_oof_test_pred.csv',\n",
       " 'rf_411_7000_leaves_oof_val_pred.csv',\n",
       " 'rf_oof_test_pred.csv',\n",
       " 'rf_oof_val_pred.csv',\n",
       " 'ridge_new_411_oof_test_pred.csv',\n",
       " 'ridge_new_411_oof_val_pred.csv',\n",
       " 'select_dense_features_lgb_oof_test_pred.csv',\n",
       " 'select_dense_features_lgb_oof_val_pred.csv',\n",
       " 'select_sparse_features_lgb_oof_test_pred.csv',\n",
       " 'select_sparse_features_lgb_oof_val_pred.csv',\n",
       " 'selftrained_bigru_conv1d_merged_with_image_adv_rnn_oof_test_pred.csv',\n",
       " 'selftrained_bigru_conv1d_merged_with_image_adv_rnn_oof_val_pred.csv',\n",
       " 'selftrained_bigru_conv1d_merged_with_image_rnn_oof_test_pred.csv',\n",
       " 'selftrained_bigru_conv1d_merged_with_image_rnn_oof_val_pred.csv',\n",
       " 'selftrained_bigru_conv1d_rnn_oof_test_pred.csv',\n",
       " 'selftrained_bigru_conv1d_rnn_oof_val_pred.csv',\n",
       " 'simple_feature_lgb_oof_test_pred.csv',\n",
       " 'simple_feature_lgb_oof_val_pred.csv',\n",
       " 'small_features_v4_xgb_oof_test_pred.csv',\n",
       " 'small_features_v4_xgb_oof_val_pred.csv',\n",
       " 'small_features_v5_xgb_oof_test_pred.csv',\n",
       " 'small_features_v5_xgb_oof_val_pred.csv',\n",
       " 'text_cwb_rg_oof_test_pred.csv',\n",
       " 'text_cwb_rg_oof_val_pred.csv',\n",
       " 'text_fm_oof_test_pred.csv',\n",
       " 'text_fm_oof_val_pred.csv',\n",
       " 'text_lgb_oof_test_pred.csv',\n",
       " 'text_lgb_oof_val_pred.csv',\n",
       " 'text_rg_oof_test_pred.csv',\n",
       " 'text_rg_oof_val_pred.csv',\n",
       " 'xentropy_add_lotsof_image_features_lgb_oof_test_pred.csv',\n",
       " 'xentropy_add_lotsof_image_features_lgb_oof_val_pred.csv',\n",
       " 'xentropy_small_lr_cat_lgb_oof_test_pred.csv',\n",
       " 'xentropy_small_lr_cat_lgb_oof_val_pred.csv',\n",
       " 'xentropy_small_lr_lgb_oof_test_pred.csv',\n",
       " 'xentropy_small_lr_lgb_oof_val_pred.csv',\n",
       " 'xgb_new_oof_test_pred.csv',\n",
       " 'xgb_new_oof_val_pred.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'final oofs/'\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_interact_statics = [\n",
    "    'xentropy_add_lotsof_image_features_lgb',\n",
    "    'lgb411_tune',\n",
    "    'plants_lgb',\n",
    "    'plants_with_img_meta_nima_fm_geo_active_lgb',\n",
    "    'simple_feature_lgb',\n",
    "    'cat_interact_lgb',\n",
    "    'mixed_features_text_proprocessing_lgb',\n",
    "    'marcus_lgb',\n",
    "    'lgb411_dart_tune',\n",
    "    'poisson_small_lr_lgb',\n",
    "    'img_meta_xgb',\n",
    "    'baseline_xgb',\n",
    "    'catboost1_without_text',\n",
    "    'cgb_with_categorical',\n",
    "    'mcl_cgb',\n",
    "    'selftrained_bigru_conv1d_rnn',\n",
    "    'pretrained_bigru_cv1d_rnn',\n",
    "    'selftrained_bigru_conv1d_merged_with_image_adv_rnn',\n",
    "    'text_lgb',\n",
    "    'text_rg',\n",
    "    'mlp',\n",
    "    'alpha_0001',\n",
    "    'ridge_new_411',\n",
    "    'rf_411_7000_leaves'\n",
    "]\n",
    "\n",
    "tri_interact_statics = [\n",
    "    'xentropy_add_lotsof_image_features_lgb',\n",
    "    'lgb411_tune',\n",
    "    'simple_feature_lgb',\n",
    "    'lgb411_dart_tune',\n",
    "    'poisson_small_lr_lgb',\n",
    "    'img_meta_xgb',\n",
    "    'baseline_xgb',\n",
    "    'catboost1_without_text',\n",
    "    'selftrained_bigru_conv1d_rnn',\n",
    "    'selftrained_bigru_conv1d_merged_with_image_adv_rnn',\n",
    "    'text_lgb',\n",
    "    'text_rg',\n",
    "    'mlp',\n",
    "    'alpha_0001',\n",
    "    'ridge_new_411',\n",
    "    'rf_411_7000_leaves'\n",
    "]\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        'name': 'lgb',\n",
    "        'prefixs': [\n",
    "            'xentropy_add_lotsof_image_features_lgb',\n",
    "            'lgb411_tune',\n",
    "            'plants_lgb', #411\n",
    "            'plants_with_img_meta_nima_fm_geo_active_lgb',\n",
    "            'plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb',\n",
    "            #'xentropy_small_lr_lgb', #lgb411_tune\n",
    "            'xentropy_small_lr_cat_lgb',\n",
    "            'simple_feature_lgb', #411\n",
    "            'all_mean_enc_lgb', #411\n",
    "            'all_mean_enc_user_feat_lgb', #411\n",
    "            'all_mean_enc_user_feat2_lgb', #411\n",
    "            'cat_interact_lgb', #411\n",
    "            'mean_enc_lgb', #411\n",
    "            'marcus_lgb', #o411\n",
    "            'fused_text_lgb', #o411\n",
    "            'mixed_features_text_proprocessing_lgb', #o411,\n",
    "            'select_dense_features_lgb', #411\n",
    "            'select_sparse_features_lgb', #411\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'lgb_dart',\n",
    "        'prefixs': [\n",
    "            'lgb411_dart_tune',\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'lgb_goss',\n",
    "        'prefixs': [\n",
    "            'lgb411_goss_tune',\n",
    "            'lgb411_goss_tune2',\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'lgb_pois',\n",
    "        'prefixs': [\n",
    "            'poisson_lgb', #o411\n",
    "            'poisson_small_lr_lgb',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'xgb_lg',\n",
    "        'prefixs': [\n",
    "            'small_features_v5_xgb', #o411\n",
    "            'small_features_v4_xgb', #o411\n",
    "            'nima_features_xgb', #o411\n",
    "            'img_meta_xgb', #o411\n",
    "            'img_meta_nima_xgb', #o411\n",
    "            'xgb_new',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'xgb_dw',\n",
    "        'prefixs': [\n",
    "            'baseline_xgb', #o411\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'xgb_ranking',\n",
    "        'prefixs': [\n",
    "            'ranking_xgb', #o411\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'catboost',\n",
    "        'prefixs': [\n",
    "            'catboost', #411\n",
    "            'catboost1_without_text',\n",
    "            'mcl_cgb',\n",
    "            'cgb_with_categorical',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'rnn',\n",
    "        'prefixs': [\n",
    "            'pretrained_bigru_cv1d_rnn', #411\n",
    "            'pretrained_bigru_attention_rnn', #411\n",
    "            'pretrained_2gru_rnn', #411\n",
    "            'selftrained_bigru_conv1d_rnn', #411\n",
    "            'selftrained_bigru_conv1d_merged_with_image_rnn',\n",
    "            'selftrained_bigru_conv1d_merged_with_image_adv_rnn',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'text',\n",
    "        'prefixs': [\n",
    "            'text_lgb',#411\n",
    "            'text_cwb_rg',#411\n",
    "            'text_fm', #411\n",
    "            'text_rg', #411\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'mlp',\n",
    "        'prefixs': [\n",
    "            'mlp',#411\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'random_forest',\n",
    "        'prefixs': [\n",
    "            'rf',#411\n",
    "            'rf_411_7000_leaves',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'ridge',\n",
    "        'prefixs': [\n",
    "            'alpha_0001',#411\n",
    "            'alpha_160',#411\n",
    "            'alpha_10',#411\n",
    "            'alpha_320',#411\n",
    "            'ridge_new_411',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'logistic_regression',\n",
    "        'prefixs': [\n",
    "            'lr_l1_05',#411\n",
    "            'lr_l1_1',#411\n",
    "            'lr_l2_01',#411\n",
    "            'lr_l2_1',#411\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'lgb_cls05',\n",
    "        'prefixs': [\n",
    "            'cls05_lgb',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'lgb_cls0',\n",
    "        'prefixs': [\n",
    "            'cls0_lgb',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'multiclass',\n",
    "        'prefixs': [\n",
    "            'multiclass_lgb',\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'multiclass3',\n",
    "        'prefixs': [\n",
    "            'multiclass3_lgb',\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group:  lgb\n",
      "Add  xentropy_add_lotsof_image_features_lgb\n",
      "Add  lgb411_tune\n",
      "Add  plants_lgb\n",
      "Add  plants_with_img_meta_nima_fm_geo_active_lgb\n",
      "Add  plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb\n",
      "Add  xentropy_small_lr_cat_lgb\n",
      "Add  simple_feature_lgb\n",
      "Add  all_mean_enc_lgb\n",
      "Add  all_mean_enc_user_feat_lgb\n",
      "Add  all_mean_enc_user_feat2_lgb\n",
      "Add  cat_interact_lgb\n",
      "Add  mean_enc_lgb\n",
      "Add  marcus_lgb\n",
      "Add  fused_text_lgb\n",
      "Add  mixed_features_text_proprocessing_lgb\n",
      "Add  select_dense_features_lgb\n",
      "Add  select_sparse_features_lgb\n",
      "Processing group:  lgb_dart\n",
      "Add  lgb411_dart_tune\n",
      "Processing group:  lgb_goss\n",
      "Add  lgb411_goss_tune\n",
      "Add  lgb411_goss_tune2\n",
      "Processing group:  lgb_pois\n",
      "Add  poisson_lgb\n",
      "Add  poisson_small_lr_lgb\n",
      "Processing group:  xgb_lg\n",
      "Add  small_features_v5_xgb\n",
      "Add  small_features_v4_xgb\n",
      "Add  nima_features_xgb\n",
      "Add  img_meta_xgb\n",
      "Add  img_meta_nima_xgb\n",
      "Add  xgb_new\n",
      "Processing group:  xgb_dw\n",
      "Add  baseline_xgb\n",
      "Processing group:  xgb_ranking\n",
      "Add  ranking_xgb\n",
      "Processing group:  catboost\n",
      "Add  catboost\n",
      "Add  catboost1_without_text\n",
      "Add  mcl_cgb\n",
      "Add  cgb_with_categorical\n",
      "Processing group:  rnn\n",
      "Add  pretrained_bigru_cv1d_rnn\n",
      "Add  pretrained_bigru_attention_rnn\n",
      "Add  pretrained_2gru_rnn\n",
      "Add  selftrained_bigru_conv1d_rnn\n",
      "Add  selftrained_bigru_conv1d_merged_with_image_rnn\n",
      "Add  selftrained_bigru_conv1d_merged_with_image_adv_rnn\n",
      "Processing group:  text\n",
      "Add  text_lgb\n",
      "Add  text_cwb_rg\n",
      "Add  text_fm\n",
      "Add  text_rg\n",
      "Processing group:  mlp\n",
      "Add  mlp\n",
      "Processing group:  random_forest\n",
      "Add  rf\n",
      "Add  rf_411_7000_leaves\n",
      "Processing group:  ridge\n",
      "Add  alpha_0001\n",
      "Add  alpha_160\n",
      "Add  alpha_10\n",
      "Add  alpha_320\n",
      "Add  ridge_new_411\n",
      "Processing group:  logistic_regression\n",
      "Add  lr_l1_05\n",
      "Add  lr_l1_1\n",
      "Add  lr_l2_01\n",
      "Add  lr_l2_1\n",
      "Processing group:  lgb_cls05\n",
      "Add  cls05_lgb\n",
      "Processing group:  lgb_cls0\n",
      "Add  cls0_lgb\n",
      "Processing group:  multiclass\n",
      "Add  multiclass_lgbmulticlass_lgb_pred0\n",
      "Add  multiclass_lgbmulticlass_lgb_pred1\n",
      "Add  multiclass_lgbmulticlass_lgb_pred2\n",
      "Add  multiclass_lgbmulticlass_lgb_pred3\n",
      "Add  multiclass_lgbmulticlass_lgb_pred4\n",
      "Add  multiclass_lgbmulticlass_lgb_pred5\n",
      "Add  multiclass_lgbmulticlass_lgb_pred6\n",
      "Add  multiclass_lgbmulticlass_lgb_pred7\n",
      "Add  multiclass_lgbmulticlass_lgb_pred8\n",
      "Add  multiclass_lgbmulticlass_lgbrank\n",
      "Processing group:  multiclass3\n",
      "Add  multiclass3_lgbmulticlass3_lgb_pred0\n",
      "Add  multiclass3_lgbmulticlass3_lgb_pred1\n",
      "Add  multiclass3_lgbmulticlass3_lgb_pred2\n",
      "Add  multiclass3_lgbmulticlass3_lgbrank\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def get_clipped_values(a):\n",
    "    return np.clip(a, 1e-15, 1.)\n",
    "\n",
    "basic_columns = []\n",
    "for config in configs:\n",
    "    columns = []\n",
    "    print('Processing group: ', config['name'])\n",
    "    for prefix in config['prefixs']:\n",
    "        train_f = folder + prefix + '_oof_val_pred.csv'\n",
    "        test_f = folder + prefix + '_oof_test_pred.csv'\n",
    "        \n",
    "        train_df = pd.read_csv(train_f)\n",
    "        test_df = pd.read_csv(test_f)\n",
    "        \n",
    "        if config['name'] == 'multiclass' or config['name'] == 'multiclass3':\n",
    "            original_cols = train_df.columns.tolist()\n",
    "            \n",
    "            for c in original_cols:\n",
    "                col = prefix+c\n",
    "                print('Add ', col)\n",
    "                \n",
    "                train.loc[:,col] = train_df[c]\n",
    "                test.loc[:,col] = test_df[c]\n",
    "        else:\n",
    "            original_col = train_df.columns.tolist()[0]\n",
    "            col = prefix\n",
    "            print('Add ', col)\n",
    "            columns.append(col)\n",
    "            basic_columns.append(col)\n",
    "            \n",
    "            train.loc[:,col] = train_df[original_col]\n",
    "            test.loc[:,col] = test_df[original_col]\n",
    "        \n",
    "        del train_df, test_df; gc.collect()\n",
    "    \n",
    "    # apply feature engineering on intra-group columns\n",
    "    if len(columns) < 2:\n",
    "        continue\n",
    "\n",
    "    for df in [train, test]:    \n",
    "        # within sample group\n",
    "        df.loc[:, config['name']+'_mean'] = df[columns].mean(axis=1)\n",
    "        df.loc[:, config['name']+'_med'] = df[columns].median(axis=1)\n",
    "        df.loc[:, config['name']+'_max'] = df[columns].max(axis=1)\n",
    "        df.loc[:, config['name']+'_min'] = df[columns].min(axis=1)\n",
    "        df.loc[:, config['name']+'_std'] = df[columns].std(axis=1)\n",
    "\n",
    "\n",
    "# apply feature engineering on inter_group columns\n",
    "for df in [train, test]:    \n",
    "    df.loc[:, 'bi_inter_group_mean']  = df[bi_interact_statics].mean(axis=1)\n",
    "    df.loc[:, 'bi_inter_group_med']   = df[bi_interact_statics].median(axis=1)\n",
    "    df.loc[:, 'bi_inter_group_max']   = df[bi_interact_statics].max(axis=1)\n",
    "    df.loc[:, 'bi_inter_group_min']   = df[bi_interact_statics].min(axis=1)\n",
    "    df.loc[:, 'bi_inter_group_std']   = df[bi_interact_statics].std(axis=1)\n",
    "    df.loc[:, 'tri_inter_group_mean'] = df[tri_interact_statics].mean(axis=1)\n",
    "    df.loc[:, 'tri_inter_group_med']  = df[tri_interact_statics].median(axis=1)\n",
    "    df.loc[:, 'tri_inter_group_max']  = df[tri_interact_statics].max(axis=1)\n",
    "    df.loc[:, 'tri_inter_group_min']  = df[tri_interact_statics].min(axis=1)\n",
    "    df.loc[:, 'tri_inter_group_std']  = df[tri_interact_statics].std(axis=1)\n",
    "    \n",
    "    '''\n",
    "    col_len = len(bi_interact_statics)\n",
    "    for i in range(col_len-1):\n",
    "        for j in range(i+1, col_len):\n",
    "            cols = [bi_interact_statics[i], bi_interact_statics[j]]\n",
    "            feat_name = cols[0]+'_'+cols[1]+'_inter'\n",
    "            print('Add ', feat_name, ' statistcs')        \n",
    "            df.loc[:, feat_name+'_mean'] = df[cols].mean(axis=1)\n",
    "            df.loc[:, feat_name+'_gmean'] = gmean(get_clipped_values(df[cols].values), axis=1)\n",
    "            #df.loc[:, feat_name+'_hmean'] = hmean(get_clipped_values(df[cols].values), axis=1)\n",
    "    \n",
    "    \n",
    "    col_len = len(tri_interact_statics)\n",
    "    for i in range(col_len-2):\n",
    "        for j in range(i+1, col_len-1):\n",
    "            for k in range(j+1, col_len):\n",
    "                cols = [tri_interact_statics[i], tri_interact_statics[j], tri_interact_statics[k]]\n",
    "                feat_name = cols[0]+'_'+cols[1]+'_'+cols[2]+'_inter'  \n",
    "                print('Add ', feat_name, ' statistcs')                    \n",
    "                df.loc[:, feat_name+'_mean'] = df[cols].mean(axis=1)\n",
    "                df.loc[:, feat_name+'_gmean'] = gmean(get_clipped_values(df[cols].values), axis=1)\n",
    "                #df.loc[:, feat_name+'_hmean'] = hmean(get_clipped_values(df[cols].values), axis=1)\n",
    "                df.loc[:, feat_name+'_med'] = df[cols].median(axis=1)\n",
    "                df.loc[:, feat_name+'_std'] = df[cols].std(axis=1)             \n",
    "    '''            \n",
    "    #df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xentropy_add_lotsof_image_features_lgb</th>\n",
       "      <th>lgb411_tune</th>\n",
       "      <th>plants_lgb</th>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_lgb</th>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb</th>\n",
       "      <th>xentropy_small_lr_cat_lgb</th>\n",
       "      <th>simple_feature_lgb</th>\n",
       "      <th>all_mean_enc_lgb</th>\n",
       "      <th>all_mean_enc_user_feat_lgb</th>\n",
       "      <th>all_mean_enc_user_feat2_lgb</th>\n",
       "      <th>...</th>\n",
       "      <th>bi_inter_group_mean</th>\n",
       "      <th>bi_inter_group_med</th>\n",
       "      <th>bi_inter_group_max</th>\n",
       "      <th>bi_inter_group_min</th>\n",
       "      <th>bi_inter_group_std</th>\n",
       "      <th>tri_inter_group_mean</th>\n",
       "      <th>tri_inter_group_med</th>\n",
       "      <th>tri_inter_group_max</th>\n",
       "      <th>tri_inter_group_min</th>\n",
       "      <th>tri_inter_group_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.062362</td>\n",
       "      <td>0.053896</td>\n",
       "      <td>0.071850</td>\n",
       "      <td>0.059415</td>\n",
       "      <td>0.047786</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>0.054969</td>\n",
       "      <td>0.052336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.080676</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>0.046161</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.080676</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.021428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039158</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.057651</td>\n",
       "      <td>0.057721</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.062043</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033417</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.047206</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>-0.047206</td>\n",
       "      <td>0.024273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047349</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.040794</td>\n",
       "      <td>0.048324</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.036656</td>\n",
       "      <td>0.034745</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.061303</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.038380</td>\n",
       "      <td>0.036989</td>\n",
       "      <td>0.056999</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.009321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   xentropy_add_lotsof_image_features_lgb  lgb411_tune  plants_lgb  \\\n",
       "0                                0.075277     0.062362    0.053896   \n",
       "1                                0.039158     0.041640    0.057651   \n",
       "2                                0.047349     0.031383    0.040794   \n",
       "\n",
       "   plants_with_img_meta_nima_fm_geo_active_lgb  \\\n",
       "0                                     0.071850   \n",
       "1                                     0.057721   \n",
       "2                                     0.048324   \n",
       "\n",
       "   plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb  \\\n",
       "0                                           0.059415          \n",
       "1                                           0.033101          \n",
       "2                                           0.039097          \n",
       "\n",
       "   xentropy_small_lr_cat_lgb  simple_feature_lgb  all_mean_enc_lgb  \\\n",
       "0                   0.047786            0.068429          0.054375   \n",
       "1                   0.062043            0.040434          0.015163   \n",
       "2                   0.052663            0.036796          0.036656   \n",
       "\n",
       "   all_mean_enc_user_feat_lgb  all_mean_enc_user_feat2_lgb  \\\n",
       "0                    0.054969                     0.052336   \n",
       "1                    0.015783                     0.017107   \n",
       "2                    0.034745                     0.035856   \n",
       "\n",
       "          ...           bi_inter_group_mean  bi_inter_group_med  \\\n",
       "0         ...                      0.051283            0.052869   \n",
       "1         ...                      0.033417            0.035638   \n",
       "2         ...                      0.039608            0.038222   \n",
       "\n",
       "   bi_inter_group_max  bi_inter_group_min  bi_inter_group_std  \\\n",
       "0            0.080676            0.004070            0.020358   \n",
       "1            0.061023           -0.047206            0.022739   \n",
       "2            0.061303            0.019574            0.009547   \n",
       "\n",
       "   tri_inter_group_mean  tri_inter_group_med  tri_inter_group_max  \\\n",
       "0              0.046161             0.042857             0.080676   \n",
       "1              0.029550             0.035638             0.061023   \n",
       "2              0.038380             0.036989             0.056999   \n",
       "\n",
       "   tri_inter_group_min  tri_inter_group_std  \n",
       "0             0.004070             0.021428  \n",
       "1            -0.047206             0.024273  \n",
       "2             0.019574             0.009321  \n",
       "\n",
       "[3 rows x 132 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xentropy_add_lotsof_image_features_lgb</th>\n",
       "      <th>lgb411_tune</th>\n",
       "      <th>plants_lgb</th>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_lgb</th>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb</th>\n",
       "      <th>xentropy_small_lr_cat_lgb</th>\n",
       "      <th>simple_feature_lgb</th>\n",
       "      <th>all_mean_enc_lgb</th>\n",
       "      <th>all_mean_enc_user_feat_lgb</th>\n",
       "      <th>all_mean_enc_user_feat2_lgb</th>\n",
       "      <th>cat_interact_lgb</th>\n",
       "      <th>mean_enc_lgb</th>\n",
       "      <th>marcus_lgb</th>\n",
       "      <th>fused_text_lgb</th>\n",
       "      <th>mixed_features_text_proprocessing_lgb</th>\n",
       "      <th>select_dense_features_lgb</th>\n",
       "      <th>select_sparse_features_lgb</th>\n",
       "      <th>lgb411_dart_tune</th>\n",
       "      <th>lgb411_goss_tune</th>\n",
       "      <th>lgb411_goss_tune2</th>\n",
       "      <th>poisson_lgb</th>\n",
       "      <th>poisson_small_lr_lgb</th>\n",
       "      <th>small_features_v5_xgb</th>\n",
       "      <th>small_features_v4_xgb</th>\n",
       "      <th>nima_features_xgb</th>\n",
       "      <th>img_meta_xgb</th>\n",
       "      <th>img_meta_nima_xgb</th>\n",
       "      <th>xgb_new</th>\n",
       "      <th>baseline_xgb</th>\n",
       "      <th>ranking_xgb</th>\n",
       "      <th>catboost</th>\n",
       "      <th>catboost1_without_text</th>\n",
       "      <th>mcl_cgb</th>\n",
       "      <th>cgb_with_categorical</th>\n",
       "      <th>pretrained_bigru_cv1d_rnn</th>\n",
       "      <th>pretrained_bigru_attention_rnn</th>\n",
       "      <th>pretrained_2gru_rnn</th>\n",
       "      <th>selftrained_bigru_conv1d_rnn</th>\n",
       "      <th>selftrained_bigru_conv1d_merged_with_image_rnn</th>\n",
       "      <th>selftrained_bigru_conv1d_merged_with_image_adv_rnn</th>\n",
       "      <th>text_lgb</th>\n",
       "      <th>text_cwb_rg</th>\n",
       "      <th>text_fm</th>\n",
       "      <th>text_rg</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>rf_411_7000_leaves</th>\n",
       "      <th>alpha_0001</th>\n",
       "      <th>alpha_160</th>\n",
       "      <th>alpha_10</th>\n",
       "      <th>alpha_320</th>\n",
       "      <th>ridge_new_411</th>\n",
       "      <th>lr_l1_05</th>\n",
       "      <th>lr_l1_1</th>\n",
       "      <th>lr_l2_01</th>\n",
       "      <th>lr_l2_1</th>\n",
       "      <th>cls05_lgb</th>\n",
       "      <th>cls0_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xentropy_add_lotsof_image_features_lgb</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987515</td>\n",
       "      <td>0.962282</td>\n",
       "      <td>0.971707</td>\n",
       "      <td>0.979859</td>\n",
       "      <td>0.963546</td>\n",
       "      <td>0.902607</td>\n",
       "      <td>0.904278</td>\n",
       "      <td>0.904221</td>\n",
       "      <td>0.896114</td>\n",
       "      <td>0.898852</td>\n",
       "      <td>0.903478</td>\n",
       "      <td>0.915897</td>\n",
       "      <td>0.912013</td>\n",
       "      <td>0.913005</td>\n",
       "      <td>0.902741</td>\n",
       "      <td>0.908337</td>\n",
       "      <td>0.976410</td>\n",
       "      <td>0.986276</td>\n",
       "      <td>0.988411</td>\n",
       "      <td>0.979855</td>\n",
       "      <td>0.983149</td>\n",
       "      <td>0.926844</td>\n",
       "      <td>0.922592</td>\n",
       "      <td>0.931074</td>\n",
       "      <td>0.936005</td>\n",
       "      <td>0.938847</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.971096</td>\n",
       "      <td>0.765870</td>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.972385</td>\n",
       "      <td>0.970223</td>\n",
       "      <td>0.892459</td>\n",
       "      <td>0.891782</td>\n",
       "      <td>0.889217</td>\n",
       "      <td>0.891598</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.915566</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.685411</td>\n",
       "      <td>0.821406</td>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.921385</td>\n",
       "      <td>0.935732</td>\n",
       "      <td>0.811904</td>\n",
       "      <td>0.846438</td>\n",
       "      <td>0.827642</td>\n",
       "      <td>0.850100</td>\n",
       "      <td>0.872428</td>\n",
       "      <td>0.811401</td>\n",
       "      <td>0.799280</td>\n",
       "      <td>0.821263</td>\n",
       "      <td>0.793754</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.785823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb411_tune</th>\n",
       "      <td>0.987515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967159</td>\n",
       "      <td>0.976990</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>0.905456</td>\n",
       "      <td>0.907395</td>\n",
       "      <td>0.907480</td>\n",
       "      <td>0.899326</td>\n",
       "      <td>0.902366</td>\n",
       "      <td>0.906453</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.914794</td>\n",
       "      <td>0.915861</td>\n",
       "      <td>0.906655</td>\n",
       "      <td>0.912361</td>\n",
       "      <td>0.982080</td>\n",
       "      <td>0.994217</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.985545</td>\n",
       "      <td>0.988986</td>\n",
       "      <td>0.931473</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.935678</td>\n",
       "      <td>0.940697</td>\n",
       "      <td>0.943550</td>\n",
       "      <td>0.987608</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.769518</td>\n",
       "      <td>0.896485</td>\n",
       "      <td>0.896485</td>\n",
       "      <td>0.976032</td>\n",
       "      <td>0.974701</td>\n",
       "      <td>0.895204</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.891942</td>\n",
       "      <td>0.894094</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.912031</td>\n",
       "      <td>0.823135</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.821971</td>\n",
       "      <td>0.823708</td>\n",
       "      <td>0.866779</td>\n",
       "      <td>0.922428</td>\n",
       "      <td>0.937665</td>\n",
       "      <td>0.813002</td>\n",
       "      <td>0.847543</td>\n",
       "      <td>0.828779</td>\n",
       "      <td>0.851161</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.800982</td>\n",
       "      <td>0.822777</td>\n",
       "      <td>0.795435</td>\n",
       "      <td>0.945198</td>\n",
       "      <td>0.788349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants_lgb</th>\n",
       "      <td>0.962282</td>\n",
       "      <td>0.967159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968862</td>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.951730</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>0.912456</td>\n",
       "      <td>0.912490</td>\n",
       "      <td>0.904745</td>\n",
       "      <td>0.907654</td>\n",
       "      <td>0.912110</td>\n",
       "      <td>0.914469</td>\n",
       "      <td>0.921208</td>\n",
       "      <td>0.921965</td>\n",
       "      <td>0.896150</td>\n",
       "      <td>0.902178</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.967875</td>\n",
       "      <td>0.963319</td>\n",
       "      <td>0.966409</td>\n",
       "      <td>0.931010</td>\n",
       "      <td>0.926905</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.925493</td>\n",
       "      <td>0.924579</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.955797</td>\n",
       "      <td>0.765113</td>\n",
       "      <td>0.890247</td>\n",
       "      <td>0.890247</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.964663</td>\n",
       "      <td>0.897465</td>\n",
       "      <td>0.896696</td>\n",
       "      <td>0.894225</td>\n",
       "      <td>0.897245</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>0.903323</td>\n",
       "      <td>0.835321</td>\n",
       "      <td>0.695687</td>\n",
       "      <td>0.834781</td>\n",
       "      <td>0.836749</td>\n",
       "      <td>0.874204</td>\n",
       "      <td>0.931922</td>\n",
       "      <td>0.942972</td>\n",
       "      <td>0.824736</td>\n",
       "      <td>0.860072</td>\n",
       "      <td>0.840884</td>\n",
       "      <td>0.863767</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.823825</td>\n",
       "      <td>0.811323</td>\n",
       "      <td>0.833793</td>\n",
       "      <td>0.805571</td>\n",
       "      <td>0.919283</td>\n",
       "      <td>0.781393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_lgb</th>\n",
       "      <td>0.971707</td>\n",
       "      <td>0.976990</td>\n",
       "      <td>0.968862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973449</td>\n",
       "      <td>0.957623</td>\n",
       "      <td>0.904752</td>\n",
       "      <td>0.906086</td>\n",
       "      <td>0.906017</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.900886</td>\n",
       "      <td>0.905318</td>\n",
       "      <td>0.915583</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>0.972245</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.977729</td>\n",
       "      <td>0.972814</td>\n",
       "      <td>0.976023</td>\n",
       "      <td>0.924954</td>\n",
       "      <td>0.920816</td>\n",
       "      <td>0.928658</td>\n",
       "      <td>0.931048</td>\n",
       "      <td>0.933453</td>\n",
       "      <td>0.971450</td>\n",
       "      <td>0.964709</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.976016</td>\n",
       "      <td>0.972276</td>\n",
       "      <td>0.891990</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.888897</td>\n",
       "      <td>0.891522</td>\n",
       "      <td>0.891001</td>\n",
       "      <td>0.904735</td>\n",
       "      <td>0.828427</td>\n",
       "      <td>0.690939</td>\n",
       "      <td>0.827950</td>\n",
       "      <td>0.830028</td>\n",
       "      <td>0.867792</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.941243</td>\n",
       "      <td>0.818223</td>\n",
       "      <td>0.853142</td>\n",
       "      <td>0.834198</td>\n",
       "      <td>0.856787</td>\n",
       "      <td>0.879468</td>\n",
       "      <td>0.816884</td>\n",
       "      <td>0.804517</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.798866</td>\n",
       "      <td>0.931634</td>\n",
       "      <td>0.782935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb</th>\n",
       "      <td>0.979859</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.973449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.900203</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>0.901888</td>\n",
       "      <td>0.893871</td>\n",
       "      <td>0.896375</td>\n",
       "      <td>0.900974</td>\n",
       "      <td>0.912759</td>\n",
       "      <td>0.910385</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>0.899385</td>\n",
       "      <td>0.905112</td>\n",
       "      <td>0.976626</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.986809</td>\n",
       "      <td>0.982530</td>\n",
       "      <td>0.985805</td>\n",
       "      <td>0.925209</td>\n",
       "      <td>0.920967</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>0.933461</td>\n",
       "      <td>0.936151</td>\n",
       "      <td>0.979641</td>\n",
       "      <td>0.972157</td>\n",
       "      <td>0.766018</td>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.971611</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>0.890066</td>\n",
       "      <td>0.889372</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.889311</td>\n",
       "      <td>0.890608</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.821424</td>\n",
       "      <td>0.684999</td>\n",
       "      <td>0.820779</td>\n",
       "      <td>0.822768</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.935721</td>\n",
       "      <td>0.811344</td>\n",
       "      <td>0.845992</td>\n",
       "      <td>0.827171</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.811378</td>\n",
       "      <td>0.799215</td>\n",
       "      <td>0.821176</td>\n",
       "      <td>0.793686</td>\n",
       "      <td>0.940242</td>\n",
       "      <td>0.785084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xentropy_small_lr_cat_lgb</th>\n",
       "      <td>0.963546</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>0.951730</td>\n",
       "      <td>0.957623</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914189</td>\n",
       "      <td>0.917104</td>\n",
       "      <td>0.916845</td>\n",
       "      <td>0.907965</td>\n",
       "      <td>0.911571</td>\n",
       "      <td>0.916972</td>\n",
       "      <td>0.932491</td>\n",
       "      <td>0.925647</td>\n",
       "      <td>0.925489</td>\n",
       "      <td>0.919620</td>\n",
       "      <td>0.924598</td>\n",
       "      <td>0.963631</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>0.968451</td>\n",
       "      <td>0.964006</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.923585</td>\n",
       "      <td>0.919470</td>\n",
       "      <td>0.926771</td>\n",
       "      <td>0.928518</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>0.963888</td>\n",
       "      <td>0.954971</td>\n",
       "      <td>0.758656</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.961636</td>\n",
       "      <td>0.956116</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>0.900185</td>\n",
       "      <td>0.897477</td>\n",
       "      <td>0.899517</td>\n",
       "      <td>0.900388</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.827092</td>\n",
       "      <td>0.686990</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>0.829751</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>0.922925</td>\n",
       "      <td>0.934852</td>\n",
       "      <td>0.821121</td>\n",
       "      <td>0.856480</td>\n",
       "      <td>0.837466</td>\n",
       "      <td>0.859861</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>0.821350</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.830989</td>\n",
       "      <td>0.804675</td>\n",
       "      <td>0.919523</td>\n",
       "      <td>0.779242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_feature_lgb</th>\n",
       "      <td>0.902607</td>\n",
       "      <td>0.905456</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>0.904752</td>\n",
       "      <td>0.900203</td>\n",
       "      <td>0.914189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968871</td>\n",
       "      <td>0.967921</td>\n",
       "      <td>0.957815</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.971213</td>\n",
       "      <td>0.956146</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.939173</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.945776</td>\n",
       "      <td>0.908589</td>\n",
       "      <td>0.906396</td>\n",
       "      <td>0.906203</td>\n",
       "      <td>0.900190</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.922071</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.921465</td>\n",
       "      <td>0.916744</td>\n",
       "      <td>0.916079</td>\n",
       "      <td>0.902595</td>\n",
       "      <td>0.893908</td>\n",
       "      <td>0.738648</td>\n",
       "      <td>0.902593</td>\n",
       "      <td>0.902593</td>\n",
       "      <td>0.918213</td>\n",
       "      <td>0.907633</td>\n",
       "      <td>0.919504</td>\n",
       "      <td>0.918586</td>\n",
       "      <td>0.916392</td>\n",
       "      <td>0.914868</td>\n",
       "      <td>0.907114</td>\n",
       "      <td>0.898792</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.849560</td>\n",
       "      <td>0.853084</td>\n",
       "      <td>0.893489</td>\n",
       "      <td>0.904446</td>\n",
       "      <td>0.912592</td>\n",
       "      <td>0.841548</td>\n",
       "      <td>0.880072</td>\n",
       "      <td>0.858496</td>\n",
       "      <td>0.884830</td>\n",
       "      <td>0.875719</td>\n",
       "      <td>0.838050</td>\n",
       "      <td>0.822719</td>\n",
       "      <td>0.847758</td>\n",
       "      <td>0.814407</td>\n",
       "      <td>0.849272</td>\n",
       "      <td>0.754601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_enc_lgb</th>\n",
       "      <td>0.904278</td>\n",
       "      <td>0.907395</td>\n",
       "      <td>0.912456</td>\n",
       "      <td>0.906086</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>0.917104</td>\n",
       "      <td>0.968871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993119</td>\n",
       "      <td>0.979055</td>\n",
       "      <td>0.973705</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>0.939821</td>\n",
       "      <td>0.943974</td>\n",
       "      <td>0.939846</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>0.909640</td>\n",
       "      <td>0.908318</td>\n",
       "      <td>0.908056</td>\n",
       "      <td>0.901865</td>\n",
       "      <td>0.904927</td>\n",
       "      <td>0.925226</td>\n",
       "      <td>0.921064</td>\n",
       "      <td>0.924221</td>\n",
       "      <td>0.919339</td>\n",
       "      <td>0.918438</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.895836</td>\n",
       "      <td>0.737372</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.908791</td>\n",
       "      <td>0.922844</td>\n",
       "      <td>0.921886</td>\n",
       "      <td>0.919655</td>\n",
       "      <td>0.917843</td>\n",
       "      <td>0.910287</td>\n",
       "      <td>0.901655</td>\n",
       "      <td>0.866855</td>\n",
       "      <td>0.710733</td>\n",
       "      <td>0.846129</td>\n",
       "      <td>0.848887</td>\n",
       "      <td>0.896498</td>\n",
       "      <td>0.902194</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>0.846315</td>\n",
       "      <td>0.878901</td>\n",
       "      <td>0.860962</td>\n",
       "      <td>0.882902</td>\n",
       "      <td>0.872686</td>\n",
       "      <td>0.840290</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.818613</td>\n",
       "      <td>0.851784</td>\n",
       "      <td>0.752769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_enc_user_feat_lgb</th>\n",
       "      <td>0.904221</td>\n",
       "      <td>0.907480</td>\n",
       "      <td>0.912490</td>\n",
       "      <td>0.906017</td>\n",
       "      <td>0.901888</td>\n",
       "      <td>0.916845</td>\n",
       "      <td>0.967921</td>\n",
       "      <td>0.993119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980549</td>\n",
       "      <td>0.972853</td>\n",
       "      <td>0.988447</td>\n",
       "      <td>0.962874</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.944687</td>\n",
       "      <td>0.939407</td>\n",
       "      <td>0.953526</td>\n",
       "      <td>0.909536</td>\n",
       "      <td>0.908428</td>\n",
       "      <td>0.908123</td>\n",
       "      <td>0.901898</td>\n",
       "      <td>0.904942</td>\n",
       "      <td>0.925803</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.919893</td>\n",
       "      <td>0.919009</td>\n",
       "      <td>0.904701</td>\n",
       "      <td>0.895842</td>\n",
       "      <td>0.737337</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.908494</td>\n",
       "      <td>0.921836</td>\n",
       "      <td>0.920802</td>\n",
       "      <td>0.918679</td>\n",
       "      <td>0.916663</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.900557</td>\n",
       "      <td>0.865516</td>\n",
       "      <td>0.709698</td>\n",
       "      <td>0.844977</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.896866</td>\n",
       "      <td>0.901531</td>\n",
       "      <td>0.910878</td>\n",
       "      <td>0.846989</td>\n",
       "      <td>0.879539</td>\n",
       "      <td>0.861631</td>\n",
       "      <td>0.883506</td>\n",
       "      <td>0.871553</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.827788</td>\n",
       "      <td>0.850257</td>\n",
       "      <td>0.819961</td>\n",
       "      <td>0.852166</td>\n",
       "      <td>0.752736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_enc_user_feat2_lgb</th>\n",
       "      <td>0.896114</td>\n",
       "      <td>0.899326</td>\n",
       "      <td>0.904745</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.893871</td>\n",
       "      <td>0.907965</td>\n",
       "      <td>0.957815</td>\n",
       "      <td>0.979055</td>\n",
       "      <td>0.980549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.974986</td>\n",
       "      <td>0.951025</td>\n",
       "      <td>0.932428</td>\n",
       "      <td>0.936438</td>\n",
       "      <td>0.928221</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.902085</td>\n",
       "      <td>0.900287</td>\n",
       "      <td>0.899951</td>\n",
       "      <td>0.893906</td>\n",
       "      <td>0.896952</td>\n",
       "      <td>0.917543</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.911642</td>\n",
       "      <td>0.910830</td>\n",
       "      <td>0.896645</td>\n",
       "      <td>0.887875</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.892868</td>\n",
       "      <td>0.892868</td>\n",
       "      <td>0.910381</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>0.914385</td>\n",
       "      <td>0.913422</td>\n",
       "      <td>0.911270</td>\n",
       "      <td>0.909777</td>\n",
       "      <td>0.900854</td>\n",
       "      <td>0.893011</td>\n",
       "      <td>0.871939</td>\n",
       "      <td>0.715363</td>\n",
       "      <td>0.851349</td>\n",
       "      <td>0.854074</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.904491</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.877224</td>\n",
       "      <td>0.858859</td>\n",
       "      <td>0.881255</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.834829</td>\n",
       "      <td>0.820828</td>\n",
       "      <td>0.843080</td>\n",
       "      <td>0.813033</td>\n",
       "      <td>0.842887</td>\n",
       "      <td>0.752974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_interact_lgb</th>\n",
       "      <td>0.898852</td>\n",
       "      <td>0.902366</td>\n",
       "      <td>0.907654</td>\n",
       "      <td>0.900886</td>\n",
       "      <td>0.896375</td>\n",
       "      <td>0.911571</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.973705</td>\n",
       "      <td>0.972853</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976066</td>\n",
       "      <td>0.960817</td>\n",
       "      <td>0.933094</td>\n",
       "      <td>0.936761</td>\n",
       "      <td>0.937580</td>\n",
       "      <td>0.950516</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.903149</td>\n",
       "      <td>0.902947</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.898981</td>\n",
       "      <td>0.920951</td>\n",
       "      <td>0.916776</td>\n",
       "      <td>0.919459</td>\n",
       "      <td>0.914348</td>\n",
       "      <td>0.913160</td>\n",
       "      <td>0.899476</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>0.734428</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.913036</td>\n",
       "      <td>0.903939</td>\n",
       "      <td>0.916719</td>\n",
       "      <td>0.915921</td>\n",
       "      <td>0.913904</td>\n",
       "      <td>0.910945</td>\n",
       "      <td>0.904098</td>\n",
       "      <td>0.895602</td>\n",
       "      <td>0.862606</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.845153</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.895244</td>\n",
       "      <td>0.904639</td>\n",
       "      <td>0.835859</td>\n",
       "      <td>0.873883</td>\n",
       "      <td>0.852646</td>\n",
       "      <td>0.878525</td>\n",
       "      <td>0.868102</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.809139</td>\n",
       "      <td>0.845405</td>\n",
       "      <td>0.749832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_enc_lgb</th>\n",
       "      <td>0.903478</td>\n",
       "      <td>0.906453</td>\n",
       "      <td>0.912110</td>\n",
       "      <td>0.905318</td>\n",
       "      <td>0.900974</td>\n",
       "      <td>0.916972</td>\n",
       "      <td>0.971213</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.988447</td>\n",
       "      <td>0.974986</td>\n",
       "      <td>0.976066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962645</td>\n",
       "      <td>0.938839</td>\n",
       "      <td>0.943108</td>\n",
       "      <td>0.937892</td>\n",
       "      <td>0.952404</td>\n",
       "      <td>0.909121</td>\n",
       "      <td>0.907386</td>\n",
       "      <td>0.907152</td>\n",
       "      <td>0.900995</td>\n",
       "      <td>0.904021</td>\n",
       "      <td>0.923394</td>\n",
       "      <td>0.919352</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.917717</td>\n",
       "      <td>0.916878</td>\n",
       "      <td>0.903714</td>\n",
       "      <td>0.894925</td>\n",
       "      <td>0.737832</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.918151</td>\n",
       "      <td>0.908191</td>\n",
       "      <td>0.921847</td>\n",
       "      <td>0.921070</td>\n",
       "      <td>0.918656</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.901170</td>\n",
       "      <td>0.869846</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>0.849202</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0.897334</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>0.911783</td>\n",
       "      <td>0.848833</td>\n",
       "      <td>0.881341</td>\n",
       "      <td>0.863476</td>\n",
       "      <td>0.885262</td>\n",
       "      <td>0.874476</td>\n",
       "      <td>0.841630</td>\n",
       "      <td>0.827670</td>\n",
       "      <td>0.850187</td>\n",
       "      <td>0.819786</td>\n",
       "      <td>0.850715</td>\n",
       "      <td>0.753346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marcus_lgb</th>\n",
       "      <td>0.915897</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.914469</td>\n",
       "      <td>0.915583</td>\n",
       "      <td>0.912759</td>\n",
       "      <td>0.932491</td>\n",
       "      <td>0.956146</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>0.962874</td>\n",
       "      <td>0.951025</td>\n",
       "      <td>0.960817</td>\n",
       "      <td>0.962645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942398</td>\n",
       "      <td>0.944862</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.975061</td>\n",
       "      <td>0.918962</td>\n",
       "      <td>0.919970</td>\n",
       "      <td>0.920275</td>\n",
       "      <td>0.912005</td>\n",
       "      <td>0.915235</td>\n",
       "      <td>0.933476</td>\n",
       "      <td>0.929105</td>\n",
       "      <td>0.932235</td>\n",
       "      <td>0.934714</td>\n",
       "      <td>0.933102</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>0.906859</td>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.919560</td>\n",
       "      <td>0.919560</td>\n",
       "      <td>0.925841</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>0.919778</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.912860</td>\n",
       "      <td>0.910647</td>\n",
       "      <td>0.902576</td>\n",
       "      <td>0.852152</td>\n",
       "      <td>0.701711</td>\n",
       "      <td>0.832332</td>\n",
       "      <td>0.835086</td>\n",
       "      <td>0.887590</td>\n",
       "      <td>0.895948</td>\n",
       "      <td>0.908071</td>\n",
       "      <td>0.825604</td>\n",
       "      <td>0.863308</td>\n",
       "      <td>0.842154</td>\n",
       "      <td>0.867993</td>\n",
       "      <td>0.863764</td>\n",
       "      <td>0.826684</td>\n",
       "      <td>0.811957</td>\n",
       "      <td>0.836491</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>0.865770</td>\n",
       "      <td>0.752856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fused_text_lgb</th>\n",
       "      <td>0.912013</td>\n",
       "      <td>0.914794</td>\n",
       "      <td>0.921208</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>0.910385</td>\n",
       "      <td>0.925647</td>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.939821</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.932428</td>\n",
       "      <td>0.933094</td>\n",
       "      <td>0.938839</td>\n",
       "      <td>0.942398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977439</td>\n",
       "      <td>0.925521</td>\n",
       "      <td>0.930711</td>\n",
       "      <td>0.918812</td>\n",
       "      <td>0.916225</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>0.911017</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.950737</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.950493</td>\n",
       "      <td>0.945683</td>\n",
       "      <td>0.945216</td>\n",
       "      <td>0.911931</td>\n",
       "      <td>0.904365</td>\n",
       "      <td>0.741206</td>\n",
       "      <td>0.904336</td>\n",
       "      <td>0.904336</td>\n",
       "      <td>0.928662</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>0.917589</td>\n",
       "      <td>0.916410</td>\n",
       "      <td>0.914216</td>\n",
       "      <td>0.915931</td>\n",
       "      <td>0.905832</td>\n",
       "      <td>0.896022</td>\n",
       "      <td>0.866779</td>\n",
       "      <td>0.715492</td>\n",
       "      <td>0.868791</td>\n",
       "      <td>0.870874</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.921293</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>0.853381</td>\n",
       "      <td>0.891558</td>\n",
       "      <td>0.870849</td>\n",
       "      <td>0.895356</td>\n",
       "      <td>0.890493</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.839089</td>\n",
       "      <td>0.861994</td>\n",
       "      <td>0.832904</td>\n",
       "      <td>0.862263</td>\n",
       "      <td>0.758297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixed_features_text_proprocessing_lgb</th>\n",
       "      <td>0.913005</td>\n",
       "      <td>0.915861</td>\n",
       "      <td>0.921965</td>\n",
       "      <td>0.915626</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>0.925489</td>\n",
       "      <td>0.939173</td>\n",
       "      <td>0.943974</td>\n",
       "      <td>0.944687</td>\n",
       "      <td>0.936438</td>\n",
       "      <td>0.936761</td>\n",
       "      <td>0.943108</td>\n",
       "      <td>0.944862</td>\n",
       "      <td>0.977439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921109</td>\n",
       "      <td>0.932118</td>\n",
       "      <td>0.919663</td>\n",
       "      <td>0.917162</td>\n",
       "      <td>0.916609</td>\n",
       "      <td>0.911857</td>\n",
       "      <td>0.914998</td>\n",
       "      <td>0.949450</td>\n",
       "      <td>0.945420</td>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>0.943598</td>\n",
       "      <td>0.913279</td>\n",
       "      <td>0.905456</td>\n",
       "      <td>0.739742</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>0.917918</td>\n",
       "      <td>0.916229</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>0.915627</td>\n",
       "      <td>0.906177</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.868076</td>\n",
       "      <td>0.710091</td>\n",
       "      <td>0.867281</td>\n",
       "      <td>0.868427</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>0.919177</td>\n",
       "      <td>0.926004</td>\n",
       "      <td>0.852450</td>\n",
       "      <td>0.889281</td>\n",
       "      <td>0.869725</td>\n",
       "      <td>0.892455</td>\n",
       "      <td>0.886403</td>\n",
       "      <td>0.851668</td>\n",
       "      <td>0.839892</td>\n",
       "      <td>0.860305</td>\n",
       "      <td>0.833779</td>\n",
       "      <td>0.864107</td>\n",
       "      <td>0.756379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>select_dense_features_lgb</th>\n",
       "      <td>0.902741</td>\n",
       "      <td>0.906655</td>\n",
       "      <td>0.896150</td>\n",
       "      <td>0.901881</td>\n",
       "      <td>0.899385</td>\n",
       "      <td>0.919620</td>\n",
       "      <td>0.933709</td>\n",
       "      <td>0.939846</td>\n",
       "      <td>0.939407</td>\n",
       "      <td>0.928221</td>\n",
       "      <td>0.937580</td>\n",
       "      <td>0.937892</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.925521</td>\n",
       "      <td>0.921109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970594</td>\n",
       "      <td>0.905117</td>\n",
       "      <td>0.906767</td>\n",
       "      <td>0.907153</td>\n",
       "      <td>0.898740</td>\n",
       "      <td>0.902010</td>\n",
       "      <td>0.915873</td>\n",
       "      <td>0.911518</td>\n",
       "      <td>0.918223</td>\n",
       "      <td>0.917351</td>\n",
       "      <td>0.918931</td>\n",
       "      <td>0.904129</td>\n",
       "      <td>0.893515</td>\n",
       "      <td>0.735165</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.911059</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>0.913667</td>\n",
       "      <td>0.912747</td>\n",
       "      <td>0.911341</td>\n",
       "      <td>0.900438</td>\n",
       "      <td>0.899333</td>\n",
       "      <td>0.893267</td>\n",
       "      <td>0.823182</td>\n",
       "      <td>0.705327</td>\n",
       "      <td>0.804784</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>0.866792</td>\n",
       "      <td>0.880062</td>\n",
       "      <td>0.893396</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.839233</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.846704</td>\n",
       "      <td>0.852123</td>\n",
       "      <td>0.799327</td>\n",
       "      <td>0.781676</td>\n",
       "      <td>0.815745</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.849946</td>\n",
       "      <td>0.750064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>select_sparse_features_lgb</th>\n",
       "      <td>0.908337</td>\n",
       "      <td>0.912361</td>\n",
       "      <td>0.902178</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>0.905112</td>\n",
       "      <td>0.924598</td>\n",
       "      <td>0.945776</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>0.953526</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.950516</td>\n",
       "      <td>0.952404</td>\n",
       "      <td>0.975061</td>\n",
       "      <td>0.930711</td>\n",
       "      <td>0.932118</td>\n",
       "      <td>0.970594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910978</td>\n",
       "      <td>0.912440</td>\n",
       "      <td>0.912812</td>\n",
       "      <td>0.904226</td>\n",
       "      <td>0.907487</td>\n",
       "      <td>0.921414</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>0.923615</td>\n",
       "      <td>0.922866</td>\n",
       "      <td>0.924344</td>\n",
       "      <td>0.910121</td>\n",
       "      <td>0.899271</td>\n",
       "      <td>0.734971</td>\n",
       "      <td>0.907917</td>\n",
       "      <td>0.907917</td>\n",
       "      <td>0.916608</td>\n",
       "      <td>0.909647</td>\n",
       "      <td>0.914844</td>\n",
       "      <td>0.914060</td>\n",
       "      <td>0.912147</td>\n",
       "      <td>0.907708</td>\n",
       "      <td>0.906939</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>0.841794</td>\n",
       "      <td>0.695711</td>\n",
       "      <td>0.821912</td>\n",
       "      <td>0.824401</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.885836</td>\n",
       "      <td>0.899280</td>\n",
       "      <td>0.813741</td>\n",
       "      <td>0.851746</td>\n",
       "      <td>0.830083</td>\n",
       "      <td>0.856936</td>\n",
       "      <td>0.855378</td>\n",
       "      <td>0.814837</td>\n",
       "      <td>0.799672</td>\n",
       "      <td>0.826084</td>\n",
       "      <td>0.791992</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.748902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb411_dart_tune</th>\n",
       "      <td>0.976410</td>\n",
       "      <td>0.982080</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.972245</td>\n",
       "      <td>0.976626</td>\n",
       "      <td>0.963631</td>\n",
       "      <td>0.908589</td>\n",
       "      <td>0.909640</td>\n",
       "      <td>0.909536</td>\n",
       "      <td>0.902085</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.909121</td>\n",
       "      <td>0.918962</td>\n",
       "      <td>0.918812</td>\n",
       "      <td>0.919663</td>\n",
       "      <td>0.905117</td>\n",
       "      <td>0.910978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.976874</td>\n",
       "      <td>0.980240</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.928168</td>\n",
       "      <td>0.935901</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.940572</td>\n",
       "      <td>0.981039</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.771464</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.975858</td>\n",
       "      <td>0.971310</td>\n",
       "      <td>0.896763</td>\n",
       "      <td>0.896112</td>\n",
       "      <td>0.893587</td>\n",
       "      <td>0.896312</td>\n",
       "      <td>0.896231</td>\n",
       "      <td>0.910889</td>\n",
       "      <td>0.834262</td>\n",
       "      <td>0.699198</td>\n",
       "      <td>0.834251</td>\n",
       "      <td>0.836672</td>\n",
       "      <td>0.870983</td>\n",
       "      <td>0.935395</td>\n",
       "      <td>0.948653</td>\n",
       "      <td>0.822557</td>\n",
       "      <td>0.858009</td>\n",
       "      <td>0.838689</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.884214</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.806717</td>\n",
       "      <td>0.829294</td>\n",
       "      <td>0.801049</td>\n",
       "      <td>0.932960</td>\n",
       "      <td>0.794906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb411_goss_tune</th>\n",
       "      <td>0.986276</td>\n",
       "      <td>0.994217</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>0.906396</td>\n",
       "      <td>0.908318</td>\n",
       "      <td>0.908428</td>\n",
       "      <td>0.900287</td>\n",
       "      <td>0.903149</td>\n",
       "      <td>0.907386</td>\n",
       "      <td>0.919970</td>\n",
       "      <td>0.916225</td>\n",
       "      <td>0.917162</td>\n",
       "      <td>0.906767</td>\n",
       "      <td>0.912440</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995097</td>\n",
       "      <td>0.986620</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.932001</td>\n",
       "      <td>0.927691</td>\n",
       "      <td>0.935954</td>\n",
       "      <td>0.940478</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.985470</td>\n",
       "      <td>0.978288</td>\n",
       "      <td>0.771626</td>\n",
       "      <td>0.897286</td>\n",
       "      <td>0.897286</td>\n",
       "      <td>0.976467</td>\n",
       "      <td>0.974433</td>\n",
       "      <td>0.895743</td>\n",
       "      <td>0.895005</td>\n",
       "      <td>0.892570</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.896516</td>\n",
       "      <td>0.911942</td>\n",
       "      <td>0.825209</td>\n",
       "      <td>0.687254</td>\n",
       "      <td>0.824191</td>\n",
       "      <td>0.825979</td>\n",
       "      <td>0.868194</td>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.815271</td>\n",
       "      <td>0.849882</td>\n",
       "      <td>0.831110</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.875844</td>\n",
       "      <td>0.814830</td>\n",
       "      <td>0.802777</td>\n",
       "      <td>0.824603</td>\n",
       "      <td>0.797247</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.790416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb411_goss_tune2</th>\n",
       "      <td>0.988411</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.967875</td>\n",
       "      <td>0.977729</td>\n",
       "      <td>0.986809</td>\n",
       "      <td>0.968451</td>\n",
       "      <td>0.906203</td>\n",
       "      <td>0.908056</td>\n",
       "      <td>0.908123</td>\n",
       "      <td>0.899951</td>\n",
       "      <td>0.902947</td>\n",
       "      <td>0.907152</td>\n",
       "      <td>0.920275</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>0.916609</td>\n",
       "      <td>0.907153</td>\n",
       "      <td>0.912812</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.995097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986215</td>\n",
       "      <td>0.989644</td>\n",
       "      <td>0.931870</td>\n",
       "      <td>0.927521</td>\n",
       "      <td>0.936097</td>\n",
       "      <td>0.941337</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.988114</td>\n",
       "      <td>0.978595</td>\n",
       "      <td>0.770214</td>\n",
       "      <td>0.897418</td>\n",
       "      <td>0.897418</td>\n",
       "      <td>0.976997</td>\n",
       "      <td>0.975571</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.895194</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.894810</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>0.912926</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.685681</td>\n",
       "      <td>0.822673</td>\n",
       "      <td>0.824458</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.922978</td>\n",
       "      <td>0.938183</td>\n",
       "      <td>0.813841</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.829625</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.874164</td>\n",
       "      <td>0.814072</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.823828</td>\n",
       "      <td>0.796454</td>\n",
       "      <td>0.946191</td>\n",
       "      <td>0.788665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poisson_lgb</th>\n",
       "      <td>0.979855</td>\n",
       "      <td>0.985545</td>\n",
       "      <td>0.963319</td>\n",
       "      <td>0.972814</td>\n",
       "      <td>0.982530</td>\n",
       "      <td>0.964006</td>\n",
       "      <td>0.900190</td>\n",
       "      <td>0.901865</td>\n",
       "      <td>0.901898</td>\n",
       "      <td>0.893906</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.900995</td>\n",
       "      <td>0.912005</td>\n",
       "      <td>0.911017</td>\n",
       "      <td>0.911857</td>\n",
       "      <td>0.898740</td>\n",
       "      <td>0.904226</td>\n",
       "      <td>0.976874</td>\n",
       "      <td>0.986620</td>\n",
       "      <td>0.986215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.925590</td>\n",
       "      <td>0.921467</td>\n",
       "      <td>0.929679</td>\n",
       "      <td>0.933917</td>\n",
       "      <td>0.936607</td>\n",
       "      <td>0.979324</td>\n",
       "      <td>0.972942</td>\n",
       "      <td>0.766890</td>\n",
       "      <td>0.891646</td>\n",
       "      <td>0.891646</td>\n",
       "      <td>0.972201</td>\n",
       "      <td>0.968376</td>\n",
       "      <td>0.890068</td>\n",
       "      <td>0.889364</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>0.889476</td>\n",
       "      <td>0.890624</td>\n",
       "      <td>0.906531</td>\n",
       "      <td>0.823106</td>\n",
       "      <td>0.687793</td>\n",
       "      <td>0.822702</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.863948</td>\n",
       "      <td>0.924469</td>\n",
       "      <td>0.937688</td>\n",
       "      <td>0.812784</td>\n",
       "      <td>0.847676</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.851360</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.812960</td>\n",
       "      <td>0.800763</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>0.795230</td>\n",
       "      <td>0.939893</td>\n",
       "      <td>0.786246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poisson_small_lr_lgb</th>\n",
       "      <td>0.983149</td>\n",
       "      <td>0.988986</td>\n",
       "      <td>0.966409</td>\n",
       "      <td>0.976023</td>\n",
       "      <td>0.985805</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.904927</td>\n",
       "      <td>0.904942</td>\n",
       "      <td>0.896952</td>\n",
       "      <td>0.898981</td>\n",
       "      <td>0.904021</td>\n",
       "      <td>0.915235</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.914998</td>\n",
       "      <td>0.902010</td>\n",
       "      <td>0.907487</td>\n",
       "      <td>0.980240</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.989644</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928921</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.933003</td>\n",
       "      <td>0.937375</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.982912</td>\n",
       "      <td>0.976541</td>\n",
       "      <td>0.769690</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.975346</td>\n",
       "      <td>0.971617</td>\n",
       "      <td>0.893223</td>\n",
       "      <td>0.892512</td>\n",
       "      <td>0.890005</td>\n",
       "      <td>0.892716</td>\n",
       "      <td>0.893784</td>\n",
       "      <td>0.909592</td>\n",
       "      <td>0.826004</td>\n",
       "      <td>0.689999</td>\n",
       "      <td>0.825559</td>\n",
       "      <td>0.827687</td>\n",
       "      <td>0.867124</td>\n",
       "      <td>0.927577</td>\n",
       "      <td>0.940851</td>\n",
       "      <td>0.815649</td>\n",
       "      <td>0.850684</td>\n",
       "      <td>0.831653</td>\n",
       "      <td>0.854368</td>\n",
       "      <td>0.877285</td>\n",
       "      <td>0.815880</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.943051</td>\n",
       "      <td>0.789149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_features_v5_xgb</th>\n",
       "      <td>0.926844</td>\n",
       "      <td>0.931473</td>\n",
       "      <td>0.931010</td>\n",
       "      <td>0.924954</td>\n",
       "      <td>0.925209</td>\n",
       "      <td>0.923585</td>\n",
       "      <td>0.922071</td>\n",
       "      <td>0.925226</td>\n",
       "      <td>0.925803</td>\n",
       "      <td>0.917543</td>\n",
       "      <td>0.920951</td>\n",
       "      <td>0.923394</td>\n",
       "      <td>0.933476</td>\n",
       "      <td>0.950737</td>\n",
       "      <td>0.949450</td>\n",
       "      <td>0.915873</td>\n",
       "      <td>0.921414</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.932001</td>\n",
       "      <td>0.931870</td>\n",
       "      <td>0.925590</td>\n",
       "      <td>0.928921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>0.987994</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>0.977972</td>\n",
       "      <td>0.931531</td>\n",
       "      <td>0.919868</td>\n",
       "      <td>0.742374</td>\n",
       "      <td>0.911971</td>\n",
       "      <td>0.911971</td>\n",
       "      <td>0.935648</td>\n",
       "      <td>0.927811</td>\n",
       "      <td>0.911734</td>\n",
       "      <td>0.911048</td>\n",
       "      <td>0.908847</td>\n",
       "      <td>0.910415</td>\n",
       "      <td>0.901820</td>\n",
       "      <td>0.893911</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.702433</td>\n",
       "      <td>0.847868</td>\n",
       "      <td>0.849526</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.914004</td>\n",
       "      <td>0.924785</td>\n",
       "      <td>0.832539</td>\n",
       "      <td>0.868728</td>\n",
       "      <td>0.848975</td>\n",
       "      <td>0.872565</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.820057</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.814219</td>\n",
       "      <td>0.878056</td>\n",
       "      <td>0.766178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_features_v4_xgb</th>\n",
       "      <td>0.922592</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.926905</td>\n",
       "      <td>0.920816</td>\n",
       "      <td>0.920967</td>\n",
       "      <td>0.919470</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.921064</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>0.913503</td>\n",
       "      <td>0.916776</td>\n",
       "      <td>0.919352</td>\n",
       "      <td>0.929105</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.945420</td>\n",
       "      <td>0.911518</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>0.928168</td>\n",
       "      <td>0.927691</td>\n",
       "      <td>0.927521</td>\n",
       "      <td>0.921467</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.973208</td>\n",
       "      <td>0.927041</td>\n",
       "      <td>0.915654</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.908011</td>\n",
       "      <td>0.908011</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.923697</td>\n",
       "      <td>0.907881</td>\n",
       "      <td>0.907101</td>\n",
       "      <td>0.904934</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.897812</td>\n",
       "      <td>0.889862</td>\n",
       "      <td>0.847049</td>\n",
       "      <td>0.699813</td>\n",
       "      <td>0.844865</td>\n",
       "      <td>0.846549</td>\n",
       "      <td>0.887099</td>\n",
       "      <td>0.910404</td>\n",
       "      <td>0.921047</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.865605</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.869439</td>\n",
       "      <td>0.867462</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.817291</td>\n",
       "      <td>0.839354</td>\n",
       "      <td>0.811488</td>\n",
       "      <td>0.874278</td>\n",
       "      <td>0.762278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nima_features_xgb</th>\n",
       "      <td>0.931074</td>\n",
       "      <td>0.935678</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.928658</td>\n",
       "      <td>0.929248</td>\n",
       "      <td>0.926771</td>\n",
       "      <td>0.921465</td>\n",
       "      <td>0.924221</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.919459</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.932235</td>\n",
       "      <td>0.950493</td>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.918223</td>\n",
       "      <td>0.923615</td>\n",
       "      <td>0.935901</td>\n",
       "      <td>0.935954</td>\n",
       "      <td>0.936097</td>\n",
       "      <td>0.929679</td>\n",
       "      <td>0.933003</td>\n",
       "      <td>0.987994</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>0.982510</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.923812</td>\n",
       "      <td>0.745941</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>0.939565</td>\n",
       "      <td>0.931775</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.910508</td>\n",
       "      <td>0.908305</td>\n",
       "      <td>0.910069</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.896499</td>\n",
       "      <td>0.851777</td>\n",
       "      <td>0.704198</td>\n",
       "      <td>0.849669</td>\n",
       "      <td>0.851503</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.916381</td>\n",
       "      <td>0.927977</td>\n",
       "      <td>0.833880</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.850466</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.874235</td>\n",
       "      <td>0.833920</td>\n",
       "      <td>0.821330</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.815432</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.768238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_meta_xgb</th>\n",
       "      <td>0.936005</td>\n",
       "      <td>0.940697</td>\n",
       "      <td>0.925493</td>\n",
       "      <td>0.931048</td>\n",
       "      <td>0.933461</td>\n",
       "      <td>0.928518</td>\n",
       "      <td>0.916744</td>\n",
       "      <td>0.919339</td>\n",
       "      <td>0.919893</td>\n",
       "      <td>0.911642</td>\n",
       "      <td>0.914348</td>\n",
       "      <td>0.917717</td>\n",
       "      <td>0.934714</td>\n",
       "      <td>0.945683</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>0.917351</td>\n",
       "      <td>0.922866</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.940478</td>\n",
       "      <td>0.941337</td>\n",
       "      <td>0.933917</td>\n",
       "      <td>0.937375</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>0.940470</td>\n",
       "      <td>0.928109</td>\n",
       "      <td>0.745525</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.940027</td>\n",
       "      <td>0.933331</td>\n",
       "      <td>0.907005</td>\n",
       "      <td>0.906356</td>\n",
       "      <td>0.904119</td>\n",
       "      <td>0.905936</td>\n",
       "      <td>0.901449</td>\n",
       "      <td>0.893833</td>\n",
       "      <td>0.848667</td>\n",
       "      <td>0.701815</td>\n",
       "      <td>0.846402</td>\n",
       "      <td>0.848316</td>\n",
       "      <td>0.887415</td>\n",
       "      <td>0.913126</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.830441</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>0.846931</td>\n",
       "      <td>0.870755</td>\n",
       "      <td>0.871764</td>\n",
       "      <td>0.830167</td>\n",
       "      <td>0.817575</td>\n",
       "      <td>0.839933</td>\n",
       "      <td>0.811707</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.768521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_meta_nima_xgb</th>\n",
       "      <td>0.938847</td>\n",
       "      <td>0.943550</td>\n",
       "      <td>0.924579</td>\n",
       "      <td>0.933453</td>\n",
       "      <td>0.936151</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>0.916079</td>\n",
       "      <td>0.918438</td>\n",
       "      <td>0.919009</td>\n",
       "      <td>0.910830</td>\n",
       "      <td>0.913160</td>\n",
       "      <td>0.916878</td>\n",
       "      <td>0.933102</td>\n",
       "      <td>0.945216</td>\n",
       "      <td>0.943598</td>\n",
       "      <td>0.918931</td>\n",
       "      <td>0.924344</td>\n",
       "      <td>0.940572</td>\n",
       "      <td>0.943147</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.936607</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.977972</td>\n",
       "      <td>0.973208</td>\n",
       "      <td>0.982510</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>0.930752</td>\n",
       "      <td>0.746903</td>\n",
       "      <td>0.918528</td>\n",
       "      <td>0.918528</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>0.935971</td>\n",
       "      <td>0.906398</td>\n",
       "      <td>0.905686</td>\n",
       "      <td>0.903453</td>\n",
       "      <td>0.905387</td>\n",
       "      <td>0.901533</td>\n",
       "      <td>0.895538</td>\n",
       "      <td>0.849234</td>\n",
       "      <td>0.702643</td>\n",
       "      <td>0.847204</td>\n",
       "      <td>0.849195</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.914289</td>\n",
       "      <td>0.926364</td>\n",
       "      <td>0.830877</td>\n",
       "      <td>0.867503</td>\n",
       "      <td>0.847454</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.873562</td>\n",
       "      <td>0.830699</td>\n",
       "      <td>0.818032</td>\n",
       "      <td>0.840524</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.892597</td>\n",
       "      <td>0.769703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_new</th>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.987608</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.971450</td>\n",
       "      <td>0.979641</td>\n",
       "      <td>0.963888</td>\n",
       "      <td>0.902595</td>\n",
       "      <td>0.904700</td>\n",
       "      <td>0.904701</td>\n",
       "      <td>0.896645</td>\n",
       "      <td>0.899476</td>\n",
       "      <td>0.903714</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>0.911931</td>\n",
       "      <td>0.913279</td>\n",
       "      <td>0.904129</td>\n",
       "      <td>0.910121</td>\n",
       "      <td>0.981039</td>\n",
       "      <td>0.985470</td>\n",
       "      <td>0.988114</td>\n",
       "      <td>0.979324</td>\n",
       "      <td>0.982912</td>\n",
       "      <td>0.931531</td>\n",
       "      <td>0.927041</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.940470</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.765451</td>\n",
       "      <td>0.893105</td>\n",
       "      <td>0.893105</td>\n",
       "      <td>0.972272</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.892691</td>\n",
       "      <td>0.890199</td>\n",
       "      <td>0.892815</td>\n",
       "      <td>0.893667</td>\n",
       "      <td>0.909740</td>\n",
       "      <td>0.822751</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>0.820821</td>\n",
       "      <td>0.822538</td>\n",
       "      <td>0.865363</td>\n",
       "      <td>0.925431</td>\n",
       "      <td>0.940940</td>\n",
       "      <td>0.810176</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>0.848448</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>0.807589</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.817199</td>\n",
       "      <td>0.790047</td>\n",
       "      <td>0.937390</td>\n",
       "      <td>0.790083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_xgb</th>\n",
       "      <td>0.971096</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.955797</td>\n",
       "      <td>0.964709</td>\n",
       "      <td>0.972157</td>\n",
       "      <td>0.954971</td>\n",
       "      <td>0.893908</td>\n",
       "      <td>0.895836</td>\n",
       "      <td>0.895842</td>\n",
       "      <td>0.887875</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>0.894925</td>\n",
       "      <td>0.906859</td>\n",
       "      <td>0.904365</td>\n",
       "      <td>0.905456</td>\n",
       "      <td>0.893515</td>\n",
       "      <td>0.899271</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.978288</td>\n",
       "      <td>0.978595</td>\n",
       "      <td>0.972942</td>\n",
       "      <td>0.976541</td>\n",
       "      <td>0.919868</td>\n",
       "      <td>0.915654</td>\n",
       "      <td>0.923812</td>\n",
       "      <td>0.928109</td>\n",
       "      <td>0.930752</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.885101</td>\n",
       "      <td>0.885101</td>\n",
       "      <td>0.964860</td>\n",
       "      <td>0.962241</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.880995</td>\n",
       "      <td>0.883780</td>\n",
       "      <td>0.884758</td>\n",
       "      <td>0.900193</td>\n",
       "      <td>0.816482</td>\n",
       "      <td>0.680675</td>\n",
       "      <td>0.815321</td>\n",
       "      <td>0.817191</td>\n",
       "      <td>0.857438</td>\n",
       "      <td>0.917079</td>\n",
       "      <td>0.931035</td>\n",
       "      <td>0.805885</td>\n",
       "      <td>0.840286</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>0.843861</td>\n",
       "      <td>0.866362</td>\n",
       "      <td>0.805410</td>\n",
       "      <td>0.793460</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>0.787995</td>\n",
       "      <td>0.931141</td>\n",
       "      <td>0.780367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranking_xgb</th>\n",
       "      <td>0.765870</td>\n",
       "      <td>0.769518</td>\n",
       "      <td>0.765113</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>0.766018</td>\n",
       "      <td>0.758656</td>\n",
       "      <td>0.738648</td>\n",
       "      <td>0.737372</td>\n",
       "      <td>0.737337</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.734428</td>\n",
       "      <td>0.737832</td>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.741206</td>\n",
       "      <td>0.739742</td>\n",
       "      <td>0.735165</td>\n",
       "      <td>0.734971</td>\n",
       "      <td>0.771464</td>\n",
       "      <td>0.771626</td>\n",
       "      <td>0.770214</td>\n",
       "      <td>0.766890</td>\n",
       "      <td>0.769690</td>\n",
       "      <td>0.742374</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.745941</td>\n",
       "      <td>0.745525</td>\n",
       "      <td>0.746903</td>\n",
       "      <td>0.765451</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741137</td>\n",
       "      <td>0.741137</td>\n",
       "      <td>0.774139</td>\n",
       "      <td>0.767015</td>\n",
       "      <td>0.723515</td>\n",
       "      <td>0.721852</td>\n",
       "      <td>0.722929</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.707121</td>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.689818</td>\n",
       "      <td>0.628618</td>\n",
       "      <td>0.696715</td>\n",
       "      <td>0.703082</td>\n",
       "      <td>0.709817</td>\n",
       "      <td>0.753216</td>\n",
       "      <td>0.760580</td>\n",
       "      <td>0.697815</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.711790</td>\n",
       "      <td>0.736516</td>\n",
       "      <td>0.755343</td>\n",
       "      <td>0.602618</td>\n",
       "      <td>0.591424</td>\n",
       "      <td>0.612974</td>\n",
       "      <td>0.586523</td>\n",
       "      <td>0.643513</td>\n",
       "      <td>0.880291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.896485</td>\n",
       "      <td>0.890247</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.902593</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.892868</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.919560</td>\n",
       "      <td>0.904336</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.907917</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.897286</td>\n",
       "      <td>0.897418</td>\n",
       "      <td>0.891646</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.911971</td>\n",
       "      <td>0.908011</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.918528</td>\n",
       "      <td>0.893105</td>\n",
       "      <td>0.885101</td>\n",
       "      <td>0.741137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911169</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.811322</td>\n",
       "      <td>0.729226</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>0.803529</td>\n",
       "      <td>0.846260</td>\n",
       "      <td>0.881499</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.787240</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.849061</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>0.757783</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.749147</td>\n",
       "      <td>0.837270</td>\n",
       "      <td>0.760855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost1_without_text</th>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.896485</td>\n",
       "      <td>0.890247</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.891253</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.902593</td>\n",
       "      <td>0.903455</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.892868</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.919560</td>\n",
       "      <td>0.904336</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.918677</td>\n",
       "      <td>0.907917</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.897286</td>\n",
       "      <td>0.897418</td>\n",
       "      <td>0.891646</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.911971</td>\n",
       "      <td>0.908011</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.918528</td>\n",
       "      <td>0.893105</td>\n",
       "      <td>0.885101</td>\n",
       "      <td>0.741137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911169</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.811322</td>\n",
       "      <td>0.729226</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>0.803529</td>\n",
       "      <td>0.846260</td>\n",
       "      <td>0.881499</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.787240</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.849061</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>0.757783</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.749147</td>\n",
       "      <td>0.837270</td>\n",
       "      <td>0.760855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcl_cgb</th>\n",
       "      <td>0.972385</td>\n",
       "      <td>0.976032</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.976016</td>\n",
       "      <td>0.971611</td>\n",
       "      <td>0.961636</td>\n",
       "      <td>0.918213</td>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.918047</td>\n",
       "      <td>0.910381</td>\n",
       "      <td>0.913036</td>\n",
       "      <td>0.918151</td>\n",
       "      <td>0.925841</td>\n",
       "      <td>0.928662</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>0.911059</td>\n",
       "      <td>0.916608</td>\n",
       "      <td>0.975858</td>\n",
       "      <td>0.976467</td>\n",
       "      <td>0.976997</td>\n",
       "      <td>0.972201</td>\n",
       "      <td>0.975346</td>\n",
       "      <td>0.935648</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.939565</td>\n",
       "      <td>0.940027</td>\n",
       "      <td>0.942517</td>\n",
       "      <td>0.972272</td>\n",
       "      <td>0.964860</td>\n",
       "      <td>0.774139</td>\n",
       "      <td>0.911169</td>\n",
       "      <td>0.911169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983371</td>\n",
       "      <td>0.906421</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.903111</td>\n",
       "      <td>0.906813</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915010</td>\n",
       "      <td>0.848970</td>\n",
       "      <td>0.710759</td>\n",
       "      <td>0.848899</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.884223</td>\n",
       "      <td>0.947720</td>\n",
       "      <td>0.959204</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.872388</td>\n",
       "      <td>0.852646</td>\n",
       "      <td>0.876225</td>\n",
       "      <td>0.899041</td>\n",
       "      <td>0.833304</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.928724</td>\n",
       "      <td>0.791433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cgb_with_categorical</th>\n",
       "      <td>0.970223</td>\n",
       "      <td>0.974701</td>\n",
       "      <td>0.964663</td>\n",
       "      <td>0.972276</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>0.956116</td>\n",
       "      <td>0.907633</td>\n",
       "      <td>0.908791</td>\n",
       "      <td>0.908494</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>0.903939</td>\n",
       "      <td>0.908191</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>0.917918</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>0.909647</td>\n",
       "      <td>0.971310</td>\n",
       "      <td>0.974433</td>\n",
       "      <td>0.975571</td>\n",
       "      <td>0.968376</td>\n",
       "      <td>0.971617</td>\n",
       "      <td>0.927811</td>\n",
       "      <td>0.923697</td>\n",
       "      <td>0.931775</td>\n",
       "      <td>0.933331</td>\n",
       "      <td>0.935971</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.962241</td>\n",
       "      <td>0.767015</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.983371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896067</td>\n",
       "      <td>0.895247</td>\n",
       "      <td>0.892782</td>\n",
       "      <td>0.896155</td>\n",
       "      <td>0.895008</td>\n",
       "      <td>0.907559</td>\n",
       "      <td>0.834495</td>\n",
       "      <td>0.695503</td>\n",
       "      <td>0.834020</td>\n",
       "      <td>0.836236</td>\n",
       "      <td>0.872875</td>\n",
       "      <td>0.932678</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.822745</td>\n",
       "      <td>0.857989</td>\n",
       "      <td>0.838852</td>\n",
       "      <td>0.861669</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.821529</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.831460</td>\n",
       "      <td>0.803197</td>\n",
       "      <td>0.927639</td>\n",
       "      <td>0.783187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_bigru_cv1d_rnn</th>\n",
       "      <td>0.892459</td>\n",
       "      <td>0.895204</td>\n",
       "      <td>0.897465</td>\n",
       "      <td>0.891990</td>\n",
       "      <td>0.890066</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>0.919504</td>\n",
       "      <td>0.922844</td>\n",
       "      <td>0.921836</td>\n",
       "      <td>0.914385</td>\n",
       "      <td>0.916719</td>\n",
       "      <td>0.921847</td>\n",
       "      <td>0.919778</td>\n",
       "      <td>0.917589</td>\n",
       "      <td>0.916229</td>\n",
       "      <td>0.913667</td>\n",
       "      <td>0.914844</td>\n",
       "      <td>0.896763</td>\n",
       "      <td>0.895743</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.890068</td>\n",
       "      <td>0.893223</td>\n",
       "      <td>0.911734</td>\n",
       "      <td>0.907881</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.907005</td>\n",
       "      <td>0.906398</td>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.723515</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>0.906421</td>\n",
       "      <td>0.896067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970911</td>\n",
       "      <td>0.968960</td>\n",
       "      <td>0.953796</td>\n",
       "      <td>0.935166</td>\n",
       "      <td>0.923658</td>\n",
       "      <td>0.849023</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.834455</td>\n",
       "      <td>0.838957</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>0.895275</td>\n",
       "      <td>0.903373</td>\n",
       "      <td>0.824145</td>\n",
       "      <td>0.864294</td>\n",
       "      <td>0.840836</td>\n",
       "      <td>0.870583</td>\n",
       "      <td>0.867369</td>\n",
       "      <td>0.831889</td>\n",
       "      <td>0.815955</td>\n",
       "      <td>0.845514</td>\n",
       "      <td>0.808175</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.748887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_bigru_attention_rnn</th>\n",
       "      <td>0.891782</td>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.896696</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.889372</td>\n",
       "      <td>0.900185</td>\n",
       "      <td>0.918586</td>\n",
       "      <td>0.921886</td>\n",
       "      <td>0.920802</td>\n",
       "      <td>0.913422</td>\n",
       "      <td>0.915921</td>\n",
       "      <td>0.921070</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>0.916410</td>\n",
       "      <td>0.914980</td>\n",
       "      <td>0.912747</td>\n",
       "      <td>0.914060</td>\n",
       "      <td>0.896112</td>\n",
       "      <td>0.895005</td>\n",
       "      <td>0.895194</td>\n",
       "      <td>0.889364</td>\n",
       "      <td>0.892512</td>\n",
       "      <td>0.911048</td>\n",
       "      <td>0.907101</td>\n",
       "      <td>0.910508</td>\n",
       "      <td>0.906356</td>\n",
       "      <td>0.905686</td>\n",
       "      <td>0.892691</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.721852</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.895247</td>\n",
       "      <td>0.970911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966881</td>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>0.921827</td>\n",
       "      <td>0.848229</td>\n",
       "      <td>0.715935</td>\n",
       "      <td>0.834031</td>\n",
       "      <td>0.838447</td>\n",
       "      <td>0.897399</td>\n",
       "      <td>0.894214</td>\n",
       "      <td>0.902575</td>\n",
       "      <td>0.823576</td>\n",
       "      <td>0.863698</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>0.869998</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>0.831351</td>\n",
       "      <td>0.815478</td>\n",
       "      <td>0.845075</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.842070</td>\n",
       "      <td>0.747406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_2gru_rnn</th>\n",
       "      <td>0.889217</td>\n",
       "      <td>0.891942</td>\n",
       "      <td>0.894225</td>\n",
       "      <td>0.888897</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.897477</td>\n",
       "      <td>0.916392</td>\n",
       "      <td>0.919655</td>\n",
       "      <td>0.918679</td>\n",
       "      <td>0.911270</td>\n",
       "      <td>0.913904</td>\n",
       "      <td>0.918656</td>\n",
       "      <td>0.916932</td>\n",
       "      <td>0.914216</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>0.911341</td>\n",
       "      <td>0.912147</td>\n",
       "      <td>0.893587</td>\n",
       "      <td>0.892570</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>0.890005</td>\n",
       "      <td>0.908847</td>\n",
       "      <td>0.904934</td>\n",
       "      <td>0.908305</td>\n",
       "      <td>0.904119</td>\n",
       "      <td>0.903453</td>\n",
       "      <td>0.890199</td>\n",
       "      <td>0.880995</td>\n",
       "      <td>0.722929</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.885382</td>\n",
       "      <td>0.903111</td>\n",
       "      <td>0.892782</td>\n",
       "      <td>0.968960</td>\n",
       "      <td>0.966881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949535</td>\n",
       "      <td>0.931613</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.845857</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.831046</td>\n",
       "      <td>0.835543</td>\n",
       "      <td>0.894728</td>\n",
       "      <td>0.891733</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.820945</td>\n",
       "      <td>0.860862</td>\n",
       "      <td>0.837553</td>\n",
       "      <td>0.867146</td>\n",
       "      <td>0.863973</td>\n",
       "      <td>0.828514</td>\n",
       "      <td>0.812761</td>\n",
       "      <td>0.842175</td>\n",
       "      <td>0.805075</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.748642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selftrained_bigru_conv1d_rnn</th>\n",
       "      <td>0.891598</td>\n",
       "      <td>0.894094</td>\n",
       "      <td>0.897245</td>\n",
       "      <td>0.891522</td>\n",
       "      <td>0.889311</td>\n",
       "      <td>0.899517</td>\n",
       "      <td>0.914868</td>\n",
       "      <td>0.917843</td>\n",
       "      <td>0.916663</td>\n",
       "      <td>0.909777</td>\n",
       "      <td>0.910945</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.912860</td>\n",
       "      <td>0.915931</td>\n",
       "      <td>0.915627</td>\n",
       "      <td>0.900438</td>\n",
       "      <td>0.907708</td>\n",
       "      <td>0.896312</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.894810</td>\n",
       "      <td>0.889476</td>\n",
       "      <td>0.892716</td>\n",
       "      <td>0.910415</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.910069</td>\n",
       "      <td>0.905936</td>\n",
       "      <td>0.905387</td>\n",
       "      <td>0.892815</td>\n",
       "      <td>0.883780</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.906813</td>\n",
       "      <td>0.896155</td>\n",
       "      <td>0.953796</td>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.949535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944339</td>\n",
       "      <td>0.932336</td>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.708776</td>\n",
       "      <td>0.847166</td>\n",
       "      <td>0.850304</td>\n",
       "      <td>0.906238</td>\n",
       "      <td>0.900735</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>0.833640</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.850473</td>\n",
       "      <td>0.877578</td>\n",
       "      <td>0.872210</td>\n",
       "      <td>0.843599</td>\n",
       "      <td>0.829074</td>\n",
       "      <td>0.854190</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.842529</td>\n",
       "      <td>0.743855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selftrained_bigru_conv1d_merged_with_image_rnn</th>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.896064</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>0.891001</td>\n",
       "      <td>0.890608</td>\n",
       "      <td>0.900388</td>\n",
       "      <td>0.907114</td>\n",
       "      <td>0.910287</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.900854</td>\n",
       "      <td>0.904098</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.910647</td>\n",
       "      <td>0.905832</td>\n",
       "      <td>0.906177</td>\n",
       "      <td>0.899333</td>\n",
       "      <td>0.906939</td>\n",
       "      <td>0.896231</td>\n",
       "      <td>0.896516</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>0.890624</td>\n",
       "      <td>0.893784</td>\n",
       "      <td>0.901820</td>\n",
       "      <td>0.897812</td>\n",
       "      <td>0.902554</td>\n",
       "      <td>0.901449</td>\n",
       "      <td>0.901533</td>\n",
       "      <td>0.893667</td>\n",
       "      <td>0.884758</td>\n",
       "      <td>0.707121</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.895008</td>\n",
       "      <td>0.935166</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>0.931613</td>\n",
       "      <td>0.944339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943779</td>\n",
       "      <td>0.828863</td>\n",
       "      <td>0.680382</td>\n",
       "      <td>0.817753</td>\n",
       "      <td>0.820265</td>\n",
       "      <td>0.877434</td>\n",
       "      <td>0.881505</td>\n",
       "      <td>0.890991</td>\n",
       "      <td>0.807451</td>\n",
       "      <td>0.844318</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.849011</td>\n",
       "      <td>0.846478</td>\n",
       "      <td>0.819210</td>\n",
       "      <td>0.805552</td>\n",
       "      <td>0.829565</td>\n",
       "      <td>0.798523</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.727658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selftrained_bigru_conv1d_merged_with_image_adv_rnn</th>\n",
       "      <td>0.915566</td>\n",
       "      <td>0.912031</td>\n",
       "      <td>0.903323</td>\n",
       "      <td>0.904735</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.898792</td>\n",
       "      <td>0.901655</td>\n",
       "      <td>0.900557</td>\n",
       "      <td>0.893011</td>\n",
       "      <td>0.895602</td>\n",
       "      <td>0.901170</td>\n",
       "      <td>0.902576</td>\n",
       "      <td>0.896022</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.893267</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>0.910889</td>\n",
       "      <td>0.911942</td>\n",
       "      <td>0.912926</td>\n",
       "      <td>0.906531</td>\n",
       "      <td>0.909592</td>\n",
       "      <td>0.893911</td>\n",
       "      <td>0.889862</td>\n",
       "      <td>0.896499</td>\n",
       "      <td>0.893833</td>\n",
       "      <td>0.895538</td>\n",
       "      <td>0.909740</td>\n",
       "      <td>0.900193</td>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.860682</td>\n",
       "      <td>0.915010</td>\n",
       "      <td>0.907559</td>\n",
       "      <td>0.923658</td>\n",
       "      <td>0.921827</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.932336</td>\n",
       "      <td>0.943779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818871</td>\n",
       "      <td>0.672434</td>\n",
       "      <td>0.808287</td>\n",
       "      <td>0.810838</td>\n",
       "      <td>0.866732</td>\n",
       "      <td>0.879680</td>\n",
       "      <td>0.891077</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>0.834788</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>0.839543</td>\n",
       "      <td>0.840113</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.795194</td>\n",
       "      <td>0.819298</td>\n",
       "      <td>0.788117</td>\n",
       "      <td>0.866651</td>\n",
       "      <td>0.733800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_lgb</th>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.823135</td>\n",
       "      <td>0.835321</td>\n",
       "      <td>0.828427</td>\n",
       "      <td>0.821424</td>\n",
       "      <td>0.827092</td>\n",
       "      <td>0.869182</td>\n",
       "      <td>0.866855</td>\n",
       "      <td>0.865516</td>\n",
       "      <td>0.871939</td>\n",
       "      <td>0.862606</td>\n",
       "      <td>0.869846</td>\n",
       "      <td>0.852152</td>\n",
       "      <td>0.866779</td>\n",
       "      <td>0.868076</td>\n",
       "      <td>0.823182</td>\n",
       "      <td>0.841794</td>\n",
       "      <td>0.834262</td>\n",
       "      <td>0.825209</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.823106</td>\n",
       "      <td>0.826004</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.847049</td>\n",
       "      <td>0.851777</td>\n",
       "      <td>0.848667</td>\n",
       "      <td>0.849234</td>\n",
       "      <td>0.822751</td>\n",
       "      <td>0.816482</td>\n",
       "      <td>0.689818</td>\n",
       "      <td>0.811322</td>\n",
       "      <td>0.811322</td>\n",
       "      <td>0.848970</td>\n",
       "      <td>0.834495</td>\n",
       "      <td>0.849023</td>\n",
       "      <td>0.848229</td>\n",
       "      <td>0.845857</td>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.828863</td>\n",
       "      <td>0.818871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.886745</td>\n",
       "      <td>0.904824</td>\n",
       "      <td>0.898917</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.914040</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.859582</td>\n",
       "      <td>0.843389</td>\n",
       "      <td>0.866778</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.773886</td>\n",
       "      <td>0.712138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_cwb_rg</th>\n",
       "      <td>0.685411</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.695687</td>\n",
       "      <td>0.690939</td>\n",
       "      <td>0.684999</td>\n",
       "      <td>0.686990</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.710733</td>\n",
       "      <td>0.709698</td>\n",
       "      <td>0.715363</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.712374</td>\n",
       "      <td>0.701711</td>\n",
       "      <td>0.715492</td>\n",
       "      <td>0.710091</td>\n",
       "      <td>0.705327</td>\n",
       "      <td>0.695711</td>\n",
       "      <td>0.699198</td>\n",
       "      <td>0.687254</td>\n",
       "      <td>0.685681</td>\n",
       "      <td>0.687793</td>\n",
       "      <td>0.689999</td>\n",
       "      <td>0.702433</td>\n",
       "      <td>0.699813</td>\n",
       "      <td>0.704198</td>\n",
       "      <td>0.701815</td>\n",
       "      <td>0.702643</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>0.680675</td>\n",
       "      <td>0.628618</td>\n",
       "      <td>0.729226</td>\n",
       "      <td>0.729226</td>\n",
       "      <td>0.710759</td>\n",
       "      <td>0.695503</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.715935</td>\n",
       "      <td>0.712184</td>\n",
       "      <td>0.708776</td>\n",
       "      <td>0.680382</td>\n",
       "      <td>0.672434</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768838</td>\n",
       "      <td>0.789577</td>\n",
       "      <td>0.716294</td>\n",
       "      <td>0.773523</td>\n",
       "      <td>0.764218</td>\n",
       "      <td>0.717921</td>\n",
       "      <td>0.766546</td>\n",
       "      <td>0.734738</td>\n",
       "      <td>0.778527</td>\n",
       "      <td>0.778525</td>\n",
       "      <td>0.672195</td>\n",
       "      <td>0.651171</td>\n",
       "      <td>0.692946</td>\n",
       "      <td>0.642389</td>\n",
       "      <td>0.617066</td>\n",
       "      <td>0.661407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_fm</th>\n",
       "      <td>0.821406</td>\n",
       "      <td>0.821971</td>\n",
       "      <td>0.834781</td>\n",
       "      <td>0.827950</td>\n",
       "      <td>0.820779</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>0.849560</td>\n",
       "      <td>0.846129</td>\n",
       "      <td>0.844977</td>\n",
       "      <td>0.851349</td>\n",
       "      <td>0.841915</td>\n",
       "      <td>0.849202</td>\n",
       "      <td>0.832332</td>\n",
       "      <td>0.868791</td>\n",
       "      <td>0.867281</td>\n",
       "      <td>0.804784</td>\n",
       "      <td>0.821912</td>\n",
       "      <td>0.834251</td>\n",
       "      <td>0.824191</td>\n",
       "      <td>0.822673</td>\n",
       "      <td>0.822702</td>\n",
       "      <td>0.825559</td>\n",
       "      <td>0.847868</td>\n",
       "      <td>0.844865</td>\n",
       "      <td>0.849669</td>\n",
       "      <td>0.846402</td>\n",
       "      <td>0.847204</td>\n",
       "      <td>0.820821</td>\n",
       "      <td>0.815321</td>\n",
       "      <td>0.696715</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>0.794808</td>\n",
       "      <td>0.848899</td>\n",
       "      <td>0.834020</td>\n",
       "      <td>0.834455</td>\n",
       "      <td>0.834031</td>\n",
       "      <td>0.831046</td>\n",
       "      <td>0.847166</td>\n",
       "      <td>0.817753</td>\n",
       "      <td>0.808287</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.768838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992530</td>\n",
       "      <td>0.895938</td>\n",
       "      <td>0.911534</td>\n",
       "      <td>0.903622</td>\n",
       "      <td>0.923028</td>\n",
       "      <td>0.952428</td>\n",
       "      <td>0.941819</td>\n",
       "      <td>0.949769</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.868349</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.875062</td>\n",
       "      <td>0.863841</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.713722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_rg</th>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.823708</td>\n",
       "      <td>0.836749</td>\n",
       "      <td>0.830028</td>\n",
       "      <td>0.822768</td>\n",
       "      <td>0.829751</td>\n",
       "      <td>0.853084</td>\n",
       "      <td>0.848887</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.854074</td>\n",
       "      <td>0.845153</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0.835086</td>\n",
       "      <td>0.870874</td>\n",
       "      <td>0.868427</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>0.824401</td>\n",
       "      <td>0.836672</td>\n",
       "      <td>0.825979</td>\n",
       "      <td>0.824458</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.827687</td>\n",
       "      <td>0.849526</td>\n",
       "      <td>0.846549</td>\n",
       "      <td>0.851503</td>\n",
       "      <td>0.848316</td>\n",
       "      <td>0.849195</td>\n",
       "      <td>0.822538</td>\n",
       "      <td>0.817191</td>\n",
       "      <td>0.703082</td>\n",
       "      <td>0.803529</td>\n",
       "      <td>0.803529</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.836236</td>\n",
       "      <td>0.838957</td>\n",
       "      <td>0.838447</td>\n",
       "      <td>0.835543</td>\n",
       "      <td>0.850304</td>\n",
       "      <td>0.820265</td>\n",
       "      <td>0.810838</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>0.789577</td>\n",
       "      <td>0.992530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890810</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>0.908041</td>\n",
       "      <td>0.918645</td>\n",
       "      <td>0.956040</td>\n",
       "      <td>0.938341</td>\n",
       "      <td>0.956755</td>\n",
       "      <td>0.921706</td>\n",
       "      <td>0.871884</td>\n",
       "      <td>0.863262</td>\n",
       "      <td>0.880309</td>\n",
       "      <td>0.859124</td>\n",
       "      <td>0.770324</td>\n",
       "      <td>0.722905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.866779</td>\n",
       "      <td>0.874204</td>\n",
       "      <td>0.867792</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>0.893489</td>\n",
       "      <td>0.896498</td>\n",
       "      <td>0.896866</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>0.897334</td>\n",
       "      <td>0.887590</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>0.866792</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.870983</td>\n",
       "      <td>0.868194</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.863948</td>\n",
       "      <td>0.867124</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.887099</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.887415</td>\n",
       "      <td>0.887269</td>\n",
       "      <td>0.865363</td>\n",
       "      <td>0.857438</td>\n",
       "      <td>0.709817</td>\n",
       "      <td>0.846260</td>\n",
       "      <td>0.846260</td>\n",
       "      <td>0.884223</td>\n",
       "      <td>0.872875</td>\n",
       "      <td>0.897684</td>\n",
       "      <td>0.897399</td>\n",
       "      <td>0.894728</td>\n",
       "      <td>0.906238</td>\n",
       "      <td>0.877434</td>\n",
       "      <td>0.866732</td>\n",
       "      <td>0.886745</td>\n",
       "      <td>0.716294</td>\n",
       "      <td>0.895938</td>\n",
       "      <td>0.890810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907552</td>\n",
       "      <td>0.911592</td>\n",
       "      <td>0.879176</td>\n",
       "      <td>0.914453</td>\n",
       "      <td>0.897046</td>\n",
       "      <td>0.916009</td>\n",
       "      <td>0.897979</td>\n",
       "      <td>0.885489</td>\n",
       "      <td>0.878420</td>\n",
       "      <td>0.892664</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.728305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.921385</td>\n",
       "      <td>0.922428</td>\n",
       "      <td>0.931922</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.922925</td>\n",
       "      <td>0.904446</td>\n",
       "      <td>0.902194</td>\n",
       "      <td>0.901531</td>\n",
       "      <td>0.896152</td>\n",
       "      <td>0.895244</td>\n",
       "      <td>0.903146</td>\n",
       "      <td>0.895948</td>\n",
       "      <td>0.921293</td>\n",
       "      <td>0.919177</td>\n",
       "      <td>0.880062</td>\n",
       "      <td>0.885836</td>\n",
       "      <td>0.935395</td>\n",
       "      <td>0.924613</td>\n",
       "      <td>0.922978</td>\n",
       "      <td>0.924469</td>\n",
       "      <td>0.927577</td>\n",
       "      <td>0.914004</td>\n",
       "      <td>0.910404</td>\n",
       "      <td>0.916381</td>\n",
       "      <td>0.913126</td>\n",
       "      <td>0.914289</td>\n",
       "      <td>0.925431</td>\n",
       "      <td>0.917079</td>\n",
       "      <td>0.753216</td>\n",
       "      <td>0.881499</td>\n",
       "      <td>0.881499</td>\n",
       "      <td>0.947720</td>\n",
       "      <td>0.932678</td>\n",
       "      <td>0.895275</td>\n",
       "      <td>0.894214</td>\n",
       "      <td>0.891733</td>\n",
       "      <td>0.900735</td>\n",
       "      <td>0.881505</td>\n",
       "      <td>0.879680</td>\n",
       "      <td>0.904824</td>\n",
       "      <td>0.773523</td>\n",
       "      <td>0.911534</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>0.907552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994529</td>\n",
       "      <td>0.880049</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.898531</td>\n",
       "      <td>0.924923</td>\n",
       "      <td>0.947094</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.854522</td>\n",
       "      <td>0.880176</td>\n",
       "      <td>0.848294</td>\n",
       "      <td>0.870954</td>\n",
       "      <td>0.779519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_411_7000_leaves</th>\n",
       "      <td>0.935732</td>\n",
       "      <td>0.937665</td>\n",
       "      <td>0.942972</td>\n",
       "      <td>0.941243</td>\n",
       "      <td>0.935721</td>\n",
       "      <td>0.934852</td>\n",
       "      <td>0.912592</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>0.910878</td>\n",
       "      <td>0.904491</td>\n",
       "      <td>0.904639</td>\n",
       "      <td>0.911783</td>\n",
       "      <td>0.908071</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>0.926004</td>\n",
       "      <td>0.893396</td>\n",
       "      <td>0.899280</td>\n",
       "      <td>0.948653</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.938183</td>\n",
       "      <td>0.937688</td>\n",
       "      <td>0.940851</td>\n",
       "      <td>0.924785</td>\n",
       "      <td>0.921047</td>\n",
       "      <td>0.927977</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.926364</td>\n",
       "      <td>0.940940</td>\n",
       "      <td>0.931035</td>\n",
       "      <td>0.760580</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.959204</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.903373</td>\n",
       "      <td>0.902575</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>0.890991</td>\n",
       "      <td>0.891077</td>\n",
       "      <td>0.898917</td>\n",
       "      <td>0.764218</td>\n",
       "      <td>0.903622</td>\n",
       "      <td>0.908041</td>\n",
       "      <td>0.911592</td>\n",
       "      <td>0.994529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876458</td>\n",
       "      <td>0.916401</td>\n",
       "      <td>0.894651</td>\n",
       "      <td>0.920632</td>\n",
       "      <td>0.942171</td>\n",
       "      <td>0.867728</td>\n",
       "      <td>0.853907</td>\n",
       "      <td>0.879102</td>\n",
       "      <td>0.847669</td>\n",
       "      <td>0.886803</td>\n",
       "      <td>0.785022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_0001</th>\n",
       "      <td>0.811904</td>\n",
       "      <td>0.813002</td>\n",
       "      <td>0.824736</td>\n",
       "      <td>0.818223</td>\n",
       "      <td>0.811344</td>\n",
       "      <td>0.821121</td>\n",
       "      <td>0.841548</td>\n",
       "      <td>0.846315</td>\n",
       "      <td>0.846989</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.835859</td>\n",
       "      <td>0.848833</td>\n",
       "      <td>0.825604</td>\n",
       "      <td>0.853381</td>\n",
       "      <td>0.852450</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.813741</td>\n",
       "      <td>0.822557</td>\n",
       "      <td>0.815271</td>\n",
       "      <td>0.813841</td>\n",
       "      <td>0.812784</td>\n",
       "      <td>0.815649</td>\n",
       "      <td>0.832539</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.833880</td>\n",
       "      <td>0.830441</td>\n",
       "      <td>0.830877</td>\n",
       "      <td>0.810176</td>\n",
       "      <td>0.805885</td>\n",
       "      <td>0.697815</td>\n",
       "      <td>0.787240</td>\n",
       "      <td>0.787240</td>\n",
       "      <td>0.836093</td>\n",
       "      <td>0.822745</td>\n",
       "      <td>0.824145</td>\n",
       "      <td>0.823576</td>\n",
       "      <td>0.820945</td>\n",
       "      <td>0.833640</td>\n",
       "      <td>0.807451</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.717921</td>\n",
       "      <td>0.923028</td>\n",
       "      <td>0.918645</td>\n",
       "      <td>0.879176</td>\n",
       "      <td>0.880049</td>\n",
       "      <td>0.876458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967830</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.957903</td>\n",
       "      <td>0.905166</td>\n",
       "      <td>0.871821</td>\n",
       "      <td>0.879716</td>\n",
       "      <td>0.874106</td>\n",
       "      <td>0.883194</td>\n",
       "      <td>0.758149</td>\n",
       "      <td>0.705350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_160</th>\n",
       "      <td>0.846438</td>\n",
       "      <td>0.847543</td>\n",
       "      <td>0.860072</td>\n",
       "      <td>0.853142</td>\n",
       "      <td>0.845992</td>\n",
       "      <td>0.856480</td>\n",
       "      <td>0.880072</td>\n",
       "      <td>0.878901</td>\n",
       "      <td>0.879539</td>\n",
       "      <td>0.877224</td>\n",
       "      <td>0.873883</td>\n",
       "      <td>0.881341</td>\n",
       "      <td>0.863308</td>\n",
       "      <td>0.891558</td>\n",
       "      <td>0.889281</td>\n",
       "      <td>0.839233</td>\n",
       "      <td>0.851746</td>\n",
       "      <td>0.858009</td>\n",
       "      <td>0.849882</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.847676</td>\n",
       "      <td>0.850684</td>\n",
       "      <td>0.868728</td>\n",
       "      <td>0.865605</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>0.867503</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>0.840286</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.872388</td>\n",
       "      <td>0.857989</td>\n",
       "      <td>0.864294</td>\n",
       "      <td>0.863698</td>\n",
       "      <td>0.860862</td>\n",
       "      <td>0.872537</td>\n",
       "      <td>0.844318</td>\n",
       "      <td>0.834788</td>\n",
       "      <td>0.914040</td>\n",
       "      <td>0.766546</td>\n",
       "      <td>0.952428</td>\n",
       "      <td>0.956040</td>\n",
       "      <td>0.914453</td>\n",
       "      <td>0.920631</td>\n",
       "      <td>0.916401</td>\n",
       "      <td>0.967830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987128</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.948172</td>\n",
       "      <td>0.908484</td>\n",
       "      <td>0.903209</td>\n",
       "      <td>0.915742</td>\n",
       "      <td>0.900263</td>\n",
       "      <td>0.788835</td>\n",
       "      <td>0.740193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_10</th>\n",
       "      <td>0.827642</td>\n",
       "      <td>0.828779</td>\n",
       "      <td>0.840884</td>\n",
       "      <td>0.834198</td>\n",
       "      <td>0.827171</td>\n",
       "      <td>0.837466</td>\n",
       "      <td>0.858496</td>\n",
       "      <td>0.860962</td>\n",
       "      <td>0.861631</td>\n",
       "      <td>0.858859</td>\n",
       "      <td>0.852646</td>\n",
       "      <td>0.863476</td>\n",
       "      <td>0.842154</td>\n",
       "      <td>0.870849</td>\n",
       "      <td>0.869725</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.830083</td>\n",
       "      <td>0.838689</td>\n",
       "      <td>0.831110</td>\n",
       "      <td>0.829625</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.831653</td>\n",
       "      <td>0.848975</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.850466</td>\n",
       "      <td>0.846931</td>\n",
       "      <td>0.847454</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>0.711790</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.852646</td>\n",
       "      <td>0.838852</td>\n",
       "      <td>0.840836</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>0.837553</td>\n",
       "      <td>0.850473</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.734738</td>\n",
       "      <td>0.941819</td>\n",
       "      <td>0.938341</td>\n",
       "      <td>0.897046</td>\n",
       "      <td>0.898531</td>\n",
       "      <td>0.894651</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.987128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978444</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.890701</td>\n",
       "      <td>0.896439</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.898729</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.719560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_320</th>\n",
       "      <td>0.850100</td>\n",
       "      <td>0.851161</td>\n",
       "      <td>0.863767</td>\n",
       "      <td>0.856787</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.859861</td>\n",
       "      <td>0.884830</td>\n",
       "      <td>0.882902</td>\n",
       "      <td>0.883506</td>\n",
       "      <td>0.881255</td>\n",
       "      <td>0.878525</td>\n",
       "      <td>0.885262</td>\n",
       "      <td>0.867993</td>\n",
       "      <td>0.895356</td>\n",
       "      <td>0.892455</td>\n",
       "      <td>0.846704</td>\n",
       "      <td>0.856936</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.853491</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.851360</td>\n",
       "      <td>0.854368</td>\n",
       "      <td>0.872565</td>\n",
       "      <td>0.869439</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>0.870755</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.848448</td>\n",
       "      <td>0.843861</td>\n",
       "      <td>0.736516</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.876225</td>\n",
       "      <td>0.861669</td>\n",
       "      <td>0.870583</td>\n",
       "      <td>0.869998</td>\n",
       "      <td>0.867146</td>\n",
       "      <td>0.877578</td>\n",
       "      <td>0.849011</td>\n",
       "      <td>0.839543</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.778527</td>\n",
       "      <td>0.949769</td>\n",
       "      <td>0.956755</td>\n",
       "      <td>0.916009</td>\n",
       "      <td>0.924923</td>\n",
       "      <td>0.920632</td>\n",
       "      <td>0.957903</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.978444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953059</td>\n",
       "      <td>0.909061</td>\n",
       "      <td>0.898929</td>\n",
       "      <td>0.919034</td>\n",
       "      <td>0.893928</td>\n",
       "      <td>0.791272</td>\n",
       "      <td>0.746015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_new_411</th>\n",
       "      <td>0.872428</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.879468</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.881965</td>\n",
       "      <td>0.875719</td>\n",
       "      <td>0.872686</td>\n",
       "      <td>0.871553</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.868102</td>\n",
       "      <td>0.874476</td>\n",
       "      <td>0.863764</td>\n",
       "      <td>0.890493</td>\n",
       "      <td>0.886403</td>\n",
       "      <td>0.852123</td>\n",
       "      <td>0.855378</td>\n",
       "      <td>0.884214</td>\n",
       "      <td>0.875844</td>\n",
       "      <td>0.874164</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.877285</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.867462</td>\n",
       "      <td>0.874235</td>\n",
       "      <td>0.871764</td>\n",
       "      <td>0.873562</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>0.866362</td>\n",
       "      <td>0.755343</td>\n",
       "      <td>0.849061</td>\n",
       "      <td>0.849061</td>\n",
       "      <td>0.899041</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.867369</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>0.863973</td>\n",
       "      <td>0.872210</td>\n",
       "      <td>0.846478</td>\n",
       "      <td>0.840113</td>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.778525</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.921706</td>\n",
       "      <td>0.897979</td>\n",
       "      <td>0.947094</td>\n",
       "      <td>0.942171</td>\n",
       "      <td>0.905166</td>\n",
       "      <td>0.948172</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.953059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872317</td>\n",
       "      <td>0.858308</td>\n",
       "      <td>0.886009</td>\n",
       "      <td>0.851865</td>\n",
       "      <td>0.815437</td>\n",
       "      <td>0.758699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_l1_05</th>\n",
       "      <td>0.811401</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.823825</td>\n",
       "      <td>0.816884</td>\n",
       "      <td>0.811378</td>\n",
       "      <td>0.821350</td>\n",
       "      <td>0.838050</td>\n",
       "      <td>0.840290</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.834829</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0.841630</td>\n",
       "      <td>0.826684</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.851668</td>\n",
       "      <td>0.799327</td>\n",
       "      <td>0.814837</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.814830</td>\n",
       "      <td>0.814072</td>\n",
       "      <td>0.812960</td>\n",
       "      <td>0.815880</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.833920</td>\n",
       "      <td>0.830167</td>\n",
       "      <td>0.830699</td>\n",
       "      <td>0.807589</td>\n",
       "      <td>0.805410</td>\n",
       "      <td>0.602618</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>0.833304</td>\n",
       "      <td>0.821529</td>\n",
       "      <td>0.831889</td>\n",
       "      <td>0.831351</td>\n",
       "      <td>0.828514</td>\n",
       "      <td>0.843599</td>\n",
       "      <td>0.819210</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.859582</td>\n",
       "      <td>0.672195</td>\n",
       "      <td>0.868349</td>\n",
       "      <td>0.871884</td>\n",
       "      <td>0.885489</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.867728</td>\n",
       "      <td>0.871821</td>\n",
       "      <td>0.908484</td>\n",
       "      <td>0.890701</td>\n",
       "      <td>0.909061</td>\n",
       "      <td>0.872317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>0.977235</td>\n",
       "      <td>0.819547</td>\n",
       "      <td>0.591173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_l1_1</th>\n",
       "      <td>0.799280</td>\n",
       "      <td>0.800982</td>\n",
       "      <td>0.811323</td>\n",
       "      <td>0.804517</td>\n",
       "      <td>0.799215</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.822719</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>0.827788</td>\n",
       "      <td>0.820828</td>\n",
       "      <td>0.817674</td>\n",
       "      <td>0.827670</td>\n",
       "      <td>0.811957</td>\n",
       "      <td>0.839089</td>\n",
       "      <td>0.839892</td>\n",
       "      <td>0.781676</td>\n",
       "      <td>0.799672</td>\n",
       "      <td>0.806717</td>\n",
       "      <td>0.802777</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.800763</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.820057</td>\n",
       "      <td>0.817291</td>\n",
       "      <td>0.821330</td>\n",
       "      <td>0.817575</td>\n",
       "      <td>0.818032</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.793460</td>\n",
       "      <td>0.591424</td>\n",
       "      <td>0.757783</td>\n",
       "      <td>0.757783</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.815955</td>\n",
       "      <td>0.815478</td>\n",
       "      <td>0.812761</td>\n",
       "      <td>0.829074</td>\n",
       "      <td>0.805552</td>\n",
       "      <td>0.795194</td>\n",
       "      <td>0.843389</td>\n",
       "      <td>0.651171</td>\n",
       "      <td>0.865318</td>\n",
       "      <td>0.863262</td>\n",
       "      <td>0.878420</td>\n",
       "      <td>0.854522</td>\n",
       "      <td>0.853907</td>\n",
       "      <td>0.879716</td>\n",
       "      <td>0.903209</td>\n",
       "      <td>0.896439</td>\n",
       "      <td>0.898929</td>\n",
       "      <td>0.858308</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>0.993113</td>\n",
       "      <td>0.808260</td>\n",
       "      <td>0.579615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_l2_01</th>\n",
       "      <td>0.821263</td>\n",
       "      <td>0.822777</td>\n",
       "      <td>0.833793</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.821176</td>\n",
       "      <td>0.830989</td>\n",
       "      <td>0.847758</td>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.850257</td>\n",
       "      <td>0.843080</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.850187</td>\n",
       "      <td>0.836491</td>\n",
       "      <td>0.861994</td>\n",
       "      <td>0.860305</td>\n",
       "      <td>0.815745</td>\n",
       "      <td>0.826084</td>\n",
       "      <td>0.829294</td>\n",
       "      <td>0.824603</td>\n",
       "      <td>0.823828</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.839354</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.839933</td>\n",
       "      <td>0.840524</td>\n",
       "      <td>0.817199</td>\n",
       "      <td>0.815044</td>\n",
       "      <td>0.612974</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>0.831460</td>\n",
       "      <td>0.845514</td>\n",
       "      <td>0.845075</td>\n",
       "      <td>0.842175</td>\n",
       "      <td>0.854190</td>\n",
       "      <td>0.829565</td>\n",
       "      <td>0.819298</td>\n",
       "      <td>0.866778</td>\n",
       "      <td>0.692946</td>\n",
       "      <td>0.875062</td>\n",
       "      <td>0.880309</td>\n",
       "      <td>0.892664</td>\n",
       "      <td>0.880176</td>\n",
       "      <td>0.879102</td>\n",
       "      <td>0.874106</td>\n",
       "      <td>0.915742</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.919034</td>\n",
       "      <td>0.886009</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>0.978720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972749</td>\n",
       "      <td>0.827777</td>\n",
       "      <td>0.602285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_l2_1</th>\n",
       "      <td>0.793754</td>\n",
       "      <td>0.795435</td>\n",
       "      <td>0.805571</td>\n",
       "      <td>0.798866</td>\n",
       "      <td>0.793686</td>\n",
       "      <td>0.804675</td>\n",
       "      <td>0.814407</td>\n",
       "      <td>0.818613</td>\n",
       "      <td>0.819961</td>\n",
       "      <td>0.813033</td>\n",
       "      <td>0.809139</td>\n",
       "      <td>0.819786</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>0.832904</td>\n",
       "      <td>0.833779</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.791992</td>\n",
       "      <td>0.801049</td>\n",
       "      <td>0.797247</td>\n",
       "      <td>0.796454</td>\n",
       "      <td>0.795230</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.814219</td>\n",
       "      <td>0.811488</td>\n",
       "      <td>0.815432</td>\n",
       "      <td>0.811707</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.790047</td>\n",
       "      <td>0.787995</td>\n",
       "      <td>0.586523</td>\n",
       "      <td>0.749147</td>\n",
       "      <td>0.749147</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.803197</td>\n",
       "      <td>0.808175</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.805075</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.798523</td>\n",
       "      <td>0.788117</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.642389</td>\n",
       "      <td>0.863841</td>\n",
       "      <td>0.859124</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.848294</td>\n",
       "      <td>0.847669</td>\n",
       "      <td>0.883194</td>\n",
       "      <td>0.900263</td>\n",
       "      <td>0.898729</td>\n",
       "      <td>0.893928</td>\n",
       "      <td>0.851865</td>\n",
       "      <td>0.977235</td>\n",
       "      <td>0.993113</td>\n",
       "      <td>0.972749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802999</td>\n",
       "      <td>0.574573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls05_lgb</th>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.945198</td>\n",
       "      <td>0.919283</td>\n",
       "      <td>0.931634</td>\n",
       "      <td>0.940242</td>\n",
       "      <td>0.919523</td>\n",
       "      <td>0.849272</td>\n",
       "      <td>0.851784</td>\n",
       "      <td>0.852166</td>\n",
       "      <td>0.842887</td>\n",
       "      <td>0.845405</td>\n",
       "      <td>0.850715</td>\n",
       "      <td>0.865770</td>\n",
       "      <td>0.862263</td>\n",
       "      <td>0.864107</td>\n",
       "      <td>0.849946</td>\n",
       "      <td>0.857522</td>\n",
       "      <td>0.932960</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.946191</td>\n",
       "      <td>0.939893</td>\n",
       "      <td>0.943051</td>\n",
       "      <td>0.878056</td>\n",
       "      <td>0.874278</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.892597</td>\n",
       "      <td>0.937390</td>\n",
       "      <td>0.931141</td>\n",
       "      <td>0.643513</td>\n",
       "      <td>0.837270</td>\n",
       "      <td>0.837270</td>\n",
       "      <td>0.928724</td>\n",
       "      <td>0.927639</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.842070</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.842529</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.866651</td>\n",
       "      <td>0.773886</td>\n",
       "      <td>0.617066</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.770324</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.870954</td>\n",
       "      <td>0.886803</td>\n",
       "      <td>0.758149</td>\n",
       "      <td>0.788835</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.791272</td>\n",
       "      <td>0.815437</td>\n",
       "      <td>0.819547</td>\n",
       "      <td>0.808260</td>\n",
       "      <td>0.827777</td>\n",
       "      <td>0.802999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.634385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls0_lgb</th>\n",
       "      <td>0.785823</td>\n",
       "      <td>0.788349</td>\n",
       "      <td>0.781393</td>\n",
       "      <td>0.782935</td>\n",
       "      <td>0.785084</td>\n",
       "      <td>0.779242</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>0.752769</td>\n",
       "      <td>0.752736</td>\n",
       "      <td>0.752974</td>\n",
       "      <td>0.749832</td>\n",
       "      <td>0.753346</td>\n",
       "      <td>0.752856</td>\n",
       "      <td>0.758297</td>\n",
       "      <td>0.756379</td>\n",
       "      <td>0.750064</td>\n",
       "      <td>0.748902</td>\n",
       "      <td>0.794906</td>\n",
       "      <td>0.790416</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>0.786246</td>\n",
       "      <td>0.789149</td>\n",
       "      <td>0.766178</td>\n",
       "      <td>0.762278</td>\n",
       "      <td>0.768238</td>\n",
       "      <td>0.768521</td>\n",
       "      <td>0.769703</td>\n",
       "      <td>0.790083</td>\n",
       "      <td>0.780367</td>\n",
       "      <td>0.880291</td>\n",
       "      <td>0.760855</td>\n",
       "      <td>0.760855</td>\n",
       "      <td>0.791433</td>\n",
       "      <td>0.783187</td>\n",
       "      <td>0.748887</td>\n",
       "      <td>0.747406</td>\n",
       "      <td>0.748642</td>\n",
       "      <td>0.743855</td>\n",
       "      <td>0.727658</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>0.712138</td>\n",
       "      <td>0.661407</td>\n",
       "      <td>0.713722</td>\n",
       "      <td>0.722905</td>\n",
       "      <td>0.728305</td>\n",
       "      <td>0.779519</td>\n",
       "      <td>0.785022</td>\n",
       "      <td>0.705350</td>\n",
       "      <td>0.740193</td>\n",
       "      <td>0.719560</td>\n",
       "      <td>0.746015</td>\n",
       "      <td>0.758699</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.579615</td>\n",
       "      <td>0.602285</td>\n",
       "      <td>0.574573</td>\n",
       "      <td>0.634385</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    xentropy_add_lotsof_image_features_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                            1.000000   \n",
       "lgb411_tune                                                                       0.987515   \n",
       "plants_lgb                                                                        0.962282   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                       0.971707   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                                0.979859   \n",
       "xentropy_small_lr_cat_lgb                                                         0.963546   \n",
       "simple_feature_lgb                                                                0.902607   \n",
       "all_mean_enc_lgb                                                                  0.904278   \n",
       "all_mean_enc_user_feat_lgb                                                        0.904221   \n",
       "all_mean_enc_user_feat2_lgb                                                       0.896114   \n",
       "cat_interact_lgb                                                                  0.898852   \n",
       "mean_enc_lgb                                                                      0.903478   \n",
       "marcus_lgb                                                                        0.915897   \n",
       "fused_text_lgb                                                                    0.912013   \n",
       "mixed_features_text_proprocessing_lgb                                             0.913005   \n",
       "select_dense_features_lgb                                                         0.902741   \n",
       "select_sparse_features_lgb                                                        0.908337   \n",
       "lgb411_dart_tune                                                                  0.976410   \n",
       "lgb411_goss_tune                                                                  0.986276   \n",
       "lgb411_goss_tune2                                                                 0.988411   \n",
       "poisson_lgb                                                                       0.979855   \n",
       "poisson_small_lr_lgb                                                              0.983149   \n",
       "small_features_v5_xgb                                                             0.926844   \n",
       "small_features_v4_xgb                                                             0.922592   \n",
       "nima_features_xgb                                                                 0.931074   \n",
       "img_meta_xgb                                                                      0.936005   \n",
       "img_meta_nima_xgb                                                                 0.938847   \n",
       "xgb_new                                                                           0.980519   \n",
       "baseline_xgb                                                                      0.971096   \n",
       "ranking_xgb                                                                       0.765870   \n",
       "catboost                                                                          0.893589   \n",
       "catboost1_without_text                                                            0.893589   \n",
       "mcl_cgb                                                                           0.972385   \n",
       "cgb_with_categorical                                                              0.970223   \n",
       "pretrained_bigru_cv1d_rnn                                                         0.892459   \n",
       "pretrained_bigru_attention_rnn                                                    0.891782   \n",
       "pretrained_2gru_rnn                                                               0.889217   \n",
       "selftrained_bigru_conv1d_rnn                                                      0.891598   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                    0.900249   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                                0.915566   \n",
       "text_lgb                                                                          0.822430   \n",
       "text_cwb_rg                                                                       0.685411   \n",
       "text_fm                                                                           0.821406   \n",
       "text_rg                                                                           0.823256   \n",
       "mlp                                                                               0.864836   \n",
       "rf                                                                                0.921385   \n",
       "rf_411_7000_leaves                                                                0.935732   \n",
       "alpha_0001                                                                        0.811904   \n",
       "alpha_160                                                                         0.846438   \n",
       "alpha_10                                                                          0.827642   \n",
       "alpha_320                                                                         0.850100   \n",
       "ridge_new_411                                                                     0.872428   \n",
       "lr_l1_05                                                                          0.811401   \n",
       "lr_l1_1                                                                           0.799280   \n",
       "lr_l2_01                                                                          0.821263   \n",
       "lr_l2_1                                                                           0.793754   \n",
       "cls05_lgb                                                                         0.938616   \n",
       "cls0_lgb                                                                          0.785823   \n",
       "\n",
       "                                                    lgb411_tune  plants_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                 0.987515    0.962282   \n",
       "lgb411_tune                                            1.000000    0.967159   \n",
       "plants_lgb                                             0.967159    1.000000   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb            0.976990    0.968862   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...     0.986189    0.963568   \n",
       "xentropy_small_lr_cat_lgb                              0.967743    0.951730   \n",
       "simple_feature_lgb                                     0.905456    0.911633   \n",
       "all_mean_enc_lgb                                       0.907395    0.912456   \n",
       "all_mean_enc_user_feat_lgb                             0.907480    0.912490   \n",
       "all_mean_enc_user_feat2_lgb                            0.899326    0.904745   \n",
       "cat_interact_lgb                                       0.902366    0.907654   \n",
       "mean_enc_lgb                                           0.906453    0.912110   \n",
       "marcus_lgb                                             0.919712    0.914469   \n",
       "fused_text_lgb                                         0.914794    0.921208   \n",
       "mixed_features_text_proprocessing_lgb                  0.915861    0.921965   \n",
       "select_dense_features_lgb                              0.906655    0.896150   \n",
       "select_sparse_features_lgb                             0.912361    0.902178   \n",
       "lgb411_dart_tune                                       0.982080    0.966236   \n",
       "lgb411_goss_tune                                       0.994217    0.968448   \n",
       "lgb411_goss_tune2                                      0.996717    0.967875   \n",
       "poisson_lgb                                            0.985545    0.963319   \n",
       "poisson_small_lr_lgb                                   0.988986    0.966409   \n",
       "small_features_v5_xgb                                  0.931473    0.931010   \n",
       "small_features_v4_xgb                                  0.927126    0.926905   \n",
       "nima_features_xgb                                      0.935678    0.930084   \n",
       "img_meta_xgb                                           0.940697    0.925493   \n",
       "img_meta_nima_xgb                                      0.943550    0.924579   \n",
       "xgb_new                                                0.987608    0.962428   \n",
       "baseline_xgb                                           0.977573    0.955797   \n",
       "ranking_xgb                                            0.769518    0.765113   \n",
       "catboost                                               0.896485    0.890247   \n",
       "catboost1_without_text                                 0.896485    0.890247   \n",
       "mcl_cgb                                                0.976032    0.969725   \n",
       "cgb_with_categorical                                   0.974701    0.964663   \n",
       "pretrained_bigru_cv1d_rnn                              0.895204    0.897465   \n",
       "pretrained_bigru_attention_rnn                         0.894450    0.896696   \n",
       "pretrained_2gru_rnn                                    0.891942    0.894225   \n",
       "selftrained_bigru_conv1d_rnn                           0.894094    0.897245   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn         0.896064    0.892095   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn     0.912031    0.903323   \n",
       "text_lgb                                               0.823135    0.835321   \n",
       "text_cwb_rg                                            0.685161    0.695687   \n",
       "text_fm                                                0.821971    0.834781   \n",
       "text_rg                                                0.823708    0.836749   \n",
       "mlp                                                    0.866779    0.874204   \n",
       "rf                                                     0.922428    0.931922   \n",
       "rf_411_7000_leaves                                     0.937665    0.942972   \n",
       "alpha_0001                                             0.813002    0.824736   \n",
       "alpha_160                                              0.847543    0.860072   \n",
       "alpha_10                                               0.828779    0.840884   \n",
       "alpha_320                                              0.851161    0.863767   \n",
       "ridge_new_411                                          0.873289    0.880408   \n",
       "lr_l1_05                                               0.813043    0.823825   \n",
       "lr_l1_1                                                0.800982    0.811323   \n",
       "lr_l2_01                                               0.822777    0.833793   \n",
       "lr_l2_1                                                0.795435    0.805571   \n",
       "cls05_lgb                                              0.945198    0.919283   \n",
       "cls0_lgb                                               0.788349    0.781393   \n",
       "\n",
       "                                                    plants_with_img_meta_nima_fm_geo_active_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                                 0.971707   \n",
       "lgb411_tune                                                                            0.976990   \n",
       "plants_lgb                                                                             0.968862   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                            1.000000   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                                     0.973449   \n",
       "xentropy_small_lr_cat_lgb                                                              0.957623   \n",
       "simple_feature_lgb                                                                     0.904752   \n",
       "all_mean_enc_lgb                                                                       0.906086   \n",
       "all_mean_enc_user_feat_lgb                                                             0.906017   \n",
       "all_mean_enc_user_feat2_lgb                                                            0.898062   \n",
       "cat_interact_lgb                                                                       0.900886   \n",
       "mean_enc_lgb                                                                           0.905318   \n",
       "marcus_lgb                                                                             0.915583   \n",
       "fused_text_lgb                                                                         0.914908   \n",
       "mixed_features_text_proprocessing_lgb                                                  0.915626   \n",
       "select_dense_features_lgb                                                              0.901881   \n",
       "select_sparse_features_lgb                                                             0.907734   \n",
       "lgb411_dart_tune                                                                       0.972245   \n",
       "lgb411_goss_tune                                                                       0.977728   \n",
       "lgb411_goss_tune2                                                                      0.977729   \n",
       "poisson_lgb                                                                            0.972814   \n",
       "poisson_small_lr_lgb                                                                   0.976023   \n",
       "small_features_v5_xgb                                                                  0.924954   \n",
       "small_features_v4_xgb                                                                  0.920816   \n",
       "nima_features_xgb                                                                      0.928658   \n",
       "img_meta_xgb                                                                           0.931048   \n",
       "img_meta_nima_xgb                                                                      0.933453   \n",
       "xgb_new                                                                                0.971450   \n",
       "baseline_xgb                                                                           0.964709   \n",
       "ranking_xgb                                                                            0.768467   \n",
       "catboost                                                                               0.894999   \n",
       "catboost1_without_text                                                                 0.894999   \n",
       "mcl_cgb                                                                                0.976016   \n",
       "cgb_with_categorical                                                                   0.972276   \n",
       "pretrained_bigru_cv1d_rnn                                                              0.891990   \n",
       "pretrained_bigru_attention_rnn                                                         0.891134   \n",
       "pretrained_2gru_rnn                                                                    0.888897   \n",
       "selftrained_bigru_conv1d_rnn                                                           0.891522   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                         0.891001   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                                     0.904735   \n",
       "text_lgb                                                                               0.828427   \n",
       "text_cwb_rg                                                                            0.690939   \n",
       "text_fm                                                                                0.827950   \n",
       "text_rg                                                                                0.830028   \n",
       "mlp                                                                                    0.867792   \n",
       "rf                                                                                     0.927867   \n",
       "rf_411_7000_leaves                                                                     0.941243   \n",
       "alpha_0001                                                                             0.818223   \n",
       "alpha_160                                                                              0.853142   \n",
       "alpha_10                                                                               0.834198   \n",
       "alpha_320                                                                              0.856787   \n",
       "ridge_new_411                                                                          0.879468   \n",
       "lr_l1_05                                                                               0.816884   \n",
       "lr_l1_1                                                                                0.804517   \n",
       "lr_l2_01                                                                               0.826794   \n",
       "lr_l2_1                                                                                0.798866   \n",
       "cls05_lgb                                                                              0.931634   \n",
       "cls0_lgb                                                                               0.782935   \n",
       "\n",
       "                                                    plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                                       0.979859          \n",
       "lgb411_tune                                                                                  0.986189          \n",
       "plants_lgb                                                                                   0.963568          \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                                  0.973449          \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                                           1.000000          \n",
       "xentropy_small_lr_cat_lgb                                                                    0.962748          \n",
       "simple_feature_lgb                                                                           0.900203          \n",
       "all_mean_enc_lgb                                                                             0.901806          \n",
       "all_mean_enc_user_feat_lgb                                                                   0.901888          \n",
       "all_mean_enc_user_feat2_lgb                                                                  0.893871          \n",
       "cat_interact_lgb                                                                             0.896375          \n",
       "mean_enc_lgb                                                                                 0.900974          \n",
       "marcus_lgb                                                                                   0.912759          \n",
       "fused_text_lgb                                                                               0.910385          \n",
       "mixed_features_text_proprocessing_lgb                                                        0.911364          \n",
       "select_dense_features_lgb                                                                    0.899385          \n",
       "select_sparse_features_lgb                                                                   0.905112          \n",
       "lgb411_dart_tune                                                                             0.976626          \n",
       "lgb411_goss_tune                                                                             0.985737          \n",
       "lgb411_goss_tune2                                                                            0.986809          \n",
       "poisson_lgb                                                                                  0.982530          \n",
       "poisson_small_lr_lgb                                                                         0.985805          \n",
       "small_features_v5_xgb                                                                        0.925209          \n",
       "small_features_v4_xgb                                                                        0.920967          \n",
       "nima_features_xgb                                                                            0.929248          \n",
       "img_meta_xgb                                                                                 0.933461          \n",
       "img_meta_nima_xgb                                                                            0.936151          \n",
       "xgb_new                                                                                      0.979641          \n",
       "baseline_xgb                                                                                 0.972157          \n",
       "ranking_xgb                                                                                  0.766018          \n",
       "catboost                                                                                     0.891253          \n",
       "catboost1_without_text                                                                       0.891253          \n",
       "mcl_cgb                                                                                      0.971611          \n",
       "cgb_with_categorical                                                                         0.968867          \n",
       "pretrained_bigru_cv1d_rnn                                                                    0.890066          \n",
       "pretrained_bigru_attention_rnn                                                               0.889372          \n",
       "pretrained_2gru_rnn                                                                          0.886792          \n",
       "selftrained_bigru_conv1d_rnn                                                                 0.889311          \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                               0.890608          \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                                           0.906435          \n",
       "text_lgb                                                                                     0.821424          \n",
       "text_cwb_rg                                                                                  0.684999          \n",
       "text_fm                                                                                      0.820779          \n",
       "text_rg                                                                                      0.822768          \n",
       "mlp                                                                                          0.862835          \n",
       "rf                                                                                           0.921629          \n",
       "rf_411_7000_leaves                                                                           0.935721          \n",
       "alpha_0001                                                                                   0.811344          \n",
       "alpha_160                                                                                    0.845992          \n",
       "alpha_10                                                                                     0.827171          \n",
       "alpha_320                                                                                    0.849634          \n",
       "ridge_new_411                                                                                0.872109          \n",
       "lr_l1_05                                                                                     0.811378          \n",
       "lr_l1_1                                                                                      0.799215          \n",
       "lr_l2_01                                                                                     0.821176          \n",
       "lr_l2_1                                                                                      0.793686          \n",
       "cls05_lgb                                                                                    0.940242          \n",
       "cls0_lgb                                                                                     0.785084          \n",
       "\n",
       "                                                    xentropy_small_lr_cat_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                               0.963546   \n",
       "lgb411_tune                                                          0.967743   \n",
       "plants_lgb                                                           0.951730   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                          0.957623   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                   0.962748   \n",
       "xentropy_small_lr_cat_lgb                                            1.000000   \n",
       "simple_feature_lgb                                                   0.914189   \n",
       "all_mean_enc_lgb                                                     0.917104   \n",
       "all_mean_enc_user_feat_lgb                                           0.916845   \n",
       "all_mean_enc_user_feat2_lgb                                          0.907965   \n",
       "cat_interact_lgb                                                     0.911571   \n",
       "mean_enc_lgb                                                         0.916972   \n",
       "marcus_lgb                                                           0.932491   \n",
       "fused_text_lgb                                                       0.925647   \n",
       "mixed_features_text_proprocessing_lgb                                0.925489   \n",
       "select_dense_features_lgb                                            0.919620   \n",
       "select_sparse_features_lgb                                           0.924598   \n",
       "lgb411_dart_tune                                                     0.963631   \n",
       "lgb411_goss_tune                                                     0.968035   \n",
       "lgb411_goss_tune2                                                    0.968451   \n",
       "poisson_lgb                                                          0.964006   \n",
       "poisson_small_lr_lgb                                                 0.967339   \n",
       "small_features_v5_xgb                                                0.923585   \n",
       "small_features_v4_xgb                                                0.919470   \n",
       "nima_features_xgb                                                    0.926771   \n",
       "img_meta_xgb                                                         0.928518   \n",
       "img_meta_nima_xgb                                                    0.930603   \n",
       "xgb_new                                                              0.963888   \n",
       "baseline_xgb                                                         0.954971   \n",
       "ranking_xgb                                                          0.758656   \n",
       "catboost                                                             0.888887   \n",
       "catboost1_without_text                                               0.888887   \n",
       "mcl_cgb                                                              0.961636   \n",
       "cgb_with_categorical                                                 0.956116   \n",
       "pretrained_bigru_cv1d_rnn                                            0.901173   \n",
       "pretrained_bigru_attention_rnn                                       0.900185   \n",
       "pretrained_2gru_rnn                                                  0.897477   \n",
       "selftrained_bigru_conv1d_rnn                                         0.899517   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                       0.900388   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                   0.912177   \n",
       "text_lgb                                                             0.827092   \n",
       "text_cwb_rg                                                          0.686990   \n",
       "text_fm                                                              0.827854   \n",
       "text_rg                                                              0.829751   \n",
       "mlp                                                                  0.872978   \n",
       "rf                                                                   0.922925   \n",
       "rf_411_7000_leaves                                                   0.934852   \n",
       "alpha_0001                                                           0.821121   \n",
       "alpha_160                                                            0.856480   \n",
       "alpha_10                                                             0.837466   \n",
       "alpha_320                                                            0.859861   \n",
       "ridge_new_411                                                        0.881965   \n",
       "lr_l1_05                                                             0.821350   \n",
       "lr_l1_1                                                              0.810223   \n",
       "lr_l2_01                                                             0.830989   \n",
       "lr_l2_1                                                              0.804675   \n",
       "cls05_lgb                                                            0.919523   \n",
       "cls0_lgb                                                             0.779242   \n",
       "\n",
       "                                                    simple_feature_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                        0.902607   \n",
       "lgb411_tune                                                   0.905456   \n",
       "plants_lgb                                                    0.911633   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                   0.904752   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...            0.900203   \n",
       "xentropy_small_lr_cat_lgb                                     0.914189   \n",
       "simple_feature_lgb                                            1.000000   \n",
       "all_mean_enc_lgb                                              0.968871   \n",
       "all_mean_enc_user_feat_lgb                                    0.967921   \n",
       "all_mean_enc_user_feat2_lgb                                   0.957815   \n",
       "cat_interact_lgb                                              0.966615   \n",
       "mean_enc_lgb                                                  0.971213   \n",
       "marcus_lgb                                                    0.956146   \n",
       "fused_text_lgb                                                0.936530   \n",
       "mixed_features_text_proprocessing_lgb                         0.939173   \n",
       "select_dense_features_lgb                                     0.933709   \n",
       "select_sparse_features_lgb                                    0.945776   \n",
       "lgb411_dart_tune                                              0.908589   \n",
       "lgb411_goss_tune                                              0.906396   \n",
       "lgb411_goss_tune2                                             0.906203   \n",
       "poisson_lgb                                                   0.900190   \n",
       "poisson_small_lr_lgb                                          0.903216   \n",
       "small_features_v5_xgb                                         0.922071   \n",
       "small_features_v4_xgb                                         0.918064   \n",
       "nima_features_xgb                                             0.921465   \n",
       "img_meta_xgb                                                  0.916744   \n",
       "img_meta_nima_xgb                                             0.916079   \n",
       "xgb_new                                                       0.902595   \n",
       "baseline_xgb                                                  0.893908   \n",
       "ranking_xgb                                                   0.738648   \n",
       "catboost                                                      0.902593   \n",
       "catboost1_without_text                                        0.902593   \n",
       "mcl_cgb                                                       0.918213   \n",
       "cgb_with_categorical                                          0.907633   \n",
       "pretrained_bigru_cv1d_rnn                                     0.919504   \n",
       "pretrained_bigru_attention_rnn                                0.918586   \n",
       "pretrained_2gru_rnn                                           0.916392   \n",
       "selftrained_bigru_conv1d_rnn                                  0.914868   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                0.907114   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn            0.898792   \n",
       "text_lgb                                                      0.869182   \n",
       "text_cwb_rg                                                   0.716797   \n",
       "text_fm                                                       0.849560   \n",
       "text_rg                                                       0.853084   \n",
       "mlp                                                           0.893489   \n",
       "rf                                                            0.904446   \n",
       "rf_411_7000_leaves                                            0.912592   \n",
       "alpha_0001                                                    0.841548   \n",
       "alpha_160                                                     0.880072   \n",
       "alpha_10                                                      0.858496   \n",
       "alpha_320                                                     0.884830   \n",
       "ridge_new_411                                                 0.875719   \n",
       "lr_l1_05                                                      0.838050   \n",
       "lr_l1_1                                                       0.822719   \n",
       "lr_l2_01                                                      0.847758   \n",
       "lr_l2_1                                                       0.814407   \n",
       "cls05_lgb                                                     0.849272   \n",
       "cls0_lgb                                                      0.754601   \n",
       "\n",
       "                                                    all_mean_enc_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                      0.904278   \n",
       "lgb411_tune                                                 0.907395   \n",
       "plants_lgb                                                  0.912456   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                 0.906086   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...          0.901806   \n",
       "xentropy_small_lr_cat_lgb                                   0.917104   \n",
       "simple_feature_lgb                                          0.968871   \n",
       "all_mean_enc_lgb                                            1.000000   \n",
       "all_mean_enc_user_feat_lgb                                  0.993119   \n",
       "all_mean_enc_user_feat2_lgb                                 0.979055   \n",
       "cat_interact_lgb                                            0.973705   \n",
       "mean_enc_lgb                                                0.989717   \n",
       "marcus_lgb                                                  0.963624   \n",
       "fused_text_lgb                                              0.939821   \n",
       "mixed_features_text_proprocessing_lgb                       0.943974   \n",
       "select_dense_features_lgb                                   0.939846   \n",
       "select_sparse_features_lgb                                  0.953933   \n",
       "lgb411_dart_tune                                            0.909640   \n",
       "lgb411_goss_tune                                            0.908318   \n",
       "lgb411_goss_tune2                                           0.908056   \n",
       "poisson_lgb                                                 0.901865   \n",
       "poisson_small_lr_lgb                                        0.904927   \n",
       "small_features_v5_xgb                                       0.925226   \n",
       "small_features_v4_xgb                                       0.921064   \n",
       "nima_features_xgb                                           0.924221   \n",
       "img_meta_xgb                                                0.919339   \n",
       "img_meta_nima_xgb                                           0.918438   \n",
       "xgb_new                                                     0.904700   \n",
       "baseline_xgb                                                0.895836   \n",
       "ranking_xgb                                                 0.737372   \n",
       "catboost                                                    0.903455   \n",
       "catboost1_without_text                                      0.903455   \n",
       "mcl_cgb                                                     0.918551   \n",
       "cgb_with_categorical                                        0.908791   \n",
       "pretrained_bigru_cv1d_rnn                                   0.922844   \n",
       "pretrained_bigru_attention_rnn                              0.921886   \n",
       "pretrained_2gru_rnn                                         0.919655   \n",
       "selftrained_bigru_conv1d_rnn                                0.917843   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn              0.910287   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn          0.901655   \n",
       "text_lgb                                                    0.866855   \n",
       "text_cwb_rg                                                 0.710733   \n",
       "text_fm                                                     0.846129   \n",
       "text_rg                                                     0.848887   \n",
       "mlp                                                         0.896498   \n",
       "rf                                                          0.902194   \n",
       "rf_411_7000_leaves                                          0.911263   \n",
       "alpha_0001                                                  0.846315   \n",
       "alpha_160                                                   0.878901   \n",
       "alpha_10                                                    0.860962   \n",
       "alpha_320                                                   0.882902   \n",
       "ridge_new_411                                               0.872686   \n",
       "lr_l1_05                                                    0.840290   \n",
       "lr_l1_1                                                     0.826367   \n",
       "lr_l2_01                                                    0.848981   \n",
       "lr_l2_1                                                     0.818613   \n",
       "cls05_lgb                                                   0.851784   \n",
       "cls0_lgb                                                    0.752769   \n",
       "\n",
       "                                                    all_mean_enc_user_feat_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                0.904221   \n",
       "lgb411_tune                                                           0.907480   \n",
       "plants_lgb                                                            0.912490   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                           0.906017   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                    0.901888   \n",
       "xentropy_small_lr_cat_lgb                                             0.916845   \n",
       "simple_feature_lgb                                                    0.967921   \n",
       "all_mean_enc_lgb                                                      0.993119   \n",
       "all_mean_enc_user_feat_lgb                                            1.000000   \n",
       "all_mean_enc_user_feat2_lgb                                           0.980549   \n",
       "cat_interact_lgb                                                      0.972853   \n",
       "mean_enc_lgb                                                          0.988447   \n",
       "marcus_lgb                                                            0.962874   \n",
       "fused_text_lgb                                                        0.940541   \n",
       "mixed_features_text_proprocessing_lgb                                 0.944687   \n",
       "select_dense_features_lgb                                             0.939407   \n",
       "select_sparse_features_lgb                                            0.953526   \n",
       "lgb411_dart_tune                                                      0.909536   \n",
       "lgb411_goss_tune                                                      0.908428   \n",
       "lgb411_goss_tune2                                                     0.908123   \n",
       "poisson_lgb                                                           0.901898   \n",
       "poisson_small_lr_lgb                                                  0.904942   \n",
       "small_features_v5_xgb                                                 0.925803   \n",
       "small_features_v4_xgb                                                 0.921642   \n",
       "nima_features_xgb                                                     0.924791   \n",
       "img_meta_xgb                                                          0.919893   \n",
       "img_meta_nima_xgb                                                     0.919009   \n",
       "xgb_new                                                               0.904701   \n",
       "baseline_xgb                                                          0.895842   \n",
       "ranking_xgb                                                           0.737337   \n",
       "catboost                                                              0.902602   \n",
       "catboost1_without_text                                                0.902602   \n",
       "mcl_cgb                                                               0.918047   \n",
       "cgb_with_categorical                                                  0.908494   \n",
       "pretrained_bigru_cv1d_rnn                                             0.921836   \n",
       "pretrained_bigru_attention_rnn                                        0.920802   \n",
       "pretrained_2gru_rnn                                                   0.918679   \n",
       "selftrained_bigru_conv1d_rnn                                          0.916663   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                        0.909152   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                    0.900557   \n",
       "text_lgb                                                              0.865516   \n",
       "text_cwb_rg                                                           0.709698   \n",
       "text_fm                                                               0.844977   \n",
       "text_rg                                                               0.847646   \n",
       "mlp                                                                   0.896866   \n",
       "rf                                                                    0.901531   \n",
       "rf_411_7000_leaves                                                    0.910878   \n",
       "alpha_0001                                                            0.846989   \n",
       "alpha_160                                                             0.879539   \n",
       "alpha_10                                                              0.861631   \n",
       "alpha_320                                                             0.883506   \n",
       "ridge_new_411                                                         0.871553   \n",
       "lr_l1_05                                                              0.841827   \n",
       "lr_l1_1                                                               0.827788   \n",
       "lr_l2_01                                                              0.850257   \n",
       "lr_l2_1                                                               0.819961   \n",
       "cls05_lgb                                                             0.852166   \n",
       "cls0_lgb                                                              0.752736   \n",
       "\n",
       "                                                    all_mean_enc_user_feat2_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                 0.896114   \n",
       "lgb411_tune                                                            0.899326   \n",
       "plants_lgb                                                             0.904745   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                            0.898062   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                     0.893871   \n",
       "xentropy_small_lr_cat_lgb                                              0.907965   \n",
       "simple_feature_lgb                                                     0.957815   \n",
       "all_mean_enc_lgb                                                       0.979055   \n",
       "all_mean_enc_user_feat_lgb                                             0.980549   \n",
       "all_mean_enc_user_feat2_lgb                                            1.000000   \n",
       "cat_interact_lgb                                                       0.962162   \n",
       "mean_enc_lgb                                                           0.974986   \n",
       "marcus_lgb                                                             0.951025   \n",
       "fused_text_lgb                                                         0.932428   \n",
       "mixed_features_text_proprocessing_lgb                                  0.936438   \n",
       "select_dense_features_lgb                                              0.928221   \n",
       "select_sparse_features_lgb                                             0.942182   \n",
       "lgb411_dart_tune                                                       0.902085   \n",
       "lgb411_goss_tune                                                       0.900287   \n",
       "lgb411_goss_tune2                                                      0.899951   \n",
       "poisson_lgb                                                            0.893906   \n",
       "poisson_small_lr_lgb                                                   0.896952   \n",
       "small_features_v5_xgb                                                  0.917543   \n",
       "small_features_v4_xgb                                                  0.913503   \n",
       "nima_features_xgb                                                      0.916518   \n",
       "img_meta_xgb                                                           0.911642   \n",
       "img_meta_nima_xgb                                                      0.910830   \n",
       "xgb_new                                                                0.896645   \n",
       "baseline_xgb                                                           0.887875   \n",
       "ranking_xgb                                                            0.737129   \n",
       "catboost                                                               0.892868   \n",
       "catboost1_without_text                                                 0.892868   \n",
       "mcl_cgb                                                                0.910381   \n",
       "cgb_with_categorical                                                   0.900400   \n",
       "pretrained_bigru_cv1d_rnn                                              0.914385   \n",
       "pretrained_bigru_attention_rnn                                         0.913422   \n",
       "pretrained_2gru_rnn                                                    0.911270   \n",
       "selftrained_bigru_conv1d_rnn                                           0.909777   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                         0.900854   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                     0.893011   \n",
       "text_lgb                                                               0.871939   \n",
       "text_cwb_rg                                                            0.715363   \n",
       "text_fm                                                                0.851349   \n",
       "text_rg                                                                0.854074   \n",
       "mlp                                                                    0.891481   \n",
       "rf                                                                     0.896152   \n",
       "rf_411_7000_leaves                                                     0.904491   \n",
       "alpha_0001                                                             0.843902   \n",
       "alpha_160                                                              0.877224   \n",
       "alpha_10                                                               0.858859   \n",
       "alpha_320                                                              0.881255   \n",
       "ridge_new_411                                                          0.867521   \n",
       "lr_l1_05                                                               0.834829   \n",
       "lr_l1_1                                                                0.820828   \n",
       "lr_l2_01                                                               0.843080   \n",
       "lr_l2_1                                                                0.813033   \n",
       "cls05_lgb                                                              0.842887   \n",
       "cls0_lgb                                                               0.752974   \n",
       "\n",
       "                                                    cat_interact_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                      0.898852   \n",
       "lgb411_tune                                                 0.902366   \n",
       "plants_lgb                                                  0.907654   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                 0.900886   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...          0.896375   \n",
       "xentropy_small_lr_cat_lgb                                   0.911571   \n",
       "simple_feature_lgb                                          0.966615   \n",
       "all_mean_enc_lgb                                            0.973705   \n",
       "all_mean_enc_user_feat_lgb                                  0.972853   \n",
       "all_mean_enc_user_feat2_lgb                                 0.962162   \n",
       "cat_interact_lgb                                            1.000000   \n",
       "mean_enc_lgb                                                0.976066   \n",
       "marcus_lgb                                                  0.960817   \n",
       "fused_text_lgb                                              0.933094   \n",
       "mixed_features_text_proprocessing_lgb                       0.936761   \n",
       "select_dense_features_lgb                                   0.937580   \n",
       "select_sparse_features_lgb                                  0.950516   \n",
       "lgb411_dart_tune                                            0.903797   \n",
       "lgb411_goss_tune                                            0.903149   \n",
       "lgb411_goss_tune2                                           0.902947   \n",
       "poisson_lgb                                                 0.895902   \n",
       "poisson_small_lr_lgb                                        0.898981   \n",
       "small_features_v5_xgb                                       0.920951   \n",
       "small_features_v4_xgb                                       0.916776   \n",
       "nima_features_xgb                                           0.919459   \n",
       "img_meta_xgb                                                0.914348   \n",
       "img_meta_nima_xgb                                           0.913160   \n",
       "xgb_new                                                     0.899476   \n",
       "baseline_xgb                                                0.890089   \n",
       "ranking_xgb                                                 0.734428   \n",
       "catboost                                                    0.902092   \n",
       "catboost1_without_text                                      0.902092   \n",
       "mcl_cgb                                                     0.913036   \n",
       "cgb_with_categorical                                        0.903939   \n",
       "pretrained_bigru_cv1d_rnn                                   0.916719   \n",
       "pretrained_bigru_attention_rnn                              0.915921   \n",
       "pretrained_2gru_rnn                                         0.913904   \n",
       "selftrained_bigru_conv1d_rnn                                0.910945   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn              0.904098   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn          0.895602   \n",
       "text_lgb                                                    0.862606   \n",
       "text_cwb_rg                                                 0.710778   \n",
       "text_fm                                                     0.841915   \n",
       "text_rg                                                     0.845153   \n",
       "mlp                                                         0.891943   \n",
       "rf                                                          0.895244   \n",
       "rf_411_7000_leaves                                          0.904639   \n",
       "alpha_0001                                                  0.835859   \n",
       "alpha_160                                                   0.873883   \n",
       "alpha_10                                                    0.852646   \n",
       "alpha_320                                                   0.878525   \n",
       "ridge_new_411                                               0.868102   \n",
       "lr_l1_05                                                    0.832751   \n",
       "lr_l1_1                                                     0.817674   \n",
       "lr_l2_01                                                    0.841905   \n",
       "lr_l2_1                                                     0.809139   \n",
       "cls05_lgb                                                   0.845405   \n",
       "cls0_lgb                                                    0.749832   \n",
       "\n",
       "                                                    mean_enc_lgb  marcus_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                  0.903478    0.915897   \n",
       "lgb411_tune                                             0.906453    0.919712   \n",
       "plants_lgb                                              0.912110    0.914469   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb             0.905318    0.915583   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...      0.900974    0.912759   \n",
       "xentropy_small_lr_cat_lgb                               0.916972    0.932491   \n",
       "simple_feature_lgb                                      0.971213    0.956146   \n",
       "all_mean_enc_lgb                                        0.989717    0.963624   \n",
       "all_mean_enc_user_feat_lgb                              0.988447    0.962874   \n",
       "all_mean_enc_user_feat2_lgb                             0.974986    0.951025   \n",
       "cat_interact_lgb                                        0.976066    0.960817   \n",
       "mean_enc_lgb                                            1.000000    0.962645   \n",
       "marcus_lgb                                              0.962645    1.000000   \n",
       "fused_text_lgb                                          0.938839    0.942398   \n",
       "mixed_features_text_proprocessing_lgb                   0.943108    0.944862   \n",
       "select_dense_features_lgb                               0.937892    0.960118   \n",
       "select_sparse_features_lgb                              0.952404    0.975061   \n",
       "lgb411_dart_tune                                        0.909121    0.918962   \n",
       "lgb411_goss_tune                                        0.907386    0.919970   \n",
       "lgb411_goss_tune2                                       0.907152    0.920275   \n",
       "poisson_lgb                                             0.900995    0.912005   \n",
       "poisson_small_lr_lgb                                    0.904021    0.915235   \n",
       "small_features_v5_xgb                                   0.923394    0.933476   \n",
       "small_features_v4_xgb                                   0.919352    0.929105   \n",
       "nima_features_xgb                                       0.922500    0.932235   \n",
       "img_meta_xgb                                            0.917717    0.934714   \n",
       "img_meta_nima_xgb                                       0.916878    0.933102   \n",
       "xgb_new                                                 0.903714    0.917684   \n",
       "baseline_xgb                                            0.894925    0.906859   \n",
       "ranking_xgb                                             0.737832    0.736728   \n",
       "catboost                                                0.902028    0.919560   \n",
       "catboost1_without_text                                  0.902028    0.919560   \n",
       "mcl_cgb                                                 0.918151    0.925841   \n",
       "cgb_with_categorical                                    0.908191    0.918187   \n",
       "pretrained_bigru_cv1d_rnn                               0.921847    0.919778   \n",
       "pretrained_bigru_attention_rnn                          0.921070    0.918981   \n",
       "pretrained_2gru_rnn                                     0.918656    0.916932   \n",
       "selftrained_bigru_conv1d_rnn                            0.917476    0.912860   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn          0.909692    0.910647   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn      0.901170    0.902576   \n",
       "text_lgb                                                0.869846    0.852152   \n",
       "text_cwb_rg                                             0.712374    0.701711   \n",
       "text_fm                                                 0.849202    0.832332   \n",
       "text_rg                                                 0.851942    0.835086   \n",
       "mlp                                                     0.897334    0.887590   \n",
       "rf                                                      0.903146    0.895948   \n",
       "rf_411_7000_leaves                                      0.911783    0.908071   \n",
       "alpha_0001                                              0.848833    0.825604   \n",
       "alpha_160                                               0.881341    0.863308   \n",
       "alpha_10                                                0.863476    0.842154   \n",
       "alpha_320                                               0.885262    0.867993   \n",
       "ridge_new_411                                           0.874476    0.863764   \n",
       "lr_l1_05                                                0.841630    0.826684   \n",
       "lr_l1_1                                                 0.827670    0.811957   \n",
       "lr_l2_01                                                0.850187    0.836491   \n",
       "lr_l2_1                                                 0.819786    0.804208   \n",
       "cls05_lgb                                               0.850715    0.865770   \n",
       "cls0_lgb                                                0.753346    0.752856   \n",
       "\n",
       "                                                    fused_text_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                    0.912013   \n",
       "lgb411_tune                                               0.914794   \n",
       "plants_lgb                                                0.921208   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb               0.914908   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...        0.910385   \n",
       "xentropy_small_lr_cat_lgb                                 0.925647   \n",
       "simple_feature_lgb                                        0.936530   \n",
       "all_mean_enc_lgb                                          0.939821   \n",
       "all_mean_enc_user_feat_lgb                                0.940541   \n",
       "all_mean_enc_user_feat2_lgb                               0.932428   \n",
       "cat_interact_lgb                                          0.933094   \n",
       "mean_enc_lgb                                              0.938839   \n",
       "marcus_lgb                                                0.942398   \n",
       "fused_text_lgb                                            1.000000   \n",
       "mixed_features_text_proprocessing_lgb                     0.977439   \n",
       "select_dense_features_lgb                                 0.925521   \n",
       "select_sparse_features_lgb                                0.930711   \n",
       "lgb411_dart_tune                                          0.918812   \n",
       "lgb411_goss_tune                                          0.916225   \n",
       "lgb411_goss_tune2                                         0.915543   \n",
       "poisson_lgb                                               0.911017   \n",
       "poisson_small_lr_lgb                                      0.914154   \n",
       "small_features_v5_xgb                                     0.950737   \n",
       "small_features_v4_xgb                                     0.946809   \n",
       "nima_features_xgb                                         0.950493   \n",
       "img_meta_xgb                                              0.945683   \n",
       "img_meta_nima_xgb                                         0.945216   \n",
       "xgb_new                                                   0.911931   \n",
       "baseline_xgb                                              0.904365   \n",
       "ranking_xgb                                               0.741206   \n",
       "catboost                                                  0.904336   \n",
       "catboost1_without_text                                    0.904336   \n",
       "mcl_cgb                                                   0.928662   \n",
       "cgb_with_categorical                                      0.917279   \n",
       "pretrained_bigru_cv1d_rnn                                 0.917589   \n",
       "pretrained_bigru_attention_rnn                            0.916410   \n",
       "pretrained_2gru_rnn                                       0.914216   \n",
       "selftrained_bigru_conv1d_rnn                              0.915931   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn            0.905832   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn        0.896022   \n",
       "text_lgb                                                  0.866779   \n",
       "text_cwb_rg                                               0.715492   \n",
       "text_fm                                                   0.868791   \n",
       "text_rg                                                   0.870874   \n",
       "mlp                                                       0.900485   \n",
       "rf                                                        0.921293   \n",
       "rf_411_7000_leaves                                        0.927609   \n",
       "alpha_0001                                                0.853381   \n",
       "alpha_160                                                 0.891558   \n",
       "alpha_10                                                  0.870849   \n",
       "alpha_320                                                 0.895356   \n",
       "ridge_new_411                                             0.890493   \n",
       "lr_l1_05                                                  0.851669   \n",
       "lr_l1_1                                                   0.839089   \n",
       "lr_l2_01                                                  0.861994   \n",
       "lr_l2_1                                                   0.832904   \n",
       "cls05_lgb                                                 0.862263   \n",
       "cls0_lgb                                                  0.758297   \n",
       "\n",
       "                                                    mixed_features_text_proprocessing_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                           0.913005   \n",
       "lgb411_tune                                                                      0.915861   \n",
       "plants_lgb                                                                       0.921965   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                      0.915626   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                               0.911364   \n",
       "xentropy_small_lr_cat_lgb                                                        0.925489   \n",
       "simple_feature_lgb                                                               0.939173   \n",
       "all_mean_enc_lgb                                                                 0.943974   \n",
       "all_mean_enc_user_feat_lgb                                                       0.944687   \n",
       "all_mean_enc_user_feat2_lgb                                                      0.936438   \n",
       "cat_interact_lgb                                                                 0.936761   \n",
       "mean_enc_lgb                                                                     0.943108   \n",
       "marcus_lgb                                                                       0.944862   \n",
       "fused_text_lgb                                                                   0.977439   \n",
       "mixed_features_text_proprocessing_lgb                                            1.000000   \n",
       "select_dense_features_lgb                                                        0.921109   \n",
       "select_sparse_features_lgb                                                       0.932118   \n",
       "lgb411_dart_tune                                                                 0.919663   \n",
       "lgb411_goss_tune                                                                 0.917162   \n",
       "lgb411_goss_tune2                                                                0.916609   \n",
       "poisson_lgb                                                                      0.911857   \n",
       "poisson_small_lr_lgb                                                             0.914998   \n",
       "small_features_v5_xgb                                                            0.949450   \n",
       "small_features_v4_xgb                                                            0.945420   \n",
       "nima_features_xgb                                                                0.949004   \n",
       "img_meta_xgb                                                                     0.944127   \n",
       "img_meta_nima_xgb                                                                0.943598   \n",
       "xgb_new                                                                          0.913279   \n",
       "baseline_xgb                                                                     0.905456   \n",
       "ranking_xgb                                                                      0.739742   \n",
       "catboost                                                                         0.898912   \n",
       "catboost1_without_text                                                           0.898912   \n",
       "mcl_cgb                                                                          0.928638   \n",
       "cgb_with_categorical                                                             0.917918   \n",
       "pretrained_bigru_cv1d_rnn                                                        0.916229   \n",
       "pretrained_bigru_attention_rnn                                                   0.914980   \n",
       "pretrained_2gru_rnn                                                              0.912850   \n",
       "selftrained_bigru_conv1d_rnn                                                     0.915627   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                   0.906177   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                               0.897084   \n",
       "text_lgb                                                                         0.868076   \n",
       "text_cwb_rg                                                                      0.710091   \n",
       "text_fm                                                                          0.867281   \n",
       "text_rg                                                                          0.868427   \n",
       "mlp                                                                              0.900056   \n",
       "rf                                                                               0.919177   \n",
       "rf_411_7000_leaves                                                               0.926004   \n",
       "alpha_0001                                                                       0.852450   \n",
       "alpha_160                                                                        0.889281   \n",
       "alpha_10                                                                         0.869725   \n",
       "alpha_320                                                                        0.892455   \n",
       "ridge_new_411                                                                    0.886403   \n",
       "lr_l1_05                                                                         0.851668   \n",
       "lr_l1_1                                                                          0.839892   \n",
       "lr_l2_01                                                                         0.860305   \n",
       "lr_l2_1                                                                          0.833779   \n",
       "cls05_lgb                                                                        0.864107   \n",
       "cls0_lgb                                                                         0.756379   \n",
       "\n",
       "                                                    select_dense_features_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                               0.902741   \n",
       "lgb411_tune                                                          0.906655   \n",
       "plants_lgb                                                           0.896150   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                          0.901881   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                   0.899385   \n",
       "xentropy_small_lr_cat_lgb                                            0.919620   \n",
       "simple_feature_lgb                                                   0.933709   \n",
       "all_mean_enc_lgb                                                     0.939846   \n",
       "all_mean_enc_user_feat_lgb                                           0.939407   \n",
       "all_mean_enc_user_feat2_lgb                                          0.928221   \n",
       "cat_interact_lgb                                                     0.937580   \n",
       "mean_enc_lgb                                                         0.937892   \n",
       "marcus_lgb                                                           0.960118   \n",
       "fused_text_lgb                                                       0.925521   \n",
       "mixed_features_text_proprocessing_lgb                                0.921109   \n",
       "select_dense_features_lgb                                            1.000000   \n",
       "select_sparse_features_lgb                                           0.970594   \n",
       "lgb411_dart_tune                                                     0.905117   \n",
       "lgb411_goss_tune                                                     0.906767   \n",
       "lgb411_goss_tune2                                                    0.907153   \n",
       "poisson_lgb                                                          0.898740   \n",
       "poisson_small_lr_lgb                                                 0.902010   \n",
       "small_features_v5_xgb                                                0.915873   \n",
       "small_features_v4_xgb                                                0.911518   \n",
       "nima_features_xgb                                                    0.918223   \n",
       "img_meta_xgb                                                         0.917351   \n",
       "img_meta_nima_xgb                                                    0.918931   \n",
       "xgb_new                                                              0.904129   \n",
       "baseline_xgb                                                         0.893515   \n",
       "ranking_xgb                                                          0.735165   \n",
       "catboost                                                             0.918677   \n",
       "catboost1_without_text                                               0.918677   \n",
       "mcl_cgb                                                              0.911059   \n",
       "cgb_with_categorical                                                 0.903624   \n",
       "pretrained_bigru_cv1d_rnn                                            0.913667   \n",
       "pretrained_bigru_attention_rnn                                       0.912747   \n",
       "pretrained_2gru_rnn                                                  0.911341   \n",
       "selftrained_bigru_conv1d_rnn                                         0.900438   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                       0.899333   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                   0.893267   \n",
       "text_lgb                                                             0.823182   \n",
       "text_cwb_rg                                                          0.705327   \n",
       "text_fm                                                              0.804784   \n",
       "text_rg                                                              0.809867   \n",
       "mlp                                                                  0.866792   \n",
       "rf                                                                   0.880062   \n",
       "rf_411_7000_leaves                                                   0.893396   \n",
       "alpha_0001                                                           0.797980   \n",
       "alpha_160                                                            0.839233   \n",
       "alpha_10                                                             0.814377   \n",
       "alpha_320                                                            0.846704   \n",
       "ridge_new_411                                                        0.852123   \n",
       "lr_l1_05                                                             0.799327   \n",
       "lr_l1_1                                                              0.781676   \n",
       "lr_l2_01                                                             0.815745   \n",
       "lr_l2_1                                                              0.773605   \n",
       "cls05_lgb                                                            0.849946   \n",
       "cls0_lgb                                                             0.750064   \n",
       "\n",
       "                                                    select_sparse_features_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                0.908337   \n",
       "lgb411_tune                                                           0.912361   \n",
       "plants_lgb                                                            0.902178   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                           0.907734   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                    0.905112   \n",
       "xentropy_small_lr_cat_lgb                                             0.924598   \n",
       "simple_feature_lgb                                                    0.945776   \n",
       "all_mean_enc_lgb                                                      0.953933   \n",
       "all_mean_enc_user_feat_lgb                                            0.953526   \n",
       "all_mean_enc_user_feat2_lgb                                           0.942182   \n",
       "cat_interact_lgb                                                      0.950516   \n",
       "mean_enc_lgb                                                          0.952404   \n",
       "marcus_lgb                                                            0.975061   \n",
       "fused_text_lgb                                                        0.930711   \n",
       "mixed_features_text_proprocessing_lgb                                 0.932118   \n",
       "select_dense_features_lgb                                             0.970594   \n",
       "select_sparse_features_lgb                                            1.000000   \n",
       "lgb411_dart_tune                                                      0.910978   \n",
       "lgb411_goss_tune                                                      0.912440   \n",
       "lgb411_goss_tune2                                                     0.912812   \n",
       "poisson_lgb                                                           0.904226   \n",
       "poisson_small_lr_lgb                                                  0.907487   \n",
       "small_features_v5_xgb                                                 0.921414   \n",
       "small_features_v4_xgb                                                 0.917017   \n",
       "nima_features_xgb                                                     0.923615   \n",
       "img_meta_xgb                                                          0.922866   \n",
       "img_meta_nima_xgb                                                     0.924344   \n",
       "xgb_new                                                               0.910121   \n",
       "baseline_xgb                                                          0.899271   \n",
       "ranking_xgb                                                           0.734971   \n",
       "catboost                                                              0.907917   \n",
       "catboost1_without_text                                                0.907917   \n",
       "mcl_cgb                                                               0.916608   \n",
       "cgb_with_categorical                                                  0.909647   \n",
       "pretrained_bigru_cv1d_rnn                                             0.914844   \n",
       "pretrained_bigru_attention_rnn                                        0.914060   \n",
       "pretrained_2gru_rnn                                                   0.912147   \n",
       "selftrained_bigru_conv1d_rnn                                          0.907708   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                        0.906939   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                    0.900848   \n",
       "text_lgb                                                              0.841794   \n",
       "text_cwb_rg                                                           0.695711   \n",
       "text_fm                                                               0.821912   \n",
       "text_rg                                                               0.824401   \n",
       "mlp                                                                   0.877851   \n",
       "rf                                                                    0.885836   \n",
       "rf_411_7000_leaves                                                    0.899280   \n",
       "alpha_0001                                                            0.813741   \n",
       "alpha_160                                                             0.851746   \n",
       "alpha_10                                                              0.830083   \n",
       "alpha_320                                                             0.856936   \n",
       "ridge_new_411                                                         0.855378   \n",
       "lr_l1_05                                                              0.814837   \n",
       "lr_l1_1                                                               0.799672   \n",
       "lr_l2_01                                                              0.826084   \n",
       "lr_l2_1                                                               0.791992   \n",
       "cls05_lgb                                                             0.857522   \n",
       "cls0_lgb                                                              0.748902   \n",
       "\n",
       "                                                    lgb411_dart_tune  \\\n",
       "xentropy_add_lotsof_image_features_lgb                      0.976410   \n",
       "lgb411_tune                                                 0.982080   \n",
       "plants_lgb                                                  0.966236   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                 0.972245   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...          0.976626   \n",
       "xentropy_small_lr_cat_lgb                                   0.963631   \n",
       "simple_feature_lgb                                          0.908589   \n",
       "all_mean_enc_lgb                                            0.909640   \n",
       "all_mean_enc_user_feat_lgb                                  0.909536   \n",
       "all_mean_enc_user_feat2_lgb                                 0.902085   \n",
       "cat_interact_lgb                                            0.903797   \n",
       "mean_enc_lgb                                                0.909121   \n",
       "marcus_lgb                                                  0.918962   \n",
       "fused_text_lgb                                              0.918812   \n",
       "mixed_features_text_proprocessing_lgb                       0.919663   \n",
       "select_dense_features_lgb                                   0.905117   \n",
       "select_sparse_features_lgb                                  0.910978   \n",
       "lgb411_dart_tune                                            1.000000   \n",
       "lgb411_goss_tune                                            0.982385   \n",
       "lgb411_goss_tune2                                           0.982841   \n",
       "poisson_lgb                                                 0.976874   \n",
       "poisson_small_lr_lgb                                        0.980240   \n",
       "small_features_v5_xgb                                       0.932515   \n",
       "small_features_v4_xgb                                       0.928168   \n",
       "nima_features_xgb                                           0.935901   \n",
       "img_meta_xgb                                                0.938310   \n",
       "img_meta_nima_xgb                                           0.940572   \n",
       "xgb_new                                                     0.981039   \n",
       "baseline_xgb                                                0.970684   \n",
       "ranking_xgb                                                 0.771464   \n",
       "catboost                                                    0.897617   \n",
       "catboost1_without_text                                      0.897617   \n",
       "mcl_cgb                                                     0.975858   \n",
       "cgb_with_categorical                                        0.971310   \n",
       "pretrained_bigru_cv1d_rnn                                   0.896763   \n",
       "pretrained_bigru_attention_rnn                              0.896112   \n",
       "pretrained_2gru_rnn                                         0.893587   \n",
       "selftrained_bigru_conv1d_rnn                                0.896312   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn              0.896231   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn          0.910889   \n",
       "text_lgb                                                    0.834262   \n",
       "text_cwb_rg                                                 0.699198   \n",
       "text_fm                                                     0.834251   \n",
       "text_rg                                                     0.836672   \n",
       "mlp                                                         0.870983   \n",
       "rf                                                          0.935395   \n",
       "rf_411_7000_leaves                                          0.948653   \n",
       "alpha_0001                                                  0.822557   \n",
       "alpha_160                                                   0.858009   \n",
       "alpha_10                                                    0.838689   \n",
       "alpha_320                                                   0.861811   \n",
       "ridge_new_411                                               0.884214   \n",
       "lr_l1_05                                                    0.819196   \n",
       "lr_l1_1                                                     0.806717   \n",
       "lr_l2_01                                                    0.829294   \n",
       "lr_l2_1                                                     0.801049   \n",
       "cls05_lgb                                                   0.932960   \n",
       "cls0_lgb                                                    0.794906   \n",
       "\n",
       "                                                    lgb411_goss_tune  \\\n",
       "xentropy_add_lotsof_image_features_lgb                      0.986276   \n",
       "lgb411_tune                                                 0.994217   \n",
       "plants_lgb                                                  0.968448   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                 0.977728   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...          0.985737   \n",
       "xentropy_small_lr_cat_lgb                                   0.968035   \n",
       "simple_feature_lgb                                          0.906396   \n",
       "all_mean_enc_lgb                                            0.908318   \n",
       "all_mean_enc_user_feat_lgb                                  0.908428   \n",
       "all_mean_enc_user_feat2_lgb                                 0.900287   \n",
       "cat_interact_lgb                                            0.903149   \n",
       "mean_enc_lgb                                                0.907386   \n",
       "marcus_lgb                                                  0.919970   \n",
       "fused_text_lgb                                              0.916225   \n",
       "mixed_features_text_proprocessing_lgb                       0.917162   \n",
       "select_dense_features_lgb                                   0.906767   \n",
       "select_sparse_features_lgb                                  0.912440   \n",
       "lgb411_dart_tune                                            0.982385   \n",
       "lgb411_goss_tune                                            1.000000   \n",
       "lgb411_goss_tune2                                           0.995097   \n",
       "poisson_lgb                                                 0.986620   \n",
       "poisson_small_lr_lgb                                        0.990096   \n",
       "small_features_v5_xgb                                       0.932001   \n",
       "small_features_v4_xgb                                       0.927691   \n",
       "nima_features_xgb                                           0.935954   \n",
       "img_meta_xgb                                                0.940478   \n",
       "img_meta_nima_xgb                                           0.943147   \n",
       "xgb_new                                                     0.985470   \n",
       "baseline_xgb                                                0.978288   \n",
       "ranking_xgb                                                 0.771626   \n",
       "catboost                                                    0.897286   \n",
       "catboost1_without_text                                      0.897286   \n",
       "mcl_cgb                                                     0.976467   \n",
       "cgb_with_categorical                                        0.974433   \n",
       "pretrained_bigru_cv1d_rnn                                   0.895743   \n",
       "pretrained_bigru_attention_rnn                              0.895005   \n",
       "pretrained_2gru_rnn                                         0.892570   \n",
       "selftrained_bigru_conv1d_rnn                                0.894714   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn              0.896516   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn          0.911942   \n",
       "text_lgb                                                    0.825209   \n",
       "text_cwb_rg                                                 0.687254   \n",
       "text_fm                                                     0.824191   \n",
       "text_rg                                                     0.825979   \n",
       "mlp                                                         0.868194   \n",
       "rf                                                          0.924613   \n",
       "rf_411_7000_leaves                                          0.939247   \n",
       "alpha_0001                                                  0.815271   \n",
       "alpha_160                                                   0.849882   \n",
       "alpha_10                                                    0.831110   \n",
       "alpha_320                                                   0.853491   \n",
       "ridge_new_411                                               0.875844   \n",
       "lr_l1_05                                                    0.814830   \n",
       "lr_l1_1                                                     0.802777   \n",
       "lr_l2_01                                                    0.824603   \n",
       "lr_l2_1                                                     0.797247   \n",
       "cls05_lgb                                                   0.944056   \n",
       "cls0_lgb                                                    0.790416   \n",
       "\n",
       "                                                    lgb411_goss_tune2  \\\n",
       "xentropy_add_lotsof_image_features_lgb                       0.988411   \n",
       "lgb411_tune                                                  0.996717   \n",
       "plants_lgb                                                   0.967875   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                  0.977729   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...           0.986809   \n",
       "xentropy_small_lr_cat_lgb                                    0.968451   \n",
       "simple_feature_lgb                                           0.906203   \n",
       "all_mean_enc_lgb                                             0.908056   \n",
       "all_mean_enc_user_feat_lgb                                   0.908123   \n",
       "all_mean_enc_user_feat2_lgb                                  0.899951   \n",
       "cat_interact_lgb                                             0.902947   \n",
       "mean_enc_lgb                                                 0.907152   \n",
       "marcus_lgb                                                   0.920275   \n",
       "fused_text_lgb                                               0.915543   \n",
       "mixed_features_text_proprocessing_lgb                        0.916609   \n",
       "select_dense_features_lgb                                    0.907153   \n",
       "select_sparse_features_lgb                                   0.912812   \n",
       "lgb411_dart_tune                                             0.982841   \n",
       "lgb411_goss_tune                                             0.995097   \n",
       "lgb411_goss_tune2                                            1.000000   \n",
       "poisson_lgb                                                  0.986215   \n",
       "poisson_small_lr_lgb                                         0.989644   \n",
       "small_features_v5_xgb                                        0.931870   \n",
       "small_features_v4_xgb                                        0.927521   \n",
       "nima_features_xgb                                            0.936097   \n",
       "img_meta_xgb                                                 0.941337   \n",
       "img_meta_nima_xgb                                            0.944206   \n",
       "xgb_new                                                      0.988114   \n",
       "baseline_xgb                                                 0.978595   \n",
       "ranking_xgb                                                  0.770214   \n",
       "catboost                                                     0.897418   \n",
       "catboost1_without_text                                       0.897418   \n",
       "mcl_cgb                                                      0.976997   \n",
       "cgb_with_categorical                                         0.975571   \n",
       "pretrained_bigru_cv1d_rnn                                    0.895913   \n",
       "pretrained_bigru_attention_rnn                               0.895194   \n",
       "pretrained_2gru_rnn                                          0.892643   \n",
       "selftrained_bigru_conv1d_rnn                                 0.894810   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn               0.896912   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn           0.912926   \n",
       "text_lgb                                                     0.823791   \n",
       "text_cwb_rg                                                  0.685681   \n",
       "text_fm                                                      0.822673   \n",
       "text_rg                                                      0.824458   \n",
       "mlp                                                          0.867342   \n",
       "rf                                                           0.922978   \n",
       "rf_411_7000_leaves                                           0.938183   \n",
       "alpha_0001                                                   0.813841   \n",
       "alpha_160                                                    0.848415   \n",
       "alpha_10                                                     0.829625   \n",
       "alpha_320                                                    0.852047   \n",
       "ridge_new_411                                                0.874164   \n",
       "lr_l1_05                                                     0.814072   \n",
       "lr_l1_1                                                      0.802009   \n",
       "lr_l2_01                                                     0.823828   \n",
       "lr_l2_1                                                      0.796454   \n",
       "cls05_lgb                                                    0.946191   \n",
       "cls0_lgb                                                     0.788665   \n",
       "\n",
       "                                                    poisson_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                 0.979855   \n",
       "lgb411_tune                                            0.985545   \n",
       "plants_lgb                                             0.963319   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb            0.972814   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...     0.982530   \n",
       "xentropy_small_lr_cat_lgb                              0.964006   \n",
       "simple_feature_lgb                                     0.900190   \n",
       "all_mean_enc_lgb                                       0.901865   \n",
       "all_mean_enc_user_feat_lgb                             0.901898   \n",
       "all_mean_enc_user_feat2_lgb                            0.893906   \n",
       "cat_interact_lgb                                       0.895902   \n",
       "mean_enc_lgb                                           0.900995   \n",
       "marcus_lgb                                             0.912005   \n",
       "fused_text_lgb                                         0.911017   \n",
       "mixed_features_text_proprocessing_lgb                  0.911857   \n",
       "select_dense_features_lgb                              0.898740   \n",
       "select_sparse_features_lgb                             0.904226   \n",
       "lgb411_dart_tune                                       0.976874   \n",
       "lgb411_goss_tune                                       0.986620   \n",
       "lgb411_goss_tune2                                      0.986215   \n",
       "poisson_lgb                                            1.000000   \n",
       "poisson_small_lr_lgb                                   0.993251   \n",
       "small_features_v5_xgb                                  0.925590   \n",
       "small_features_v4_xgb                                  0.921467   \n",
       "nima_features_xgb                                      0.929679   \n",
       "img_meta_xgb                                           0.933917   \n",
       "img_meta_nima_xgb                                      0.936607   \n",
       "xgb_new                                                0.979324   \n",
       "baseline_xgb                                           0.972942   \n",
       "ranking_xgb                                            0.766890   \n",
       "catboost                                               0.891646   \n",
       "catboost1_without_text                                 0.891646   \n",
       "mcl_cgb                                                0.972201   \n",
       "cgb_with_categorical                                   0.968376   \n",
       "pretrained_bigru_cv1d_rnn                              0.890068   \n",
       "pretrained_bigru_attention_rnn                         0.889364   \n",
       "pretrained_2gru_rnn                                    0.886849   \n",
       "selftrained_bigru_conv1d_rnn                           0.889476   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn         0.890624   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn     0.906531   \n",
       "text_lgb                                               0.823106   \n",
       "text_cwb_rg                                            0.687793   \n",
       "text_fm                                                0.822702   \n",
       "text_rg                                                0.824834   \n",
       "mlp                                                    0.863948   \n",
       "rf                                                     0.924469   \n",
       "rf_411_7000_leaves                                     0.937688   \n",
       "alpha_0001                                             0.812784   \n",
       "alpha_160                                              0.847676   \n",
       "alpha_10                                               0.828704   \n",
       "alpha_320                                              0.851360   \n",
       "ridge_new_411                                          0.874312   \n",
       "lr_l1_05                                               0.812960   \n",
       "lr_l1_1                                                0.800763   \n",
       "lr_l2_01                                               0.822877   \n",
       "lr_l2_1                                                0.795230   \n",
       "cls05_lgb                                              0.939893   \n",
       "cls0_lgb                                               0.786246   \n",
       "\n",
       "                                                    poisson_small_lr_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                          0.983149   \n",
       "lgb411_tune                                                     0.988986   \n",
       "plants_lgb                                                      0.966409   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                     0.976023   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...              0.985805   \n",
       "xentropy_small_lr_cat_lgb                                       0.967339   \n",
       "simple_feature_lgb                                              0.903216   \n",
       "all_mean_enc_lgb                                                0.904927   \n",
       "all_mean_enc_user_feat_lgb                                      0.904942   \n",
       "all_mean_enc_user_feat2_lgb                                     0.896952   \n",
       "cat_interact_lgb                                                0.898981   \n",
       "mean_enc_lgb                                                    0.904021   \n",
       "marcus_lgb                                                      0.915235   \n",
       "fused_text_lgb                                                  0.914154   \n",
       "mixed_features_text_proprocessing_lgb                           0.914998   \n",
       "select_dense_features_lgb                                       0.902010   \n",
       "select_sparse_features_lgb                                      0.907487   \n",
       "lgb411_dart_tune                                                0.980240   \n",
       "lgb411_goss_tune                                                0.990096   \n",
       "lgb411_goss_tune2                                               0.989644   \n",
       "poisson_lgb                                                     0.993251   \n",
       "poisson_small_lr_lgb                                            1.000000   \n",
       "small_features_v5_xgb                                           0.928921   \n",
       "small_features_v4_xgb                                           0.924713   \n",
       "nima_features_xgb                                               0.933003   \n",
       "img_meta_xgb                                                    0.937375   \n",
       "img_meta_nima_xgb                                               0.940084   \n",
       "xgb_new                                                         0.982912   \n",
       "baseline_xgb                                                    0.976541   \n",
       "ranking_xgb                                                     0.769690   \n",
       "catboost                                                        0.894689   \n",
       "catboost1_without_text                                          0.894689   \n",
       "mcl_cgb                                                         0.975346   \n",
       "cgb_with_categorical                                            0.971617   \n",
       "pretrained_bigru_cv1d_rnn                                       0.893223   \n",
       "pretrained_bigru_attention_rnn                                  0.892512   \n",
       "pretrained_2gru_rnn                                             0.890005   \n",
       "selftrained_bigru_conv1d_rnn                                    0.892716   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                  0.893784   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn              0.909592   \n",
       "text_lgb                                                        0.826004   \n",
       "text_cwb_rg                                                     0.689999   \n",
       "text_fm                                                         0.825559   \n",
       "text_rg                                                         0.827687   \n",
       "mlp                                                             0.867124   \n",
       "rf                                                              0.927577   \n",
       "rf_411_7000_leaves                                              0.940851   \n",
       "alpha_0001                                                      0.815649   \n",
       "alpha_160                                                       0.850684   \n",
       "alpha_10                                                        0.831653   \n",
       "alpha_320                                                       0.854368   \n",
       "ridge_new_411                                                   0.877285   \n",
       "lr_l1_05                                                        0.815880   \n",
       "lr_l1_1                                                         0.803637   \n",
       "lr_l2_01                                                        0.825806   \n",
       "lr_l2_1                                                         0.798084   \n",
       "cls05_lgb                                                       0.943051   \n",
       "cls0_lgb                                                        0.789149   \n",
       "\n",
       "                                                    small_features_v5_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                           0.926844   \n",
       "lgb411_tune                                                      0.931473   \n",
       "plants_lgb                                                       0.931010   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                      0.924954   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...               0.925209   \n",
       "xentropy_small_lr_cat_lgb                                        0.923585   \n",
       "simple_feature_lgb                                               0.922071   \n",
       "all_mean_enc_lgb                                                 0.925226   \n",
       "all_mean_enc_user_feat_lgb                                       0.925803   \n",
       "all_mean_enc_user_feat2_lgb                                      0.917543   \n",
       "cat_interact_lgb                                                 0.920951   \n",
       "mean_enc_lgb                                                     0.923394   \n",
       "marcus_lgb                                                       0.933476   \n",
       "fused_text_lgb                                                   0.950737   \n",
       "mixed_features_text_proprocessing_lgb                            0.949450   \n",
       "select_dense_features_lgb                                        0.915873   \n",
       "select_sparse_features_lgb                                       0.921414   \n",
       "lgb411_dart_tune                                                 0.932515   \n",
       "lgb411_goss_tune                                                 0.932001   \n",
       "lgb411_goss_tune2                                                0.931870   \n",
       "poisson_lgb                                                      0.925590   \n",
       "poisson_small_lr_lgb                                             0.928921   \n",
       "small_features_v5_xgb                                            1.000000   \n",
       "small_features_v4_xgb                                            0.987775   \n",
       "nima_features_xgb                                                0.987994   \n",
       "img_meta_xgb                                                     0.980873   \n",
       "img_meta_nima_xgb                                                0.977972   \n",
       "xgb_new                                                          0.931531   \n",
       "baseline_xgb                                                     0.919868   \n",
       "ranking_xgb                                                      0.742374   \n",
       "catboost                                                         0.911971   \n",
       "catboost1_without_text                                           0.911971   \n",
       "mcl_cgb                                                          0.935648   \n",
       "cgb_with_categorical                                             0.927811   \n",
       "pretrained_bigru_cv1d_rnn                                        0.911734   \n",
       "pretrained_bigru_attention_rnn                                   0.911048   \n",
       "pretrained_2gru_rnn                                              0.908847   \n",
       "selftrained_bigru_conv1d_rnn                                     0.910415   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                   0.901820   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn               0.893911   \n",
       "text_lgb                                                         0.850251   \n",
       "text_cwb_rg                                                      0.702433   \n",
       "text_fm                                                          0.847868   \n",
       "text_rg                                                          0.849526   \n",
       "mlp                                                              0.890831   \n",
       "rf                                                               0.914004   \n",
       "rf_411_7000_leaves                                               0.924785   \n",
       "alpha_0001                                                       0.832539   \n",
       "alpha_160                                                        0.868728   \n",
       "alpha_10                                                         0.848975   \n",
       "alpha_320                                                        0.872565   \n",
       "ridge_new_411                                                    0.870717   \n",
       "lr_l1_05                                                         0.832500   \n",
       "lr_l1_1                                                          0.820057   \n",
       "lr_l2_01                                                         0.842153   \n",
       "lr_l2_1                                                          0.814219   \n",
       "cls05_lgb                                                        0.878056   \n",
       "cls0_lgb                                                         0.766178   \n",
       "\n",
       "                                                    small_features_v4_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                           0.922592   \n",
       "lgb411_tune                                                      0.927126   \n",
       "plants_lgb                                                       0.926905   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                      0.920816   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...               0.920967   \n",
       "xentropy_small_lr_cat_lgb                                        0.919470   \n",
       "simple_feature_lgb                                               0.918064   \n",
       "all_mean_enc_lgb                                                 0.921064   \n",
       "all_mean_enc_user_feat_lgb                                       0.921642   \n",
       "all_mean_enc_user_feat2_lgb                                      0.913503   \n",
       "cat_interact_lgb                                                 0.916776   \n",
       "mean_enc_lgb                                                     0.919352   \n",
       "marcus_lgb                                                       0.929105   \n",
       "fused_text_lgb                                                   0.946809   \n",
       "mixed_features_text_proprocessing_lgb                            0.945420   \n",
       "select_dense_features_lgb                                        0.911518   \n",
       "select_sparse_features_lgb                                       0.917017   \n",
       "lgb411_dart_tune                                                 0.928168   \n",
       "lgb411_goss_tune                                                 0.927691   \n",
       "lgb411_goss_tune2                                                0.927521   \n",
       "poisson_lgb                                                      0.921467   \n",
       "poisson_small_lr_lgb                                             0.924713   \n",
       "small_features_v5_xgb                                            0.987775   \n",
       "small_features_v4_xgb                                            1.000000   \n",
       "nima_features_xgb                                                0.983083   \n",
       "img_meta_xgb                                                     0.976000   \n",
       "img_meta_nima_xgb                                                0.973208   \n",
       "xgb_new                                                          0.927041   \n",
       "baseline_xgb                                                     0.915654   \n",
       "ranking_xgb                                                      0.740242   \n",
       "catboost                                                         0.908011   \n",
       "catboost1_without_text                                           0.908011   \n",
       "mcl_cgb                                                          0.931624   \n",
       "cgb_with_categorical                                             0.923697   \n",
       "pretrained_bigru_cv1d_rnn                                        0.907881   \n",
       "pretrained_bigru_attention_rnn                                   0.907101   \n",
       "pretrained_2gru_rnn                                              0.904934   \n",
       "selftrained_bigru_conv1d_rnn                                     0.906435   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                   0.897812   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn               0.889862   \n",
       "text_lgb                                                         0.847049   \n",
       "text_cwb_rg                                                      0.699813   \n",
       "text_fm                                                          0.844865   \n",
       "text_rg                                                          0.846549   \n",
       "mlp                                                              0.887099   \n",
       "rf                                                               0.910404   \n",
       "rf_411_7000_leaves                                               0.921047   \n",
       "alpha_0001                                                       0.829478   \n",
       "alpha_160                                                        0.865605   \n",
       "alpha_10                                                         0.845877   \n",
       "alpha_320                                                        0.869439   \n",
       "ridge_new_411                                                    0.867462   \n",
       "lr_l1_05                                                         0.829700   \n",
       "lr_l1_1                                                          0.817291   \n",
       "lr_l2_01                                                         0.839354   \n",
       "lr_l2_1                                                          0.811488   \n",
       "cls05_lgb                                                        0.874278   \n",
       "cls0_lgb                                                         0.762278   \n",
       "\n",
       "                                                    nima_features_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                       0.931074   \n",
       "lgb411_tune                                                  0.935678   \n",
       "plants_lgb                                                   0.930084   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                  0.928658   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...           0.929248   \n",
       "xentropy_small_lr_cat_lgb                                    0.926771   \n",
       "simple_feature_lgb                                           0.921465   \n",
       "all_mean_enc_lgb                                             0.924221   \n",
       "all_mean_enc_user_feat_lgb                                   0.924791   \n",
       "all_mean_enc_user_feat2_lgb                                  0.916518   \n",
       "cat_interact_lgb                                             0.919459   \n",
       "mean_enc_lgb                                                 0.922500   \n",
       "marcus_lgb                                                   0.932235   \n",
       "fused_text_lgb                                               0.950493   \n",
       "mixed_features_text_proprocessing_lgb                        0.949004   \n",
       "select_dense_features_lgb                                    0.918223   \n",
       "select_sparse_features_lgb                                   0.923615   \n",
       "lgb411_dart_tune                                             0.935901   \n",
       "lgb411_goss_tune                                             0.935954   \n",
       "lgb411_goss_tune2                                            0.936097   \n",
       "poisson_lgb                                                  0.929679   \n",
       "poisson_small_lr_lgb                                         0.933003   \n",
       "small_features_v5_xgb                                        0.987994   \n",
       "small_features_v4_xgb                                        0.983083   \n",
       "nima_features_xgb                                            1.000000   \n",
       "img_meta_xgb                                                 0.978996   \n",
       "img_meta_nima_xgb                                            0.982510   \n",
       "xgb_new                                                      0.935533   \n",
       "baseline_xgb                                                 0.923812   \n",
       "ranking_xgb                                                  0.745941   \n",
       "catboost                                                     0.912601   \n",
       "catboost1_without_text                                       0.912601   \n",
       "mcl_cgb                                                      0.939565   \n",
       "cgb_with_categorical                                         0.931775   \n",
       "pretrained_bigru_cv1d_rnn                                    0.911240   \n",
       "pretrained_bigru_attention_rnn                               0.910508   \n",
       "pretrained_2gru_rnn                                          0.908305   \n",
       "selftrained_bigru_conv1d_rnn                                 0.910069   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn               0.902554   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn           0.896499   \n",
       "text_lgb                                                     0.851777   \n",
       "text_cwb_rg                                                  0.704198   \n",
       "text_fm                                                      0.849669   \n",
       "text_rg                                                      0.851503   \n",
       "mlp                                                          0.891333   \n",
       "rf                                                           0.916381   \n",
       "rf_411_7000_leaves                                           0.927977   \n",
       "alpha_0001                                                   0.833880   \n",
       "alpha_160                                                    0.870432   \n",
       "alpha_10                                                     0.850466   \n",
       "alpha_320                                                    0.874324   \n",
       "ridge_new_411                                                0.874235   \n",
       "lr_l1_05                                                     0.833920   \n",
       "lr_l1_1                                                      0.821330   \n",
       "lr_l2_01                                                     0.843655   \n",
       "lr_l2_1                                                      0.815432   \n",
       "cls05_lgb                                                    0.883037   \n",
       "cls0_lgb                                                     0.768238   \n",
       "\n",
       "                                                    img_meta_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                  0.936005   \n",
       "lgb411_tune                                             0.940697   \n",
       "plants_lgb                                              0.925493   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb             0.931048   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...      0.933461   \n",
       "xentropy_small_lr_cat_lgb                               0.928518   \n",
       "simple_feature_lgb                                      0.916744   \n",
       "all_mean_enc_lgb                                        0.919339   \n",
       "all_mean_enc_user_feat_lgb                              0.919893   \n",
       "all_mean_enc_user_feat2_lgb                             0.911642   \n",
       "cat_interact_lgb                                        0.914348   \n",
       "mean_enc_lgb                                            0.917717   \n",
       "marcus_lgb                                              0.934714   \n",
       "fused_text_lgb                                          0.945683   \n",
       "mixed_features_text_proprocessing_lgb                   0.944127   \n",
       "select_dense_features_lgb                               0.917351   \n",
       "select_sparse_features_lgb                              0.922866   \n",
       "lgb411_dart_tune                                        0.938310   \n",
       "lgb411_goss_tune                                        0.940478   \n",
       "lgb411_goss_tune2                                       0.941337   \n",
       "poisson_lgb                                             0.933917   \n",
       "poisson_small_lr_lgb                                    0.937375   \n",
       "small_features_v5_xgb                                   0.980873   \n",
       "small_features_v4_xgb                                   0.976000   \n",
       "nima_features_xgb                                       0.978996   \n",
       "img_meta_xgb                                            1.000000   \n",
       "img_meta_nima_xgb                                       0.989161   \n",
       "xgb_new                                                 0.940470   \n",
       "baseline_xgb                                            0.928109   \n",
       "ranking_xgb                                             0.745525   \n",
       "catboost                                                0.919371   \n",
       "catboost1_without_text                                  0.919371   \n",
       "mcl_cgb                                                 0.940027   \n",
       "cgb_with_categorical                                    0.933331   \n",
       "pretrained_bigru_cv1d_rnn                               0.907005   \n",
       "pretrained_bigru_attention_rnn                          0.906356   \n",
       "pretrained_2gru_rnn                                     0.904119   \n",
       "selftrained_bigru_conv1d_rnn                            0.905936   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn          0.901449   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn      0.893833   \n",
       "text_lgb                                                0.848667   \n",
       "text_cwb_rg                                             0.701815   \n",
       "text_fm                                                 0.846402   \n",
       "text_rg                                                 0.848316   \n",
       "mlp                                                     0.887415   \n",
       "rf                                                      0.913126   \n",
       "rf_411_7000_leaves                                      0.924500   \n",
       "alpha_0001                                              0.830441   \n",
       "alpha_160                                               0.866846   \n",
       "alpha_10                                                0.846931   \n",
       "alpha_320                                               0.870755   \n",
       "ridge_new_411                                           0.871764   \n",
       "lr_l1_05                                                0.830167   \n",
       "lr_l1_1                                                 0.817575   \n",
       "lr_l2_01                                                0.839933   \n",
       "lr_l2_1                                                 0.811707   \n",
       "cls05_lgb                                               0.889163   \n",
       "cls0_lgb                                                0.768521   \n",
       "\n",
       "                                                    img_meta_nima_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb                       0.938847   \n",
       "lgb411_tune                                                  0.943550   \n",
       "plants_lgb                                                   0.924579   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                  0.933453   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...           0.936151   \n",
       "xentropy_small_lr_cat_lgb                                    0.930603   \n",
       "simple_feature_lgb                                           0.916079   \n",
       "all_mean_enc_lgb                                             0.918438   \n",
       "all_mean_enc_user_feat_lgb                                   0.919009   \n",
       "all_mean_enc_user_feat2_lgb                                  0.910830   \n",
       "cat_interact_lgb                                             0.913160   \n",
       "mean_enc_lgb                                                 0.916878   \n",
       "marcus_lgb                                                   0.933102   \n",
       "fused_text_lgb                                               0.945216   \n",
       "mixed_features_text_proprocessing_lgb                        0.943598   \n",
       "select_dense_features_lgb                                    0.918931   \n",
       "select_sparse_features_lgb                                   0.924344   \n",
       "lgb411_dart_tune                                             0.940572   \n",
       "lgb411_goss_tune                                             0.943147   \n",
       "lgb411_goss_tune2                                            0.944206   \n",
       "poisson_lgb                                                  0.936607   \n",
       "poisson_small_lr_lgb                                         0.940084   \n",
       "small_features_v5_xgb                                        0.977972   \n",
       "small_features_v4_xgb                                        0.973208   \n",
       "nima_features_xgb                                            0.982510   \n",
       "img_meta_xgb                                                 0.989161   \n",
       "img_meta_nima_xgb                                            1.000000   \n",
       "xgb_new                                                      0.943198   \n",
       "baseline_xgb                                                 0.930752   \n",
       "ranking_xgb                                                  0.746903   \n",
       "catboost                                                     0.918528   \n",
       "catboost1_without_text                                       0.918528   \n",
       "mcl_cgb                                                      0.942517   \n",
       "cgb_with_categorical                                         0.935971   \n",
       "pretrained_bigru_cv1d_rnn                                    0.906398   \n",
       "pretrained_bigru_attention_rnn                               0.905686   \n",
       "pretrained_2gru_rnn                                          0.903453   \n",
       "selftrained_bigru_conv1d_rnn                                 0.905387   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn               0.901533   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn           0.895538   \n",
       "text_lgb                                                     0.849234   \n",
       "text_cwb_rg                                                  0.702643   \n",
       "text_fm                                                      0.847204   \n",
       "text_rg                                                      0.849195   \n",
       "mlp                                                          0.887269   \n",
       "rf                                                           0.914289   \n",
       "rf_411_7000_leaves                                           0.926364   \n",
       "alpha_0001                                                   0.830877   \n",
       "alpha_160                                                    0.867503   \n",
       "alpha_10                                                     0.847454   \n",
       "alpha_320                                                    0.871452   \n",
       "ridge_new_411                                                0.873562   \n",
       "lr_l1_05                                                     0.830699   \n",
       "lr_l1_1                                                      0.818032   \n",
       "lr_l2_01                                                     0.840524   \n",
       "lr_l2_1                                                      0.812143   \n",
       "cls05_lgb                                                    0.892597   \n",
       "cls0_lgb                                                     0.769703   \n",
       "\n",
       "                                                     xgb_new  baseline_xgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.980519      0.971096   \n",
       "lgb411_tune                                         0.987608      0.977573   \n",
       "plants_lgb                                          0.962428      0.955797   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.971450      0.964709   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.979641      0.972157   \n",
       "xentropy_small_lr_cat_lgb                           0.963888      0.954971   \n",
       "simple_feature_lgb                                  0.902595      0.893908   \n",
       "all_mean_enc_lgb                                    0.904700      0.895836   \n",
       "all_mean_enc_user_feat_lgb                          0.904701      0.895842   \n",
       "all_mean_enc_user_feat2_lgb                         0.896645      0.887875   \n",
       "cat_interact_lgb                                    0.899476      0.890089   \n",
       "mean_enc_lgb                                        0.903714      0.894925   \n",
       "marcus_lgb                                          0.917684      0.906859   \n",
       "fused_text_lgb                                      0.911931      0.904365   \n",
       "mixed_features_text_proprocessing_lgb               0.913279      0.905456   \n",
       "select_dense_features_lgb                           0.904129      0.893515   \n",
       "select_sparse_features_lgb                          0.910121      0.899271   \n",
       "lgb411_dart_tune                                    0.981039      0.970684   \n",
       "lgb411_goss_tune                                    0.985470      0.978288   \n",
       "lgb411_goss_tune2                                   0.988114      0.978595   \n",
       "poisson_lgb                                         0.979324      0.972942   \n",
       "poisson_small_lr_lgb                                0.982912      0.976541   \n",
       "small_features_v5_xgb                               0.931531      0.919868   \n",
       "small_features_v4_xgb                               0.927041      0.915654   \n",
       "nima_features_xgb                                   0.935533      0.923812   \n",
       "img_meta_xgb                                        0.940470      0.928109   \n",
       "img_meta_nima_xgb                                   0.943198      0.930752   \n",
       "xgb_new                                             1.000000      0.974321   \n",
       "baseline_xgb                                        0.974321      1.000000   \n",
       "ranking_xgb                                         0.765451      0.762846   \n",
       "catboost                                            0.893105      0.885101   \n",
       "catboost1_without_text                              0.893105      0.885101   \n",
       "mcl_cgb                                             0.972272      0.964860   \n",
       "cgb_with_categorical                                0.971047      0.962241   \n",
       "pretrained_bigru_cv1d_rnn                           0.893433      0.884244   \n",
       "pretrained_bigru_attention_rnn                      0.892691      0.883541   \n",
       "pretrained_2gru_rnn                                 0.890199      0.880995   \n",
       "selftrained_bigru_conv1d_rnn                        0.892815      0.883780   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.893667      0.884758   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.909740      0.900193   \n",
       "text_lgb                                            0.822751      0.816482   \n",
       "text_cwb_rg                                         0.685213      0.680675   \n",
       "text_fm                                             0.820821      0.815321   \n",
       "text_rg                                             0.822538      0.817191   \n",
       "mlp                                                 0.865363      0.857438   \n",
       "rf                                                  0.925431      0.917079   \n",
       "rf_411_7000_leaves                                  0.940940      0.931035   \n",
       "alpha_0001                                          0.810176      0.805885   \n",
       "alpha_160                                           0.844804      0.840286   \n",
       "alpha_10                                            0.825969      0.821631   \n",
       "alpha_320                                           0.848448      0.843861   \n",
       "ridge_new_411                                       0.870229      0.866362   \n",
       "lr_l1_05                                            0.807589      0.805410   \n",
       "lr_l1_1                                             0.795570      0.793460   \n",
       "lr_l2_01                                            0.817199      0.815044   \n",
       "lr_l2_1                                             0.790047      0.787995   \n",
       "cls05_lgb                                           0.937390      0.931141   \n",
       "cls0_lgb                                            0.790083      0.780367   \n",
       "\n",
       "                                                    ranking_xgb  catboost  \\\n",
       "xentropy_add_lotsof_image_features_lgb                 0.765870  0.893589   \n",
       "lgb411_tune                                            0.769518  0.896485   \n",
       "plants_lgb                                             0.765113  0.890247   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb            0.768467  0.894999   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...     0.766018  0.891253   \n",
       "xentropy_small_lr_cat_lgb                              0.758656  0.888887   \n",
       "simple_feature_lgb                                     0.738648  0.902593   \n",
       "all_mean_enc_lgb                                       0.737372  0.903455   \n",
       "all_mean_enc_user_feat_lgb                             0.737337  0.902602   \n",
       "all_mean_enc_user_feat2_lgb                            0.737129  0.892868   \n",
       "cat_interact_lgb                                       0.734428  0.902092   \n",
       "mean_enc_lgb                                           0.737832  0.902028   \n",
       "marcus_lgb                                             0.736728  0.919560   \n",
       "fused_text_lgb                                         0.741206  0.904336   \n",
       "mixed_features_text_proprocessing_lgb                  0.739742  0.898912   \n",
       "select_dense_features_lgb                              0.735165  0.918677   \n",
       "select_sparse_features_lgb                             0.734971  0.907917   \n",
       "lgb411_dart_tune                                       0.771464  0.897617   \n",
       "lgb411_goss_tune                                       0.771626  0.897286   \n",
       "lgb411_goss_tune2                                      0.770214  0.897418   \n",
       "poisson_lgb                                            0.766890  0.891646   \n",
       "poisson_small_lr_lgb                                   0.769690  0.894689   \n",
       "small_features_v5_xgb                                  0.742374  0.911971   \n",
       "small_features_v4_xgb                                  0.740242  0.908011   \n",
       "nima_features_xgb                                      0.745941  0.912601   \n",
       "img_meta_xgb                                           0.745525  0.919371   \n",
       "img_meta_nima_xgb                                      0.746903  0.918528   \n",
       "xgb_new                                                0.765451  0.893105   \n",
       "baseline_xgb                                           0.762846  0.885101   \n",
       "ranking_xgb                                            1.000000  0.741137   \n",
       "catboost                                               0.741137  1.000000   \n",
       "catboost1_without_text                                 0.741137  1.000000   \n",
       "mcl_cgb                                                0.774139  0.911169   \n",
       "cgb_with_categorical                                   0.767015  0.898974   \n",
       "pretrained_bigru_cv1d_rnn                              0.723515  0.888036   \n",
       "pretrained_bigru_attention_rnn                         0.721852  0.887385   \n",
       "pretrained_2gru_rnn                                    0.722929  0.885382   \n",
       "selftrained_bigru_conv1d_rnn                           0.717453  0.872626   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn         0.707121  0.869259   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn     0.709372  0.860682   \n",
       "text_lgb                                               0.689818  0.811322   \n",
       "text_cwb_rg                                            0.628618  0.729226   \n",
       "text_fm                                                0.696715  0.794808   \n",
       "text_rg                                                0.703082  0.803529   \n",
       "mlp                                                    0.709817  0.846260   \n",
       "rf                                                     0.753216  0.881499   \n",
       "rf_411_7000_leaves                                     0.760580  0.891610   \n",
       "alpha_0001                                             0.697815  0.787240   \n",
       "alpha_160                                              0.731386  0.830252   \n",
       "alpha_10                                               0.711790  0.803459   \n",
       "alpha_320                                              0.736516  0.839353   \n",
       "ridge_new_411                                          0.755343  0.849061   \n",
       "lr_l1_05                                               0.602618  0.778251   \n",
       "lr_l1_1                                                0.591424  0.757783   \n",
       "lr_l2_01                                               0.612974  0.797388   \n",
       "lr_l2_1                                                0.586523  0.749147   \n",
       "cls05_lgb                                              0.643513  0.837270   \n",
       "cls0_lgb                                               0.880291  0.760855   \n",
       "\n",
       "                                                    catboost1_without_text  \\\n",
       "xentropy_add_lotsof_image_features_lgb                            0.893589   \n",
       "lgb411_tune                                                       0.896485   \n",
       "plants_lgb                                                        0.890247   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                       0.894999   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                0.891253   \n",
       "xentropy_small_lr_cat_lgb                                         0.888887   \n",
       "simple_feature_lgb                                                0.902593   \n",
       "all_mean_enc_lgb                                                  0.903455   \n",
       "all_mean_enc_user_feat_lgb                                        0.902602   \n",
       "all_mean_enc_user_feat2_lgb                                       0.892868   \n",
       "cat_interact_lgb                                                  0.902092   \n",
       "mean_enc_lgb                                                      0.902028   \n",
       "marcus_lgb                                                        0.919560   \n",
       "fused_text_lgb                                                    0.904336   \n",
       "mixed_features_text_proprocessing_lgb                             0.898912   \n",
       "select_dense_features_lgb                                         0.918677   \n",
       "select_sparse_features_lgb                                        0.907917   \n",
       "lgb411_dart_tune                                                  0.897617   \n",
       "lgb411_goss_tune                                                  0.897286   \n",
       "lgb411_goss_tune2                                                 0.897418   \n",
       "poisson_lgb                                                       0.891646   \n",
       "poisson_small_lr_lgb                                              0.894689   \n",
       "small_features_v5_xgb                                             0.911971   \n",
       "small_features_v4_xgb                                             0.908011   \n",
       "nima_features_xgb                                                 0.912601   \n",
       "img_meta_xgb                                                      0.919371   \n",
       "img_meta_nima_xgb                                                 0.918528   \n",
       "xgb_new                                                           0.893105   \n",
       "baseline_xgb                                                      0.885101   \n",
       "ranking_xgb                                                       0.741137   \n",
       "catboost                                                          1.000000   \n",
       "catboost1_without_text                                            1.000000   \n",
       "mcl_cgb                                                           0.911169   \n",
       "cgb_with_categorical                                              0.898974   \n",
       "pretrained_bigru_cv1d_rnn                                         0.888036   \n",
       "pretrained_bigru_attention_rnn                                    0.887385   \n",
       "pretrained_2gru_rnn                                               0.885382   \n",
       "selftrained_bigru_conv1d_rnn                                      0.872626   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                    0.869259   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                0.860682   \n",
       "text_lgb                                                          0.811322   \n",
       "text_cwb_rg                                                       0.729226   \n",
       "text_fm                                                           0.794808   \n",
       "text_rg                                                           0.803529   \n",
       "mlp                                                               0.846260   \n",
       "rf                                                                0.881499   \n",
       "rf_411_7000_leaves                                                0.891610   \n",
       "alpha_0001                                                        0.787240   \n",
       "alpha_160                                                         0.830252   \n",
       "alpha_10                                                          0.803459   \n",
       "alpha_320                                                         0.839353   \n",
       "ridge_new_411                                                     0.849061   \n",
       "lr_l1_05                                                          0.778251   \n",
       "lr_l1_1                                                           0.757783   \n",
       "lr_l2_01                                                          0.797388   \n",
       "lr_l2_1                                                           0.749147   \n",
       "cls05_lgb                                                         0.837270   \n",
       "cls0_lgb                                                          0.760855   \n",
       "\n",
       "                                                     mcl_cgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.972385   \n",
       "lgb411_tune                                         0.976032   \n",
       "plants_lgb                                          0.969725   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.976016   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.971611   \n",
       "xentropy_small_lr_cat_lgb                           0.961636   \n",
       "simple_feature_lgb                                  0.918213   \n",
       "all_mean_enc_lgb                                    0.918551   \n",
       "all_mean_enc_user_feat_lgb                          0.918047   \n",
       "all_mean_enc_user_feat2_lgb                         0.910381   \n",
       "cat_interact_lgb                                    0.913036   \n",
       "mean_enc_lgb                                        0.918151   \n",
       "marcus_lgb                                          0.925841   \n",
       "fused_text_lgb                                      0.928662   \n",
       "mixed_features_text_proprocessing_lgb               0.928638   \n",
       "select_dense_features_lgb                           0.911059   \n",
       "select_sparse_features_lgb                          0.916608   \n",
       "lgb411_dart_tune                                    0.975858   \n",
       "lgb411_goss_tune                                    0.976467   \n",
       "lgb411_goss_tune2                                   0.976997   \n",
       "poisson_lgb                                         0.972201   \n",
       "poisson_small_lr_lgb                                0.975346   \n",
       "small_features_v5_xgb                               0.935648   \n",
       "small_features_v4_xgb                               0.931624   \n",
       "nima_features_xgb                                   0.939565   \n",
       "img_meta_xgb                                        0.940027   \n",
       "img_meta_nima_xgb                                   0.942517   \n",
       "xgb_new                                             0.972272   \n",
       "baseline_xgb                                        0.964860   \n",
       "ranking_xgb                                         0.774139   \n",
       "catboost                                            0.911169   \n",
       "catboost1_without_text                              0.911169   \n",
       "mcl_cgb                                             1.000000   \n",
       "cgb_with_categorical                                0.983371   \n",
       "pretrained_bigru_cv1d_rnn                           0.906421   \n",
       "pretrained_bigru_attention_rnn                      0.905660   \n",
       "pretrained_2gru_rnn                                 0.903111   \n",
       "selftrained_bigru_conv1d_rnn                        0.906813   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.903614   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.915010   \n",
       "text_lgb                                            0.848970   \n",
       "text_cwb_rg                                         0.710759   \n",
       "text_fm                                             0.848899   \n",
       "text_rg                                             0.851632   \n",
       "mlp                                                 0.884223   \n",
       "rf                                                  0.947720   \n",
       "rf_411_7000_leaves                                  0.959204   \n",
       "alpha_0001                                          0.836093   \n",
       "alpha_160                                           0.872388   \n",
       "alpha_10                                            0.852646   \n",
       "alpha_320                                           0.876225   \n",
       "ridge_new_411                                       0.899041   \n",
       "lr_l1_05                                            0.833304   \n",
       "lr_l1_1                                             0.820399   \n",
       "lr_l2_01                                            0.843665   \n",
       "lr_l2_1                                             0.814558   \n",
       "cls05_lgb                                           0.928724   \n",
       "cls0_lgb                                            0.791433   \n",
       "\n",
       "                                                    cgb_with_categorical  \\\n",
       "xentropy_add_lotsof_image_features_lgb                          0.970223   \n",
       "lgb411_tune                                                     0.974701   \n",
       "plants_lgb                                                      0.964663   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                     0.972276   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...              0.968867   \n",
       "xentropy_small_lr_cat_lgb                                       0.956116   \n",
       "simple_feature_lgb                                              0.907633   \n",
       "all_mean_enc_lgb                                                0.908791   \n",
       "all_mean_enc_user_feat_lgb                                      0.908494   \n",
       "all_mean_enc_user_feat2_lgb                                     0.900400   \n",
       "cat_interact_lgb                                                0.903939   \n",
       "mean_enc_lgb                                                    0.908191   \n",
       "marcus_lgb                                                      0.918187   \n",
       "fused_text_lgb                                                  0.917279   \n",
       "mixed_features_text_proprocessing_lgb                           0.917918   \n",
       "select_dense_features_lgb                                       0.903624   \n",
       "select_sparse_features_lgb                                      0.909647   \n",
       "lgb411_dart_tune                                                0.971310   \n",
       "lgb411_goss_tune                                                0.974433   \n",
       "lgb411_goss_tune2                                               0.975571   \n",
       "poisson_lgb                                                     0.968376   \n",
       "poisson_small_lr_lgb                                            0.971617   \n",
       "small_features_v5_xgb                                           0.927811   \n",
       "small_features_v4_xgb                                           0.923697   \n",
       "nima_features_xgb                                               0.931775   \n",
       "img_meta_xgb                                                    0.933331   \n",
       "img_meta_nima_xgb                                               0.935971   \n",
       "xgb_new                                                         0.971047   \n",
       "baseline_xgb                                                    0.962241   \n",
       "ranking_xgb                                                     0.767015   \n",
       "catboost                                                        0.898974   \n",
       "catboost1_without_text                                          0.898974   \n",
       "mcl_cgb                                                         0.983371   \n",
       "cgb_with_categorical                                            1.000000   \n",
       "pretrained_bigru_cv1d_rnn                                       0.896067   \n",
       "pretrained_bigru_attention_rnn                                  0.895247   \n",
       "pretrained_2gru_rnn                                             0.892782   \n",
       "selftrained_bigru_conv1d_rnn                                    0.896155   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                  0.895008   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn              0.907559   \n",
       "text_lgb                                                        0.834495   \n",
       "text_cwb_rg                                                     0.695503   \n",
       "text_fm                                                         0.834020   \n",
       "text_rg                                                         0.836236   \n",
       "mlp                                                             0.872875   \n",
       "rf                                                              0.932678   \n",
       "rf_411_7000_leaves                                              0.946346   \n",
       "alpha_0001                                                      0.822745   \n",
       "alpha_160                                                       0.857989   \n",
       "alpha_10                                                        0.838852   \n",
       "alpha_320                                                       0.861669   \n",
       "ridge_new_411                                                   0.883679   \n",
       "lr_l1_05                                                        0.821529   \n",
       "lr_l1_1                                                         0.808943   \n",
       "lr_l2_01                                                        0.831460   \n",
       "lr_l2_1                                                         0.803197   \n",
       "cls05_lgb                                                       0.927639   \n",
       "cls0_lgb                                                        0.783187   \n",
       "\n",
       "                                                    pretrained_bigru_cv1d_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                               0.892459   \n",
       "lgb411_tune                                                          0.895204   \n",
       "plants_lgb                                                           0.897465   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                          0.891990   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                   0.890066   \n",
       "xentropy_small_lr_cat_lgb                                            0.901173   \n",
       "simple_feature_lgb                                                   0.919504   \n",
       "all_mean_enc_lgb                                                     0.922844   \n",
       "all_mean_enc_user_feat_lgb                                           0.921836   \n",
       "all_mean_enc_user_feat2_lgb                                          0.914385   \n",
       "cat_interact_lgb                                                     0.916719   \n",
       "mean_enc_lgb                                                         0.921847   \n",
       "marcus_lgb                                                           0.919778   \n",
       "fused_text_lgb                                                       0.917589   \n",
       "mixed_features_text_proprocessing_lgb                                0.916229   \n",
       "select_dense_features_lgb                                            0.913667   \n",
       "select_sparse_features_lgb                                           0.914844   \n",
       "lgb411_dart_tune                                                     0.896763   \n",
       "lgb411_goss_tune                                                     0.895743   \n",
       "lgb411_goss_tune2                                                    0.895913   \n",
       "poisson_lgb                                                          0.890068   \n",
       "poisson_small_lr_lgb                                                 0.893223   \n",
       "small_features_v5_xgb                                                0.911734   \n",
       "small_features_v4_xgb                                                0.907881   \n",
       "nima_features_xgb                                                    0.911240   \n",
       "img_meta_xgb                                                         0.907005   \n",
       "img_meta_nima_xgb                                                    0.906398   \n",
       "xgb_new                                                              0.893433   \n",
       "baseline_xgb                                                         0.884244   \n",
       "ranking_xgb                                                          0.723515   \n",
       "catboost                                                             0.888036   \n",
       "catboost1_without_text                                               0.888036   \n",
       "mcl_cgb                                                              0.906421   \n",
       "cgb_with_categorical                                                 0.896067   \n",
       "pretrained_bigru_cv1d_rnn                                            1.000000   \n",
       "pretrained_bigru_attention_rnn                                       0.970911   \n",
       "pretrained_2gru_rnn                                                  0.968960   \n",
       "selftrained_bigru_conv1d_rnn                                         0.953796   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                       0.935166   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                   0.923658   \n",
       "text_lgb                                                             0.849023   \n",
       "text_cwb_rg                                                          0.714940   \n",
       "text_fm                                                              0.834455   \n",
       "text_rg                                                              0.838957   \n",
       "mlp                                                                  0.897684   \n",
       "rf                                                                   0.895275   \n",
       "rf_411_7000_leaves                                                   0.903373   \n",
       "alpha_0001                                                           0.824145   \n",
       "alpha_160                                                            0.864294   \n",
       "alpha_10                                                             0.840836   \n",
       "alpha_320                                                            0.870583   \n",
       "ridge_new_411                                                        0.867369   \n",
       "lr_l1_05                                                             0.831889   \n",
       "lr_l1_1                                                              0.815955   \n",
       "lr_l2_01                                                             0.845514   \n",
       "lr_l2_1                                                              0.808175   \n",
       "cls05_lgb                                                            0.842373   \n",
       "cls0_lgb                                                             0.748887   \n",
       "\n",
       "                                                    pretrained_bigru_attention_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                    0.891782   \n",
       "lgb411_tune                                                               0.894450   \n",
       "plants_lgb                                                                0.896696   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                               0.891134   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                        0.889372   \n",
       "xentropy_small_lr_cat_lgb                                                 0.900185   \n",
       "simple_feature_lgb                                                        0.918586   \n",
       "all_mean_enc_lgb                                                          0.921886   \n",
       "all_mean_enc_user_feat_lgb                                                0.920802   \n",
       "all_mean_enc_user_feat2_lgb                                               0.913422   \n",
       "cat_interact_lgb                                                          0.915921   \n",
       "mean_enc_lgb                                                              0.921070   \n",
       "marcus_lgb                                                                0.918981   \n",
       "fused_text_lgb                                                            0.916410   \n",
       "mixed_features_text_proprocessing_lgb                                     0.914980   \n",
       "select_dense_features_lgb                                                 0.912747   \n",
       "select_sparse_features_lgb                                                0.914060   \n",
       "lgb411_dart_tune                                                          0.896112   \n",
       "lgb411_goss_tune                                                          0.895005   \n",
       "lgb411_goss_tune2                                                         0.895194   \n",
       "poisson_lgb                                                               0.889364   \n",
       "poisson_small_lr_lgb                                                      0.892512   \n",
       "small_features_v5_xgb                                                     0.911048   \n",
       "small_features_v4_xgb                                                     0.907101   \n",
       "nima_features_xgb                                                         0.910508   \n",
       "img_meta_xgb                                                              0.906356   \n",
       "img_meta_nima_xgb                                                         0.905686   \n",
       "xgb_new                                                                   0.892691   \n",
       "baseline_xgb                                                              0.883541   \n",
       "ranking_xgb                                                               0.721852   \n",
       "catboost                                                                  0.887385   \n",
       "catboost1_without_text                                                    0.887385   \n",
       "mcl_cgb                                                                   0.905660   \n",
       "cgb_with_categorical                                                      0.895247   \n",
       "pretrained_bigru_cv1d_rnn                                                 0.970911   \n",
       "pretrained_bigru_attention_rnn                                            1.000000   \n",
       "pretrained_2gru_rnn                                                       0.966881   \n",
       "selftrained_bigru_conv1d_rnn                                              0.952309   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                            0.933630   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                        0.921827   \n",
       "text_lgb                                                                  0.848229   \n",
       "text_cwb_rg                                                               0.715935   \n",
       "text_fm                                                                   0.834031   \n",
       "text_rg                                                                   0.838447   \n",
       "mlp                                                                       0.897399   \n",
       "rf                                                                        0.894214   \n",
       "rf_411_7000_leaves                                                        0.902575   \n",
       "alpha_0001                                                                0.823576   \n",
       "alpha_160                                                                 0.863698   \n",
       "alpha_10                                                                  0.840236   \n",
       "alpha_320                                                                 0.869998   \n",
       "ridge_new_411                                                             0.866900   \n",
       "lr_l1_05                                                                  0.831351   \n",
       "lr_l1_1                                                                   0.815478   \n",
       "lr_l2_01                                                                  0.845075   \n",
       "lr_l2_1                                                                   0.807718   \n",
       "cls05_lgb                                                                 0.842070   \n",
       "cls0_lgb                                                                  0.747406   \n",
       "\n",
       "                                                    pretrained_2gru_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                         0.889217   \n",
       "lgb411_tune                                                    0.891942   \n",
       "plants_lgb                                                     0.894225   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                    0.888897   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...             0.886792   \n",
       "xentropy_small_lr_cat_lgb                                      0.897477   \n",
       "simple_feature_lgb                                             0.916392   \n",
       "all_mean_enc_lgb                                               0.919655   \n",
       "all_mean_enc_user_feat_lgb                                     0.918679   \n",
       "all_mean_enc_user_feat2_lgb                                    0.911270   \n",
       "cat_interact_lgb                                               0.913904   \n",
       "mean_enc_lgb                                                   0.918656   \n",
       "marcus_lgb                                                     0.916932   \n",
       "fused_text_lgb                                                 0.914216   \n",
       "mixed_features_text_proprocessing_lgb                          0.912850   \n",
       "select_dense_features_lgb                                      0.911341   \n",
       "select_sparse_features_lgb                                     0.912147   \n",
       "lgb411_dart_tune                                               0.893587   \n",
       "lgb411_goss_tune                                               0.892570   \n",
       "lgb411_goss_tune2                                              0.892643   \n",
       "poisson_lgb                                                    0.886849   \n",
       "poisson_small_lr_lgb                                           0.890005   \n",
       "small_features_v5_xgb                                          0.908847   \n",
       "small_features_v4_xgb                                          0.904934   \n",
       "nima_features_xgb                                              0.908305   \n",
       "img_meta_xgb                                                   0.904119   \n",
       "img_meta_nima_xgb                                              0.903453   \n",
       "xgb_new                                                        0.890199   \n",
       "baseline_xgb                                                   0.880995   \n",
       "ranking_xgb                                                    0.722929   \n",
       "catboost                                                       0.885382   \n",
       "catboost1_without_text                                         0.885382   \n",
       "mcl_cgb                                                        0.903111   \n",
       "cgb_with_categorical                                           0.892782   \n",
       "pretrained_bigru_cv1d_rnn                                      0.968960   \n",
       "pretrained_bigru_attention_rnn                                 0.966881   \n",
       "pretrained_2gru_rnn                                            1.000000   \n",
       "selftrained_bigru_conv1d_rnn                                   0.949535   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                 0.931613   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn             0.919855   \n",
       "text_lgb                                                       0.845857   \n",
       "text_cwb_rg                                                    0.712184   \n",
       "text_fm                                                        0.831046   \n",
       "text_rg                                                        0.835543   \n",
       "mlp                                                            0.894728   \n",
       "rf                                                             0.891733   \n",
       "rf_411_7000_leaves                                             0.900000   \n",
       "alpha_0001                                                     0.820945   \n",
       "alpha_160                                                      0.860862   \n",
       "alpha_10                                                       0.837553   \n",
       "alpha_320                                                      0.867146   \n",
       "ridge_new_411                                                  0.863973   \n",
       "lr_l1_05                                                       0.828514   \n",
       "lr_l1_1                                                        0.812761   \n",
       "lr_l2_01                                                       0.842175   \n",
       "lr_l2_1                                                        0.805075   \n",
       "cls05_lgb                                                      0.838464   \n",
       "cls0_lgb                                                       0.748642   \n",
       "\n",
       "                                                    selftrained_bigru_conv1d_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                  0.891598   \n",
       "lgb411_tune                                                             0.894094   \n",
       "plants_lgb                                                              0.897245   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                             0.891522   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                      0.889311   \n",
       "xentropy_small_lr_cat_lgb                                               0.899517   \n",
       "simple_feature_lgb                                                      0.914868   \n",
       "all_mean_enc_lgb                                                        0.917843   \n",
       "all_mean_enc_user_feat_lgb                                              0.916663   \n",
       "all_mean_enc_user_feat2_lgb                                             0.909777   \n",
       "cat_interact_lgb                                                        0.910945   \n",
       "mean_enc_lgb                                                            0.917476   \n",
       "marcus_lgb                                                              0.912860   \n",
       "fused_text_lgb                                                          0.915931   \n",
       "mixed_features_text_proprocessing_lgb                                   0.915627   \n",
       "select_dense_features_lgb                                               0.900438   \n",
       "select_sparse_features_lgb                                              0.907708   \n",
       "lgb411_dart_tune                                                        0.896312   \n",
       "lgb411_goss_tune                                                        0.894714   \n",
       "lgb411_goss_tune2                                                       0.894810   \n",
       "poisson_lgb                                                             0.889476   \n",
       "poisson_small_lr_lgb                                                    0.892716   \n",
       "small_features_v5_xgb                                                   0.910415   \n",
       "small_features_v4_xgb                                                   0.906435   \n",
       "nima_features_xgb                                                       0.910069   \n",
       "img_meta_xgb                                                            0.905936   \n",
       "img_meta_nima_xgb                                                       0.905387   \n",
       "xgb_new                                                                 0.892815   \n",
       "baseline_xgb                                                            0.883780   \n",
       "ranking_xgb                                                             0.717453   \n",
       "catboost                                                                0.872626   \n",
       "catboost1_without_text                                                  0.872626   \n",
       "mcl_cgb                                                                 0.906813   \n",
       "cgb_with_categorical                                                    0.896155   \n",
       "pretrained_bigru_cv1d_rnn                                               0.953796   \n",
       "pretrained_bigru_attention_rnn                                          0.952309   \n",
       "pretrained_2gru_rnn                                                     0.949535   \n",
       "selftrained_bigru_conv1d_rnn                                            1.000000   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                          0.944339   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                      0.932336   \n",
       "text_lgb                                                                0.859459   \n",
       "text_cwb_rg                                                             0.708776   \n",
       "text_fm                                                                 0.847166   \n",
       "text_rg                                                                 0.850304   \n",
       "mlp                                                                     0.906238   \n",
       "rf                                                                      0.900735   \n",
       "rf_411_7000_leaves                                                      0.907731   \n",
       "alpha_0001                                                              0.833640   \n",
       "alpha_160                                                               0.872537   \n",
       "alpha_10                                                                0.850473   \n",
       "alpha_320                                                               0.877578   \n",
       "ridge_new_411                                                           0.872210   \n",
       "lr_l1_05                                                                0.843599   \n",
       "lr_l1_1                                                                 0.829074   \n",
       "lr_l2_01                                                                0.854190   \n",
       "lr_l2_1                                                                 0.821526   \n",
       "cls05_lgb                                                               0.842529   \n",
       "cls0_lgb                                                                0.743855   \n",
       "\n",
       "                                                    selftrained_bigru_conv1d_merged_with_image_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                                    0.900249   \n",
       "lgb411_tune                                                                               0.896064   \n",
       "plants_lgb                                                                                0.892095   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                               0.891001   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                                        0.890608   \n",
       "xentropy_small_lr_cat_lgb                                                                 0.900388   \n",
       "simple_feature_lgb                                                                        0.907114   \n",
       "all_mean_enc_lgb                                                                          0.910287   \n",
       "all_mean_enc_user_feat_lgb                                                                0.909152   \n",
       "all_mean_enc_user_feat2_lgb                                                               0.900854   \n",
       "cat_interact_lgb                                                                          0.904098   \n",
       "mean_enc_lgb                                                                              0.909692   \n",
       "marcus_lgb                                                                                0.910647   \n",
       "fused_text_lgb                                                                            0.905832   \n",
       "mixed_features_text_proprocessing_lgb                                                     0.906177   \n",
       "select_dense_features_lgb                                                                 0.899333   \n",
       "select_sparse_features_lgb                                                                0.906939   \n",
       "lgb411_dart_tune                                                                          0.896231   \n",
       "lgb411_goss_tune                                                                          0.896516   \n",
       "lgb411_goss_tune2                                                                         0.896912   \n",
       "poisson_lgb                                                                               0.890624   \n",
       "poisson_small_lr_lgb                                                                      0.893784   \n",
       "small_features_v5_xgb                                                                     0.901820   \n",
       "small_features_v4_xgb                                                                     0.897812   \n",
       "nima_features_xgb                                                                         0.902554   \n",
       "img_meta_xgb                                                                              0.901449   \n",
       "img_meta_nima_xgb                                                                         0.901533   \n",
       "xgb_new                                                                                   0.893667   \n",
       "baseline_xgb                                                                              0.884758   \n",
       "ranking_xgb                                                                               0.707121   \n",
       "catboost                                                                                  0.869259   \n",
       "catboost1_without_text                                                                    0.869259   \n",
       "mcl_cgb                                                                                   0.903614   \n",
       "cgb_with_categorical                                                                      0.895008   \n",
       "pretrained_bigru_cv1d_rnn                                                                 0.935166   \n",
       "pretrained_bigru_attention_rnn                                                            0.933630   \n",
       "pretrained_2gru_rnn                                                                       0.931613   \n",
       "selftrained_bigru_conv1d_rnn                                                              0.944339   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                            1.000000   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                                        0.943779   \n",
       "text_lgb                                                                                  0.828863   \n",
       "text_cwb_rg                                                                               0.680382   \n",
       "text_fm                                                                                   0.817753   \n",
       "text_rg                                                                                   0.820265   \n",
       "mlp                                                                                       0.877434   \n",
       "rf                                                                                        0.881505   \n",
       "rf_411_7000_leaves                                                                        0.890991   \n",
       "alpha_0001                                                                                0.807451   \n",
       "alpha_160                                                                                 0.844318   \n",
       "alpha_10                                                                                  0.823500   \n",
       "alpha_320                                                                                 0.849011   \n",
       "ridge_new_411                                                                             0.846478   \n",
       "lr_l1_05                                                                                  0.819210   \n",
       "lr_l1_1                                                                                   0.805552   \n",
       "lr_l2_01                                                                                  0.829565   \n",
       "lr_l2_1                                                                                   0.798523   \n",
       "cls05_lgb                                                                                 0.849337   \n",
       "cls0_lgb                                                                                  0.727658   \n",
       "\n",
       "                                                    selftrained_bigru_conv1d_merged_with_image_adv_rnn  \\\n",
       "xentropy_add_lotsof_image_features_lgb                                                       0.915566    \n",
       "lgb411_tune                                                                                  0.912031    \n",
       "plants_lgb                                                                                   0.903323    \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                                                  0.904735    \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...                                           0.906435    \n",
       "xentropy_small_lr_cat_lgb                                                                    0.912177    \n",
       "simple_feature_lgb                                                                           0.898792    \n",
       "all_mean_enc_lgb                                                                             0.901655    \n",
       "all_mean_enc_user_feat_lgb                                                                   0.900557    \n",
       "all_mean_enc_user_feat2_lgb                                                                  0.893011    \n",
       "cat_interact_lgb                                                                             0.895602    \n",
       "mean_enc_lgb                                                                                 0.901170    \n",
       "marcus_lgb                                                                                   0.902576    \n",
       "fused_text_lgb                                                                               0.896022    \n",
       "mixed_features_text_proprocessing_lgb                                                        0.897084    \n",
       "select_dense_features_lgb                                                                    0.893267    \n",
       "select_sparse_features_lgb                                                                   0.900848    \n",
       "lgb411_dart_tune                                                                             0.910889    \n",
       "lgb411_goss_tune                                                                             0.911942    \n",
       "lgb411_goss_tune2                                                                            0.912926    \n",
       "poisson_lgb                                                                                  0.906531    \n",
       "poisson_small_lr_lgb                                                                         0.909592    \n",
       "small_features_v5_xgb                                                                        0.893911    \n",
       "small_features_v4_xgb                                                                        0.889862    \n",
       "nima_features_xgb                                                                            0.896499    \n",
       "img_meta_xgb                                                                                 0.893833    \n",
       "img_meta_nima_xgb                                                                            0.895538    \n",
       "xgb_new                                                                                      0.909740    \n",
       "baseline_xgb                                                                                 0.900193    \n",
       "ranking_xgb                                                                                  0.709372    \n",
       "catboost                                                                                     0.860682    \n",
       "catboost1_without_text                                                                       0.860682    \n",
       "mcl_cgb                                                                                      0.915010    \n",
       "cgb_with_categorical                                                                         0.907559    \n",
       "pretrained_bigru_cv1d_rnn                                                                    0.923658    \n",
       "pretrained_bigru_attention_rnn                                                               0.921827    \n",
       "pretrained_2gru_rnn                                                                          0.919855    \n",
       "selftrained_bigru_conv1d_rnn                                                                 0.932336    \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                                               0.943779    \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn                                           1.000000    \n",
       "text_lgb                                                                                     0.818871    \n",
       "text_cwb_rg                                                                                  0.672434    \n",
       "text_fm                                                                                      0.808287    \n",
       "text_rg                                                                                      0.810838    \n",
       "mlp                                                                                          0.866732    \n",
       "rf                                                                                           0.879680    \n",
       "rf_411_7000_leaves                                                                           0.891077    \n",
       "alpha_0001                                                                                   0.798445    \n",
       "alpha_160                                                                                    0.834788    \n",
       "alpha_10                                                                                     0.814161    \n",
       "alpha_320                                                                                    0.839543    \n",
       "ridge_new_411                                                                                0.840113    \n",
       "lr_l1_05                                                                                     0.808935    \n",
       "lr_l1_1                                                                                      0.795194    \n",
       "lr_l2_01                                                                                     0.819298    \n",
       "lr_l2_1                                                                                      0.788117    \n",
       "cls05_lgb                                                                                    0.866651    \n",
       "cls0_lgb                                                                                     0.733800    \n",
       "\n",
       "                                                    text_lgb  text_cwb_rg  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.822430     0.685411   \n",
       "lgb411_tune                                         0.823135     0.685161   \n",
       "plants_lgb                                          0.835321     0.695687   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.828427     0.690939   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.821424     0.684999   \n",
       "xentropy_small_lr_cat_lgb                           0.827092     0.686990   \n",
       "simple_feature_lgb                                  0.869182     0.716797   \n",
       "all_mean_enc_lgb                                    0.866855     0.710733   \n",
       "all_mean_enc_user_feat_lgb                          0.865516     0.709698   \n",
       "all_mean_enc_user_feat2_lgb                         0.871939     0.715363   \n",
       "cat_interact_lgb                                    0.862606     0.710778   \n",
       "mean_enc_lgb                                        0.869846     0.712374   \n",
       "marcus_lgb                                          0.852152     0.701711   \n",
       "fused_text_lgb                                      0.866779     0.715492   \n",
       "mixed_features_text_proprocessing_lgb               0.868076     0.710091   \n",
       "select_dense_features_lgb                           0.823182     0.705327   \n",
       "select_sparse_features_lgb                          0.841794     0.695711   \n",
       "lgb411_dart_tune                                    0.834262     0.699198   \n",
       "lgb411_goss_tune                                    0.825209     0.687254   \n",
       "lgb411_goss_tune2                                   0.823791     0.685681   \n",
       "poisson_lgb                                         0.823106     0.687793   \n",
       "poisson_small_lr_lgb                                0.826004     0.689999   \n",
       "small_features_v5_xgb                               0.850251     0.702433   \n",
       "small_features_v4_xgb                               0.847049     0.699813   \n",
       "nima_features_xgb                                   0.851777     0.704198   \n",
       "img_meta_xgb                                        0.848667     0.701815   \n",
       "img_meta_nima_xgb                                   0.849234     0.702643   \n",
       "xgb_new                                             0.822751     0.685213   \n",
       "baseline_xgb                                        0.816482     0.680675   \n",
       "ranking_xgb                                         0.689818     0.628618   \n",
       "catboost                                            0.811322     0.729226   \n",
       "catboost1_without_text                              0.811322     0.729226   \n",
       "mcl_cgb                                             0.848970     0.710759   \n",
       "cgb_with_categorical                                0.834495     0.695503   \n",
       "pretrained_bigru_cv1d_rnn                           0.849023     0.714940   \n",
       "pretrained_bigru_attention_rnn                      0.848229     0.715935   \n",
       "pretrained_2gru_rnn                                 0.845857     0.712184   \n",
       "selftrained_bigru_conv1d_rnn                        0.859459     0.708776   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.828863     0.680382   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.818871     0.672434   \n",
       "text_lgb                                            1.000000     0.788162   \n",
       "text_cwb_rg                                         0.788162     1.000000   \n",
       "text_fm                                             0.940994     0.768838   \n",
       "text_rg                                             0.947320     0.789577   \n",
       "mlp                                                 0.886745     0.716294   \n",
       "rf                                                  0.904824     0.773523   \n",
       "rf_411_7000_leaves                                  0.898917     0.764218   \n",
       "alpha_0001                                          0.872291     0.717921   \n",
       "alpha_160                                           0.914040     0.766546   \n",
       "alpha_10                                            0.891084     0.734738   \n",
       "alpha_320                                           0.918478     0.778527   \n",
       "ridge_new_411                                       0.897974     0.778525   \n",
       "lr_l1_05                                            0.859582     0.672195   \n",
       "lr_l1_1                                             0.843389     0.651171   \n",
       "lr_l2_01                                            0.866778     0.692946   \n",
       "lr_l2_1                                             0.834438     0.642389   \n",
       "cls05_lgb                                           0.773886     0.617066   \n",
       "cls0_lgb                                            0.712138     0.661407   \n",
       "\n",
       "                                                     text_fm   text_rg  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.821406  0.823256   \n",
       "lgb411_tune                                         0.821971  0.823708   \n",
       "plants_lgb                                          0.834781  0.836749   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.827950  0.830028   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.820779  0.822768   \n",
       "xentropy_small_lr_cat_lgb                           0.827854  0.829751   \n",
       "simple_feature_lgb                                  0.849560  0.853084   \n",
       "all_mean_enc_lgb                                    0.846129  0.848887   \n",
       "all_mean_enc_user_feat_lgb                          0.844977  0.847646   \n",
       "all_mean_enc_user_feat2_lgb                         0.851349  0.854074   \n",
       "cat_interact_lgb                                    0.841915  0.845153   \n",
       "mean_enc_lgb                                        0.849202  0.851942   \n",
       "marcus_lgb                                          0.832332  0.835086   \n",
       "fused_text_lgb                                      0.868791  0.870874   \n",
       "mixed_features_text_proprocessing_lgb               0.867281  0.868427   \n",
       "select_dense_features_lgb                           0.804784  0.809867   \n",
       "select_sparse_features_lgb                          0.821912  0.824401   \n",
       "lgb411_dart_tune                                    0.834251  0.836672   \n",
       "lgb411_goss_tune                                    0.824191  0.825979   \n",
       "lgb411_goss_tune2                                   0.822673  0.824458   \n",
       "poisson_lgb                                         0.822702  0.824834   \n",
       "poisson_small_lr_lgb                                0.825559  0.827687   \n",
       "small_features_v5_xgb                               0.847868  0.849526   \n",
       "small_features_v4_xgb                               0.844865  0.846549   \n",
       "nima_features_xgb                                   0.849669  0.851503   \n",
       "img_meta_xgb                                        0.846402  0.848316   \n",
       "img_meta_nima_xgb                                   0.847204  0.849195   \n",
       "xgb_new                                             0.820821  0.822538   \n",
       "baseline_xgb                                        0.815321  0.817191   \n",
       "ranking_xgb                                         0.696715  0.703082   \n",
       "catboost                                            0.794808  0.803529   \n",
       "catboost1_without_text                              0.794808  0.803529   \n",
       "mcl_cgb                                             0.848899  0.851632   \n",
       "cgb_with_categorical                                0.834020  0.836236   \n",
       "pretrained_bigru_cv1d_rnn                           0.834455  0.838957   \n",
       "pretrained_bigru_attention_rnn                      0.834031  0.838447   \n",
       "pretrained_2gru_rnn                                 0.831046  0.835543   \n",
       "selftrained_bigru_conv1d_rnn                        0.847166  0.850304   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.817753  0.820265   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.808287  0.810838   \n",
       "text_lgb                                            0.940994  0.947320   \n",
       "text_cwb_rg                                         0.768838  0.789577   \n",
       "text_fm                                             1.000000  0.992530   \n",
       "text_rg                                             0.992530  1.000000   \n",
       "mlp                                                 0.895938  0.890810   \n",
       "rf                                                  0.911534  0.916779   \n",
       "rf_411_7000_leaves                                  0.903622  0.908041   \n",
       "alpha_0001                                          0.923028  0.918645   \n",
       "alpha_160                                           0.952428  0.956040   \n",
       "alpha_10                                            0.941819  0.938341   \n",
       "alpha_320                                           0.949769  0.956755   \n",
       "ridge_new_411                                       0.915000  0.921706   \n",
       "lr_l1_05                                            0.868349  0.871884   \n",
       "lr_l1_1                                             0.865318  0.863262   \n",
       "lr_l2_01                                            0.875062  0.880309   \n",
       "lr_l2_1                                             0.863841  0.859124   \n",
       "cls05_lgb                                           0.769777  0.770324   \n",
       "cls0_lgb                                            0.713722  0.722905   \n",
       "\n",
       "                                                         mlp        rf  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.864836  0.921385   \n",
       "lgb411_tune                                         0.866779  0.922428   \n",
       "plants_lgb                                          0.874204  0.931922   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.867792  0.927867   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.862835  0.921629   \n",
       "xentropy_small_lr_cat_lgb                           0.872978  0.922925   \n",
       "simple_feature_lgb                                  0.893489  0.904446   \n",
       "all_mean_enc_lgb                                    0.896498  0.902194   \n",
       "all_mean_enc_user_feat_lgb                          0.896866  0.901531   \n",
       "all_mean_enc_user_feat2_lgb                         0.891481  0.896152   \n",
       "cat_interact_lgb                                    0.891943  0.895244   \n",
       "mean_enc_lgb                                        0.897334  0.903146   \n",
       "marcus_lgb                                          0.887590  0.895948   \n",
       "fused_text_lgb                                      0.900485  0.921293   \n",
       "mixed_features_text_proprocessing_lgb               0.900056  0.919177   \n",
       "select_dense_features_lgb                           0.866792  0.880062   \n",
       "select_sparse_features_lgb                          0.877851  0.885836   \n",
       "lgb411_dart_tune                                    0.870983  0.935395   \n",
       "lgb411_goss_tune                                    0.868194  0.924613   \n",
       "lgb411_goss_tune2                                   0.867342  0.922978   \n",
       "poisson_lgb                                         0.863948  0.924469   \n",
       "poisson_small_lr_lgb                                0.867124  0.927577   \n",
       "small_features_v5_xgb                               0.890831  0.914004   \n",
       "small_features_v4_xgb                               0.887099  0.910404   \n",
       "nima_features_xgb                                   0.891333  0.916381   \n",
       "img_meta_xgb                                        0.887415  0.913126   \n",
       "img_meta_nima_xgb                                   0.887269  0.914289   \n",
       "xgb_new                                             0.865363  0.925431   \n",
       "baseline_xgb                                        0.857438  0.917079   \n",
       "ranking_xgb                                         0.709817  0.753216   \n",
       "catboost                                            0.846260  0.881499   \n",
       "catboost1_without_text                              0.846260  0.881499   \n",
       "mcl_cgb                                             0.884223  0.947720   \n",
       "cgb_with_categorical                                0.872875  0.932678   \n",
       "pretrained_bigru_cv1d_rnn                           0.897684  0.895275   \n",
       "pretrained_bigru_attention_rnn                      0.897399  0.894214   \n",
       "pretrained_2gru_rnn                                 0.894728  0.891733   \n",
       "selftrained_bigru_conv1d_rnn                        0.906238  0.900735   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.877434  0.881505   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.866732  0.879680   \n",
       "text_lgb                                            0.886745  0.904824   \n",
       "text_cwb_rg                                         0.716294  0.773523   \n",
       "text_fm                                             0.895938  0.911534   \n",
       "text_rg                                             0.890810  0.916779   \n",
       "mlp                                                 1.000000  0.907552   \n",
       "rf                                                  0.907552  1.000000   \n",
       "rf_411_7000_leaves                                  0.911592  0.994529   \n",
       "alpha_0001                                          0.879176  0.880049   \n",
       "alpha_160                                           0.914453  0.920631   \n",
       "alpha_10                                            0.897046  0.898531   \n",
       "alpha_320                                           0.916009  0.924923   \n",
       "ridge_new_411                                       0.897979  0.947094   \n",
       "lr_l1_05                                            0.885489  0.868474   \n",
       "lr_l1_1                                             0.878420  0.854522   \n",
       "lr_l2_01                                            0.892664  0.880176   \n",
       "lr_l2_1                                             0.874183  0.848294   \n",
       "cls05_lgb                                           0.815301  0.870954   \n",
       "cls0_lgb                                            0.728305  0.779519   \n",
       "\n",
       "                                                    rf_411_7000_leaves  \\\n",
       "xentropy_add_lotsof_image_features_lgb                        0.935732   \n",
       "lgb411_tune                                                   0.937665   \n",
       "plants_lgb                                                    0.942972   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb                   0.941243   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...            0.935721   \n",
       "xentropy_small_lr_cat_lgb                                     0.934852   \n",
       "simple_feature_lgb                                            0.912592   \n",
       "all_mean_enc_lgb                                              0.911263   \n",
       "all_mean_enc_user_feat_lgb                                    0.910878   \n",
       "all_mean_enc_user_feat2_lgb                                   0.904491   \n",
       "cat_interact_lgb                                              0.904639   \n",
       "mean_enc_lgb                                                  0.911783   \n",
       "marcus_lgb                                                    0.908071   \n",
       "fused_text_lgb                                                0.927609   \n",
       "mixed_features_text_proprocessing_lgb                         0.926004   \n",
       "select_dense_features_lgb                                     0.893396   \n",
       "select_sparse_features_lgb                                    0.899280   \n",
       "lgb411_dart_tune                                              0.948653   \n",
       "lgb411_goss_tune                                              0.939247   \n",
       "lgb411_goss_tune2                                             0.938183   \n",
       "poisson_lgb                                                   0.937688   \n",
       "poisson_small_lr_lgb                                          0.940851   \n",
       "small_features_v5_xgb                                         0.924785   \n",
       "small_features_v4_xgb                                         0.921047   \n",
       "nima_features_xgb                                             0.927977   \n",
       "img_meta_xgb                                                  0.924500   \n",
       "img_meta_nima_xgb                                             0.926364   \n",
       "xgb_new                                                       0.940940   \n",
       "baseline_xgb                                                  0.931035   \n",
       "ranking_xgb                                                   0.760580   \n",
       "catboost                                                      0.891610   \n",
       "catboost1_without_text                                        0.891610   \n",
       "mcl_cgb                                                       0.959204   \n",
       "cgb_with_categorical                                          0.946346   \n",
       "pretrained_bigru_cv1d_rnn                                     0.903373   \n",
       "pretrained_bigru_attention_rnn                                0.902575   \n",
       "pretrained_2gru_rnn                                           0.900000   \n",
       "selftrained_bigru_conv1d_rnn                                  0.907731   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn                0.890991   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn            0.891077   \n",
       "text_lgb                                                      0.898917   \n",
       "text_cwb_rg                                                   0.764218   \n",
       "text_fm                                                       0.903622   \n",
       "text_rg                                                       0.908041   \n",
       "mlp                                                           0.911592   \n",
       "rf                                                            0.994529   \n",
       "rf_411_7000_leaves                                            1.000000   \n",
       "alpha_0001                                                    0.876458   \n",
       "alpha_160                                                     0.916401   \n",
       "alpha_10                                                      0.894651   \n",
       "alpha_320                                                     0.920632   \n",
       "ridge_new_411                                                 0.942171   \n",
       "lr_l1_05                                                      0.867728   \n",
       "lr_l1_1                                                       0.853907   \n",
       "lr_l2_01                                                      0.879102   \n",
       "lr_l2_1                                                       0.847669   \n",
       "cls05_lgb                                                     0.886803   \n",
       "cls0_lgb                                                      0.785022   \n",
       "\n",
       "                                                    alpha_0001  alpha_160  \\\n",
       "xentropy_add_lotsof_image_features_lgb                0.811904   0.846438   \n",
       "lgb411_tune                                           0.813002   0.847543   \n",
       "plants_lgb                                            0.824736   0.860072   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb           0.818223   0.853142   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...    0.811344   0.845992   \n",
       "xentropy_small_lr_cat_lgb                             0.821121   0.856480   \n",
       "simple_feature_lgb                                    0.841548   0.880072   \n",
       "all_mean_enc_lgb                                      0.846315   0.878901   \n",
       "all_mean_enc_user_feat_lgb                            0.846989   0.879539   \n",
       "all_mean_enc_user_feat2_lgb                           0.843902   0.877224   \n",
       "cat_interact_lgb                                      0.835859   0.873883   \n",
       "mean_enc_lgb                                          0.848833   0.881341   \n",
       "marcus_lgb                                            0.825604   0.863308   \n",
       "fused_text_lgb                                        0.853381   0.891558   \n",
       "mixed_features_text_proprocessing_lgb                 0.852450   0.889281   \n",
       "select_dense_features_lgb                             0.797980   0.839233   \n",
       "select_sparse_features_lgb                            0.813741   0.851746   \n",
       "lgb411_dart_tune                                      0.822557   0.858009   \n",
       "lgb411_goss_tune                                      0.815271   0.849882   \n",
       "lgb411_goss_tune2                                     0.813841   0.848415   \n",
       "poisson_lgb                                           0.812784   0.847676   \n",
       "poisson_small_lr_lgb                                  0.815649   0.850684   \n",
       "small_features_v5_xgb                                 0.832539   0.868728   \n",
       "small_features_v4_xgb                                 0.829478   0.865605   \n",
       "nima_features_xgb                                     0.833880   0.870432   \n",
       "img_meta_xgb                                          0.830441   0.866846   \n",
       "img_meta_nima_xgb                                     0.830877   0.867503   \n",
       "xgb_new                                               0.810176   0.844804   \n",
       "baseline_xgb                                          0.805885   0.840286   \n",
       "ranking_xgb                                           0.697815   0.731386   \n",
       "catboost                                              0.787240   0.830252   \n",
       "catboost1_without_text                                0.787240   0.830252   \n",
       "mcl_cgb                                               0.836093   0.872388   \n",
       "cgb_with_categorical                                  0.822745   0.857989   \n",
       "pretrained_bigru_cv1d_rnn                             0.824145   0.864294   \n",
       "pretrained_bigru_attention_rnn                        0.823576   0.863698   \n",
       "pretrained_2gru_rnn                                   0.820945   0.860862   \n",
       "selftrained_bigru_conv1d_rnn                          0.833640   0.872537   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn        0.807451   0.844318   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn    0.798445   0.834788   \n",
       "text_lgb                                              0.872291   0.914040   \n",
       "text_cwb_rg                                           0.717921   0.766546   \n",
       "text_fm                                               0.923028   0.952428   \n",
       "text_rg                                               0.918645   0.956040   \n",
       "mlp                                                   0.879176   0.914453   \n",
       "rf                                                    0.880049   0.920631   \n",
       "rf_411_7000_leaves                                    0.876458   0.916401   \n",
       "alpha_0001                                            1.000000   0.967830   \n",
       "alpha_160                                             0.967830   1.000000   \n",
       "alpha_10                                              0.993234   0.987128   \n",
       "alpha_320                                             0.957903   0.998369   \n",
       "ridge_new_411                                         0.905166   0.948172   \n",
       "lr_l1_05                                              0.871821   0.908484   \n",
       "lr_l1_1                                               0.879716   0.903209   \n",
       "lr_l2_01                                              0.874106   0.915742   \n",
       "lr_l2_1                                               0.883194   0.900263   \n",
       "cls05_lgb                                             0.758149   0.788835   \n",
       "cls0_lgb                                              0.705350   0.740193   \n",
       "\n",
       "                                                    alpha_10  alpha_320  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.827642   0.850100   \n",
       "lgb411_tune                                         0.828779   0.851161   \n",
       "plants_lgb                                          0.840884   0.863767   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.834198   0.856787   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.827171   0.849634   \n",
       "xentropy_small_lr_cat_lgb                           0.837466   0.859861   \n",
       "simple_feature_lgb                                  0.858496   0.884830   \n",
       "all_mean_enc_lgb                                    0.860962   0.882902   \n",
       "all_mean_enc_user_feat_lgb                          0.861631   0.883506   \n",
       "all_mean_enc_user_feat2_lgb                         0.858859   0.881255   \n",
       "cat_interact_lgb                                    0.852646   0.878525   \n",
       "mean_enc_lgb                                        0.863476   0.885262   \n",
       "marcus_lgb                                          0.842154   0.867993   \n",
       "fused_text_lgb                                      0.870849   0.895356   \n",
       "mixed_features_text_proprocessing_lgb               0.869725   0.892455   \n",
       "select_dense_features_lgb                           0.814377   0.846704   \n",
       "select_sparse_features_lgb                          0.830083   0.856936   \n",
       "lgb411_dart_tune                                    0.838689   0.861811   \n",
       "lgb411_goss_tune                                    0.831110   0.853491   \n",
       "lgb411_goss_tune2                                   0.829625   0.852047   \n",
       "poisson_lgb                                         0.828704   0.851360   \n",
       "poisson_small_lr_lgb                                0.831653   0.854368   \n",
       "small_features_v5_xgb                               0.848975   0.872565   \n",
       "small_features_v4_xgb                               0.845877   0.869439   \n",
       "nima_features_xgb                                   0.850466   0.874324   \n",
       "img_meta_xgb                                        0.846931   0.870755   \n",
       "img_meta_nima_xgb                                   0.847454   0.871452   \n",
       "xgb_new                                             0.825969   0.848448   \n",
       "baseline_xgb                                        0.821631   0.843861   \n",
       "ranking_xgb                                         0.711790   0.736516   \n",
       "catboost                                            0.803459   0.839353   \n",
       "catboost1_without_text                              0.803459   0.839353   \n",
       "mcl_cgb                                             0.852646   0.876225   \n",
       "cgb_with_categorical                                0.838852   0.861669   \n",
       "pretrained_bigru_cv1d_rnn                           0.840836   0.870583   \n",
       "pretrained_bigru_attention_rnn                      0.840236   0.869998   \n",
       "pretrained_2gru_rnn                                 0.837553   0.867146   \n",
       "selftrained_bigru_conv1d_rnn                        0.850473   0.877578   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.823500   0.849011   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.814161   0.839543   \n",
       "text_lgb                                            0.891084   0.918478   \n",
       "text_cwb_rg                                         0.734738   0.778527   \n",
       "text_fm                                             0.941819   0.949769   \n",
       "text_rg                                             0.938341   0.956755   \n",
       "mlp                                                 0.897046   0.916009   \n",
       "rf                                                  0.898531   0.924923   \n",
       "rf_411_7000_leaves                                  0.894651   0.920632   \n",
       "alpha_0001                                          0.993234   0.957903   \n",
       "alpha_160                                           0.987128   0.998369   \n",
       "alpha_10                                            1.000000   0.978444   \n",
       "alpha_320                                           0.978444   1.000000   \n",
       "ridge_new_411                                       0.924500   0.953059   \n",
       "lr_l1_05                                            0.890701   0.909061   \n",
       "lr_l1_1                                             0.896439   0.898929   \n",
       "lr_l2_01                                            0.893548   0.919034   \n",
       "lr_l2_1                                             0.898729   0.893928   \n",
       "cls05_lgb                                           0.772767   0.791272   \n",
       "cls0_lgb                                            0.719560   0.746015   \n",
       "\n",
       "                                                    ridge_new_411  lr_l1_05  \\\n",
       "xentropy_add_lotsof_image_features_lgb                   0.872428  0.811401   \n",
       "lgb411_tune                                              0.873289  0.813043   \n",
       "plants_lgb                                               0.880408  0.823825   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb              0.879468  0.816884   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...       0.872109  0.811378   \n",
       "xentropy_small_lr_cat_lgb                                0.881965  0.821350   \n",
       "simple_feature_lgb                                       0.875719  0.838050   \n",
       "all_mean_enc_lgb                                         0.872686  0.840290   \n",
       "all_mean_enc_user_feat_lgb                               0.871553  0.841827   \n",
       "all_mean_enc_user_feat2_lgb                              0.867521  0.834829   \n",
       "cat_interact_lgb                                         0.868102  0.832751   \n",
       "mean_enc_lgb                                             0.874476  0.841630   \n",
       "marcus_lgb                                               0.863764  0.826684   \n",
       "fused_text_lgb                                           0.890493  0.851669   \n",
       "mixed_features_text_proprocessing_lgb                    0.886403  0.851668   \n",
       "select_dense_features_lgb                                0.852123  0.799327   \n",
       "select_sparse_features_lgb                               0.855378  0.814837   \n",
       "lgb411_dart_tune                                         0.884214  0.819196   \n",
       "lgb411_goss_tune                                         0.875844  0.814830   \n",
       "lgb411_goss_tune2                                        0.874164  0.814072   \n",
       "poisson_lgb                                              0.874312  0.812960   \n",
       "poisson_small_lr_lgb                                     0.877285  0.815880   \n",
       "small_features_v5_xgb                                    0.870717  0.832500   \n",
       "small_features_v4_xgb                                    0.867462  0.829700   \n",
       "nima_features_xgb                                        0.874235  0.833920   \n",
       "img_meta_xgb                                             0.871764  0.830167   \n",
       "img_meta_nima_xgb                                        0.873562  0.830699   \n",
       "xgb_new                                                  0.870229  0.807589   \n",
       "baseline_xgb                                             0.866362  0.805410   \n",
       "ranking_xgb                                              0.755343  0.602618   \n",
       "catboost                                                 0.849061  0.778251   \n",
       "catboost1_without_text                                   0.849061  0.778251   \n",
       "mcl_cgb                                                  0.899041  0.833304   \n",
       "cgb_with_categorical                                     0.883679  0.821529   \n",
       "pretrained_bigru_cv1d_rnn                                0.867369  0.831889   \n",
       "pretrained_bigru_attention_rnn                           0.866900  0.831351   \n",
       "pretrained_2gru_rnn                                      0.863973  0.828514   \n",
       "selftrained_bigru_conv1d_rnn                             0.872210  0.843599   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn           0.846478  0.819210   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn       0.840113  0.808935   \n",
       "text_lgb                                                 0.897974  0.859582   \n",
       "text_cwb_rg                                              0.778525  0.672195   \n",
       "text_fm                                                  0.915000  0.868349   \n",
       "text_rg                                                  0.921706  0.871884   \n",
       "mlp                                                      0.897979  0.885489   \n",
       "rf                                                       0.947094  0.868474   \n",
       "rf_411_7000_leaves                                       0.942171  0.867728   \n",
       "alpha_0001                                               0.905166  0.871821   \n",
       "alpha_160                                                0.948172  0.908484   \n",
       "alpha_10                                                 0.924500  0.890701   \n",
       "alpha_320                                                0.953059  0.909061   \n",
       "ridge_new_411                                            1.000000  0.872317   \n",
       "lr_l1_05                                                 0.872317  1.000000   \n",
       "lr_l1_1                                                  0.858308  0.989319   \n",
       "lr_l2_01                                                 0.886009  0.990881   \n",
       "lr_l2_1                                                  0.851865  0.977235   \n",
       "cls05_lgb                                                0.815437  0.819547   \n",
       "cls0_lgb                                                 0.758699  0.591173   \n",
       "\n",
       "                                                     lr_l1_1  lr_l2_01  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.799280  0.821263   \n",
       "lgb411_tune                                         0.800982  0.822777   \n",
       "plants_lgb                                          0.811323  0.833793   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.804517  0.826794   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.799215  0.821176   \n",
       "xentropy_small_lr_cat_lgb                           0.810223  0.830989   \n",
       "simple_feature_lgb                                  0.822719  0.847758   \n",
       "all_mean_enc_lgb                                    0.826367  0.848981   \n",
       "all_mean_enc_user_feat_lgb                          0.827788  0.850257   \n",
       "all_mean_enc_user_feat2_lgb                         0.820828  0.843080   \n",
       "cat_interact_lgb                                    0.817674  0.841905   \n",
       "mean_enc_lgb                                        0.827670  0.850187   \n",
       "marcus_lgb                                          0.811957  0.836491   \n",
       "fused_text_lgb                                      0.839089  0.861994   \n",
       "mixed_features_text_proprocessing_lgb               0.839892  0.860305   \n",
       "select_dense_features_lgb                           0.781676  0.815745   \n",
       "select_sparse_features_lgb                          0.799672  0.826084   \n",
       "lgb411_dart_tune                                    0.806717  0.829294   \n",
       "lgb411_goss_tune                                    0.802777  0.824603   \n",
       "lgb411_goss_tune2                                   0.802009  0.823828   \n",
       "poisson_lgb                                         0.800763  0.822877   \n",
       "poisson_small_lr_lgb                                0.803637  0.825806   \n",
       "small_features_v5_xgb                               0.820057  0.842153   \n",
       "small_features_v4_xgb                               0.817291  0.839354   \n",
       "nima_features_xgb                                   0.821330  0.843655   \n",
       "img_meta_xgb                                        0.817575  0.839933   \n",
       "img_meta_nima_xgb                                   0.818032  0.840524   \n",
       "xgb_new                                             0.795570  0.817199   \n",
       "baseline_xgb                                        0.793460  0.815044   \n",
       "ranking_xgb                                         0.591424  0.612974   \n",
       "catboost                                            0.757783  0.797388   \n",
       "catboost1_without_text                              0.757783  0.797388   \n",
       "mcl_cgb                                             0.820399  0.843665   \n",
       "cgb_with_categorical                                0.808943  0.831460   \n",
       "pretrained_bigru_cv1d_rnn                           0.815955  0.845514   \n",
       "pretrained_bigru_attention_rnn                      0.815478  0.845075   \n",
       "pretrained_2gru_rnn                                 0.812761  0.842175   \n",
       "selftrained_bigru_conv1d_rnn                        0.829074  0.854190   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.805552  0.829565   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.795194  0.819298   \n",
       "text_lgb                                            0.843389  0.866778   \n",
       "text_cwb_rg                                         0.651171  0.692946   \n",
       "text_fm                                             0.865318  0.875062   \n",
       "text_rg                                             0.863262  0.880309   \n",
       "mlp                                                 0.878420  0.892664   \n",
       "rf                                                  0.854522  0.880176   \n",
       "rf_411_7000_leaves                                  0.853907  0.879102   \n",
       "alpha_0001                                          0.879716  0.874106   \n",
       "alpha_160                                           0.903209  0.915742   \n",
       "alpha_10                                            0.896439  0.893548   \n",
       "alpha_320                                           0.898929  0.919034   \n",
       "ridge_new_411                                       0.858308  0.886009   \n",
       "lr_l1_05                                            0.989319  0.990881   \n",
       "lr_l1_1                                             1.000000  0.978720   \n",
       "lr_l2_01                                            0.978720  1.000000   \n",
       "lr_l2_1                                             0.993113  0.972749   \n",
       "cls05_lgb                                           0.808260  0.827777   \n",
       "cls0_lgb                                            0.579615  0.602285   \n",
       "\n",
       "                                                     lr_l2_1  cls05_lgb  \\\n",
       "xentropy_add_lotsof_image_features_lgb              0.793754   0.938616   \n",
       "lgb411_tune                                         0.795435   0.945198   \n",
       "plants_lgb                                          0.805571   0.919283   \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.798866   0.931634   \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.793686   0.940242   \n",
       "xentropy_small_lr_cat_lgb                           0.804675   0.919523   \n",
       "simple_feature_lgb                                  0.814407   0.849272   \n",
       "all_mean_enc_lgb                                    0.818613   0.851784   \n",
       "all_mean_enc_user_feat_lgb                          0.819961   0.852166   \n",
       "all_mean_enc_user_feat2_lgb                         0.813033   0.842887   \n",
       "cat_interact_lgb                                    0.809139   0.845405   \n",
       "mean_enc_lgb                                        0.819786   0.850715   \n",
       "marcus_lgb                                          0.804208   0.865770   \n",
       "fused_text_lgb                                      0.832904   0.862263   \n",
       "mixed_features_text_proprocessing_lgb               0.833779   0.864107   \n",
       "select_dense_features_lgb                           0.773605   0.849946   \n",
       "select_sparse_features_lgb                          0.791992   0.857522   \n",
       "lgb411_dart_tune                                    0.801049   0.932960   \n",
       "lgb411_goss_tune                                    0.797247   0.944056   \n",
       "lgb411_goss_tune2                                   0.796454   0.946191   \n",
       "poisson_lgb                                         0.795230   0.939893   \n",
       "poisson_small_lr_lgb                                0.798084   0.943051   \n",
       "small_features_v5_xgb                               0.814219   0.878056   \n",
       "small_features_v4_xgb                               0.811488   0.874278   \n",
       "nima_features_xgb                                   0.815432   0.883037   \n",
       "img_meta_xgb                                        0.811707   0.889163   \n",
       "img_meta_nima_xgb                                   0.812143   0.892597   \n",
       "xgb_new                                             0.790047   0.937390   \n",
       "baseline_xgb                                        0.787995   0.931141   \n",
       "ranking_xgb                                         0.586523   0.643513   \n",
       "catboost                                            0.749147   0.837270   \n",
       "catboost1_without_text                              0.749147   0.837270   \n",
       "mcl_cgb                                             0.814558   0.928724   \n",
       "cgb_with_categorical                                0.803197   0.927639   \n",
       "pretrained_bigru_cv1d_rnn                           0.808175   0.842373   \n",
       "pretrained_bigru_attention_rnn                      0.807718   0.842070   \n",
       "pretrained_2gru_rnn                                 0.805075   0.838464   \n",
       "selftrained_bigru_conv1d_rnn                        0.821526   0.842529   \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.798523   0.849337   \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.788117   0.866651   \n",
       "text_lgb                                            0.834438   0.773886   \n",
       "text_cwb_rg                                         0.642389   0.617066   \n",
       "text_fm                                             0.863841   0.769777   \n",
       "text_rg                                             0.859124   0.770324   \n",
       "mlp                                                 0.874183   0.815301   \n",
       "rf                                                  0.848294   0.870954   \n",
       "rf_411_7000_leaves                                  0.847669   0.886803   \n",
       "alpha_0001                                          0.883194   0.758149   \n",
       "alpha_160                                           0.900263   0.788835   \n",
       "alpha_10                                            0.898729   0.772767   \n",
       "alpha_320                                           0.893928   0.791272   \n",
       "ridge_new_411                                       0.851865   0.815437   \n",
       "lr_l1_05                                            0.977235   0.819547   \n",
       "lr_l1_1                                             0.993113   0.808260   \n",
       "lr_l2_01                                            0.972749   0.827777   \n",
       "lr_l2_1                                             1.000000   0.802999   \n",
       "cls05_lgb                                           0.802999   1.000000   \n",
       "cls0_lgb                                            0.574573   0.634385   \n",
       "\n",
       "                                                    cls0_lgb  \n",
       "xentropy_add_lotsof_image_features_lgb              0.785823  \n",
       "lgb411_tune                                         0.788349  \n",
       "plants_lgb                                          0.781393  \n",
       "plants_with_img_meta_nima_fm_geo_active_lgb         0.782935  \n",
       "plants_with_img_meta_nima_fm_geo_active_obj_xen...  0.785084  \n",
       "xentropy_small_lr_cat_lgb                           0.779242  \n",
       "simple_feature_lgb                                  0.754601  \n",
       "all_mean_enc_lgb                                    0.752769  \n",
       "all_mean_enc_user_feat_lgb                          0.752736  \n",
       "all_mean_enc_user_feat2_lgb                         0.752974  \n",
       "cat_interact_lgb                                    0.749832  \n",
       "mean_enc_lgb                                        0.753346  \n",
       "marcus_lgb                                          0.752856  \n",
       "fused_text_lgb                                      0.758297  \n",
       "mixed_features_text_proprocessing_lgb               0.756379  \n",
       "select_dense_features_lgb                           0.750064  \n",
       "select_sparse_features_lgb                          0.748902  \n",
       "lgb411_dart_tune                                    0.794906  \n",
       "lgb411_goss_tune                                    0.790416  \n",
       "lgb411_goss_tune2                                   0.788665  \n",
       "poisson_lgb                                         0.786246  \n",
       "poisson_small_lr_lgb                                0.789149  \n",
       "small_features_v5_xgb                               0.766178  \n",
       "small_features_v4_xgb                               0.762278  \n",
       "nima_features_xgb                                   0.768238  \n",
       "img_meta_xgb                                        0.768521  \n",
       "img_meta_nima_xgb                                   0.769703  \n",
       "xgb_new                                             0.790083  \n",
       "baseline_xgb                                        0.780367  \n",
       "ranking_xgb                                         0.880291  \n",
       "catboost                                            0.760855  \n",
       "catboost1_without_text                              0.760855  \n",
       "mcl_cgb                                             0.791433  \n",
       "cgb_with_categorical                                0.783187  \n",
       "pretrained_bigru_cv1d_rnn                           0.748887  \n",
       "pretrained_bigru_attention_rnn                      0.747406  \n",
       "pretrained_2gru_rnn                                 0.748642  \n",
       "selftrained_bigru_conv1d_rnn                        0.743855  \n",
       "selftrained_bigru_conv1d_merged_with_image_rnn      0.727658  \n",
       "selftrained_bigru_conv1d_merged_with_image_adv_rnn  0.733800  \n",
       "text_lgb                                            0.712138  \n",
       "text_cwb_rg                                         0.661407  \n",
       "text_fm                                             0.713722  \n",
       "text_rg                                             0.722905  \n",
       "mlp                                                 0.728305  \n",
       "rf                                                  0.779519  \n",
       "rf_411_7000_leaves                                  0.785022  \n",
       "alpha_0001                                          0.705350  \n",
       "alpha_160                                           0.740193  \n",
       "alpha_10                                            0.719560  \n",
       "alpha_320                                           0.746015  \n",
       "ridge_new_411                                       0.758699  \n",
       "lr_l1_05                                            0.591173  \n",
       "lr_l1_1                                             0.579615  \n",
       "lr_l2_01                                            0.602285  \n",
       "lr_l2_1                                             0.574573  \n",
       "cls05_lgb                                           0.634385  \n",
       "cls0_lgb                                            1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows=100\n",
    "pd.options.display.max_columns=100\n",
    "train[basic_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503424 entries, 0 to 1503423\n",
      "Data columns (total 132 columns):\n",
      "xentropy_add_lotsof_image_features_lgb                      float64\n",
      "lgb411_tune                                                 float64\n",
      "plants_lgb                                                  float64\n",
      "plants_with_img_meta_nima_fm_geo_active_lgb                 float64\n",
      "plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb    float64\n",
      "xentropy_small_lr_cat_lgb                                   float64\n",
      "simple_feature_lgb                                          float64\n",
      "all_mean_enc_lgb                                            float64\n",
      "all_mean_enc_user_feat_lgb                                  float64\n",
      "all_mean_enc_user_feat2_lgb                                 float64\n",
      "cat_interact_lgb                                            float64\n",
      "mean_enc_lgb                                                float64\n",
      "marcus_lgb                                                  float64\n",
      "fused_text_lgb                                              float64\n",
      "mixed_features_text_proprocessing_lgb                       float64\n",
      "select_dense_features_lgb                                   float64\n",
      "select_sparse_features_lgb                                  float64\n",
      "lgb_mean                                                    float64\n",
      "lgb_med                                                     float64\n",
      "lgb_max                                                     float64\n",
      "lgb_min                                                     float64\n",
      "lgb_std                                                     float64\n",
      "lgb411_dart_tune                                            float64\n",
      "lgb411_goss_tune                                            float64\n",
      "lgb411_goss_tune2                                           float64\n",
      "lgb_goss_mean                                               float64\n",
      "lgb_goss_med                                                float64\n",
      "lgb_goss_max                                                float64\n",
      "lgb_goss_min                                                float64\n",
      "lgb_goss_std                                                float64\n",
      "poisson_lgb                                                 float64\n",
      "poisson_small_lr_lgb                                        float64\n",
      "lgb_pois_mean                                               float64\n",
      "lgb_pois_med                                                float64\n",
      "lgb_pois_max                                                float64\n",
      "lgb_pois_min                                                float64\n",
      "lgb_pois_std                                                float64\n",
      "small_features_v5_xgb                                       float64\n",
      "small_features_v4_xgb                                       float64\n",
      "nima_features_xgb                                           float64\n",
      "img_meta_xgb                                                float64\n",
      "img_meta_nima_xgb                                           float64\n",
      "xgb_new                                                     float64\n",
      "xgb_lg_mean                                                 float64\n",
      "xgb_lg_med                                                  float64\n",
      "xgb_lg_max                                                  float64\n",
      "xgb_lg_min                                                  float64\n",
      "xgb_lg_std                                                  float64\n",
      "baseline_xgb                                                float64\n",
      "ranking_xgb                                                 float64\n",
      "catboost                                                    float64\n",
      "catboost1_without_text                                      float64\n",
      "mcl_cgb                                                     float64\n",
      "cgb_with_categorical                                        float64\n",
      "catboost_mean                                               float64\n",
      "catboost_med                                                float64\n",
      "catboost_max                                                float64\n",
      "catboost_min                                                float64\n",
      "catboost_std                                                float64\n",
      "pretrained_bigru_cv1d_rnn                                   float64\n",
      "pretrained_bigru_attention_rnn                              float64\n",
      "pretrained_2gru_rnn                                         float64\n",
      "selftrained_bigru_conv1d_rnn                                float64\n",
      "selftrained_bigru_conv1d_merged_with_image_rnn              float64\n",
      "selftrained_bigru_conv1d_merged_with_image_adv_rnn          float64\n",
      "rnn_mean                                                    float64\n",
      "rnn_med                                                     float64\n",
      "rnn_max                                                     float64\n",
      "rnn_min                                                     float64\n",
      "rnn_std                                                     float64\n",
      "text_lgb                                                    float64\n",
      "text_cwb_rg                                                 float64\n",
      "text_fm                                                     float64\n",
      "text_rg                                                     float64\n",
      "text_mean                                                   float64\n",
      "text_med                                                    float64\n",
      "text_max                                                    float64\n",
      "text_min                                                    float64\n",
      "text_std                                                    float64\n",
      "mlp                                                         float64\n",
      "rf                                                          float64\n",
      "rf_411_7000_leaves                                          float64\n",
      "random_forest_mean                                          float64\n",
      "random_forest_med                                           float64\n",
      "random_forest_max                                           float64\n",
      "random_forest_min                                           float64\n",
      "random_forest_std                                           float64\n",
      "alpha_0001                                                  float64\n",
      "alpha_160                                                   float64\n",
      "alpha_10                                                    float64\n",
      "alpha_320                                                   float64\n",
      "ridge_new_411                                               float64\n",
      "ridge_mean                                                  float64\n",
      "ridge_med                                                   float64\n",
      "ridge_max                                                   float64\n",
      "ridge_min                                                   float64\n",
      "ridge_std                                                   float64\n",
      "lr_l1_05                                                    float64\n",
      "lr_l1_1                                                     float64\n",
      "lr_l2_01                                                    float64\n",
      "lr_l2_1                                                     float64\n",
      "logistic_regression_mean                                    float64\n",
      "logistic_regression_med                                     float64\n",
      "logistic_regression_max                                     float64\n",
      "logistic_regression_min                                     float64\n",
      "logistic_regression_std                                     float64\n",
      "cls05_lgb                                                   float64\n",
      "cls0_lgb                                                    float64\n",
      "multiclass_lgbmulticlass_lgb_pred0                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred1                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred2                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred3                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred4                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred5                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred6                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred7                          float64\n",
      "multiclass_lgbmulticlass_lgb_pred8                          float64\n",
      "multiclass_lgbmulticlass_lgbrank                            int64\n",
      "multiclass3_lgbmulticlass3_lgb_pred0                        float64\n",
      "multiclass3_lgbmulticlass3_lgb_pred1                        float64\n",
      "multiclass3_lgbmulticlass3_lgb_pred2                        float64\n",
      "multiclass3_lgbmulticlass3_lgbrank                          int64\n",
      "bi_inter_group_mean                                         float64\n",
      "bi_inter_group_med                                          float64\n",
      "bi_inter_group_max                                          float64\n",
      "bi_inter_group_min                                          float64\n",
      "bi_inter_group_std                                          float64\n",
      "tri_inter_group_mean                                        float64\n",
      "tri_inter_group_med                                         float64\n",
      "tri_inter_group_max                                         float64\n",
      "tri_inter_group_min                                         float64\n",
      "tri_inter_group_std                                         float64\n",
      "dtypes: float64(130), int64(2)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503424, 132), (508438, 132))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum().max()) \n",
    "print(test.isnull().sum().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(train.columns):\n",
    "    train[col] = train[col].astype(np.float32)\n",
    "    test[col] = test[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503424 entries, 0 to 1503423\n",
      "Data columns (total 132 columns):\n",
      "xentropy_add_lotsof_image_features_lgb                      float32\n",
      "lgb411_tune                                                 float32\n",
      "plants_lgb                                                  float32\n",
      "plants_with_img_meta_nima_fm_geo_active_lgb                 float32\n",
      "plants_with_img_meta_nima_fm_geo_active_obj_xentropy_lgb    float32\n",
      "xentropy_small_lr_cat_lgb                                   float32\n",
      "simple_feature_lgb                                          float32\n",
      "all_mean_enc_lgb                                            float32\n",
      "all_mean_enc_user_feat_lgb                                  float32\n",
      "all_mean_enc_user_feat2_lgb                                 float32\n",
      "cat_interact_lgb                                            float32\n",
      "mean_enc_lgb                                                float32\n",
      "marcus_lgb                                                  float32\n",
      "fused_text_lgb                                              float32\n",
      "mixed_features_text_proprocessing_lgb                       float32\n",
      "select_dense_features_lgb                                   float32\n",
      "select_sparse_features_lgb                                  float32\n",
      "lgb_mean                                                    float32\n",
      "lgb_med                                                     float32\n",
      "lgb_max                                                     float32\n",
      "lgb_min                                                     float32\n",
      "lgb_std                                                     float32\n",
      "lgb411_dart_tune                                            float32\n",
      "lgb411_goss_tune                                            float32\n",
      "lgb411_goss_tune2                                           float32\n",
      "lgb_goss_mean                                               float32\n",
      "lgb_goss_med                                                float32\n",
      "lgb_goss_max                                                float32\n",
      "lgb_goss_min                                                float32\n",
      "lgb_goss_std                                                float32\n",
      "poisson_lgb                                                 float32\n",
      "poisson_small_lr_lgb                                        float32\n",
      "lgb_pois_mean                                               float32\n",
      "lgb_pois_med                                                float32\n",
      "lgb_pois_max                                                float32\n",
      "lgb_pois_min                                                float32\n",
      "lgb_pois_std                                                float32\n",
      "small_features_v5_xgb                                       float32\n",
      "small_features_v4_xgb                                       float32\n",
      "nima_features_xgb                                           float32\n",
      "img_meta_xgb                                                float32\n",
      "img_meta_nima_xgb                                           float32\n",
      "xgb_new                                                     float32\n",
      "xgb_lg_mean                                                 float32\n",
      "xgb_lg_med                                                  float32\n",
      "xgb_lg_max                                                  float32\n",
      "xgb_lg_min                                                  float32\n",
      "xgb_lg_std                                                  float32\n",
      "baseline_xgb                                                float32\n",
      "ranking_xgb                                                 float32\n",
      "catboost                                                    float32\n",
      "catboost1_without_text                                      float32\n",
      "mcl_cgb                                                     float32\n",
      "cgb_with_categorical                                        float32\n",
      "catboost_mean                                               float32\n",
      "catboost_med                                                float32\n",
      "catboost_max                                                float32\n",
      "catboost_min                                                float32\n",
      "catboost_std                                                float32\n",
      "pretrained_bigru_cv1d_rnn                                   float32\n",
      "pretrained_bigru_attention_rnn                              float32\n",
      "pretrained_2gru_rnn                                         float32\n",
      "selftrained_bigru_conv1d_rnn                                float32\n",
      "selftrained_bigru_conv1d_merged_with_image_rnn              float32\n",
      "selftrained_bigru_conv1d_merged_with_image_adv_rnn          float32\n",
      "rnn_mean                                                    float32\n",
      "rnn_med                                                     float32\n",
      "rnn_max                                                     float32\n",
      "rnn_min                                                     float32\n",
      "rnn_std                                                     float32\n",
      "text_lgb                                                    float32\n",
      "text_cwb_rg                                                 float32\n",
      "text_fm                                                     float32\n",
      "text_rg                                                     float32\n",
      "text_mean                                                   float32\n",
      "text_med                                                    float32\n",
      "text_max                                                    float32\n",
      "text_min                                                    float32\n",
      "text_std                                                    float32\n",
      "mlp                                                         float32\n",
      "rf                                                          float32\n",
      "rf_411_7000_leaves                                          float32\n",
      "random_forest_mean                                          float32\n",
      "random_forest_med                                           float32\n",
      "random_forest_max                                           float32\n",
      "random_forest_min                                           float32\n",
      "random_forest_std                                           float32\n",
      "alpha_0001                                                  float32\n",
      "alpha_160                                                   float32\n",
      "alpha_10                                                    float32\n",
      "alpha_320                                                   float32\n",
      "ridge_new_411                                               float32\n",
      "ridge_mean                                                  float32\n",
      "ridge_med                                                   float32\n",
      "ridge_max                                                   float32\n",
      "ridge_min                                                   float32\n",
      "ridge_std                                                   float32\n",
      "lr_l1_05                                                    float32\n",
      "lr_l1_1                                                     float32\n",
      "lr_l2_01                                                    float32\n",
      "lr_l2_1                                                     float32\n",
      "logistic_regression_mean                                    float32\n",
      "logistic_regression_med                                     float32\n",
      "logistic_regression_max                                     float32\n",
      "logistic_regression_min                                     float32\n",
      "logistic_regression_std                                     float32\n",
      "cls05_lgb                                                   float32\n",
      "cls0_lgb                                                    float32\n",
      "multiclass_lgbmulticlass_lgb_pred0                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred1                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred2                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred3                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred4                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred5                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred6                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred7                          float32\n",
      "multiclass_lgbmulticlass_lgb_pred8                          float32\n",
      "multiclass_lgbmulticlass_lgbrank                            float32\n",
      "multiclass3_lgbmulticlass3_lgb_pred0                        float32\n",
      "multiclass3_lgbmulticlass3_lgb_pred1                        float32\n",
      "multiclass3_lgbmulticlass3_lgb_pred2                        float32\n",
      "multiclass3_lgbmulticlass3_lgbrank                          float32\n",
      "bi_inter_group_mean                                         float32\n",
      "bi_inter_group_med                                          float32\n",
      "bi_inter_group_max                                          float32\n",
      "bi_inter_group_min                                          float32\n",
      "bi_inter_group_std                                          float32\n",
      "tri_inter_group_mean                                        float32\n",
      "tri_inter_group_med                                         float32\n",
      "tri_inter_group_max                                         float32\n",
      "tri_inter_group_min                                         float32\n",
      "tri_inter_group_std                                         float32\n",
      "dtypes: float32(132)\n",
      "memory usage: 757.0 MB\n"
     ]
    }
   ],
   "source": [
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_train_411_simple.pickle', 'wb') as handle:\n",
    "    pickle.dump(train, handle)\n",
    "    \n",
    "with open('meta_test_411_simple.pickle', 'wb') as handle:\n",
    "    pickle.dump(test, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc; gc.enable()\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from GridSearcher import data_loader, model_loader, fit_params, get_oof_predictions, clip_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED=411\n",
    "train_y = pd.read_csv(\"regression_target.csv\").deal_probability.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('meta_train.pickle', 'rb') as handle:\n",
    "    train = pickle.load(handle)\n",
    "    \n",
    "with open('meta_test.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 684)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm-gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_split_gain': 0.0} train loss: 0.207717, valid loss:0.208867, loss_diff:0.001150\n",
      "{'min_split_gain': 0.0} train loss: 0.207552, valid loss:0.209566, loss_diff:0.002014\n",
      "{'min_split_gain': 0.0} train loss: 0.207818, valid loss:0.208491, loss_diff:0.000673\n",
      "{'min_split_gain': 0.0} train loss: 0.207751, valid loss:0.208752, loss_diff:0.001001\n",
      "{'min_split_gain': 0.0} train loss: 0.207555, valid loss:0.209447, loss_diff:0.001891\n",
      "=================>{'min_split_gain': 0.0} loss:0.209025\n",
      "{'min_split_gain': 0.1} train loss: 0.207720, valid loss:0.208860, loss_diff:0.001140\n",
      "{'min_split_gain': 0.1} train loss: 0.207555, valid loss:0.209577, loss_diff:0.002021\n",
      "{'min_split_gain': 0.1} train loss: 0.207806, valid loss:0.208466, loss_diff:0.000660\n",
      "{'min_split_gain': 0.1} train loss: 0.207734, valid loss:0.208763, loss_diff:0.001029\n",
      "{'min_split_gain': 0.1} train loss: 0.207557, valid loss:0.209453, loss_diff:0.001896\n",
      "=================>{'min_split_gain': 0.1} loss:0.209024\n",
      "{'min_split_gain': 0.2} train loss: 0.207745, valid loss:0.208870, loss_diff:0.001126\n",
      "{'min_split_gain': 0.2} train loss: 0.207589, valid loss:0.209587, loss_diff:0.001999\n",
      "{'min_split_gain': 0.2} train loss: 0.207825, valid loss:0.208502, loss_diff:0.000677\n",
      "{'min_split_gain': 0.2} train loss: 0.207767, valid loss:0.208780, loss_diff:0.001013\n",
      "{'min_split_gain': 0.2} train loss: 0.207580, valid loss:0.209447, loss_diff:0.001866\n",
      "=================>{'min_split_gain': 0.2} loss:0.209037\n",
      "{'min_split_gain': 0.3} train loss: 0.207797, valid loss:0.208894, loss_diff:0.001097\n",
      "{'min_split_gain': 0.3} train loss: 0.207656, valid loss:0.209629, loss_diff:0.001973\n",
      "{'min_split_gain': 0.3} train loss: 0.207851, valid loss:0.208506, loss_diff:0.000656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a828f4846d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mfit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_eval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Kaggle Competitions\\Kaggle-avito-demand-prediction\\GridSearcher.py\u001b[0m in \u001b[0;36mfit_params\u001b[1;34m(X, y, model_loader, default_params, try_params, use_eval_set, fit_params, seed, loss_func, predict_proba)\u001b[0m\n\u001b[0;32m    303\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    610\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    457\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    197\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1437\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1438\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'min_split_gain': [.0, .1, .2, .3, .4]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest\\n{'min_split_gain': 0.0} train loss: 0.207978, valid loss:0.208974, loss_diff:0.000996\\n{'min_split_gain': 0.0} train loss: 0.207808, valid loss:0.209675, loss_diff:0.001867\\n{'min_split_gain': 0.0} train loss: 0.208046, valid loss:0.208600, loss_diff:0.000554\\n{'min_split_gain': 0.0} train loss: 0.207981, valid loss:0.208823, loss_diff:0.000843\\n{'min_split_gain': 0.0} train loss: 0.207785, valid loss:0.209536, loss_diff:0.001751\\n=================>{'min_split_gain': 0.0} loss:0.209122\\n\\n\\nbest \\n{'min_split_gain': 0.1} train loss: 0.208348, valid loss:0.209236, loss_diff:0.000887\\n{'min_split_gain': 0.1} train loss: 0.208166, valid loss:0.209885, loss_diff:0.001718\\n{'min_split_gain': 0.1} train loss: 0.208426, valid loss:0.208832, loss_diff:0.000405\\n{'min_split_gain': 0.1} train loss: 0.208379, valid loss:0.208949, loss_diff:0.000570\\n{'min_split_gain': 0.1} train loss: 0.208165, valid loss:0.209724, loss_diff:0.001559\\n=================>{'min_split_gain': 0.1} loss:0.209325\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "best\n",
    "{'min_split_gain': 0.0} train loss: 0.207978, valid loss:0.208974, loss_diff:0.000996\n",
    "{'min_split_gain': 0.0} train loss: 0.207808, valid loss:0.209675, loss_diff:0.001867\n",
    "{'min_split_gain': 0.0} train loss: 0.208046, valid loss:0.208600, loss_diff:0.000554\n",
    "{'min_split_gain': 0.0} train loss: 0.207981, valid loss:0.208823, loss_diff:0.000843\n",
    "{'min_split_gain': 0.0} train loss: 0.207785, valid loss:0.209536, loss_diff:0.001751\n",
    "=================>{'min_split_gain': 0.0} loss:0.209122\n",
    "\n",
    "\n",
    "best \n",
    "{'min_split_gain': 0.1} train loss: 0.208348, valid loss:0.209236, loss_diff:0.000887\n",
    "{'min_split_gain': 0.1} train loss: 0.208166, valid loss:0.209885, loss_diff:0.001718\n",
    "{'min_split_gain': 0.1} train loss: 0.208426, valid loss:0.208832, loss_diff:0.000405\n",
    "{'min_split_gain': 0.1} train loss: 0.208379, valid loss:0.208949, loss_diff:0.000570\n",
    "{'min_split_gain': 0.1} train loss: 0.208165, valid loss:0.209724, loss_diff:0.001559\n",
    "=================>{'min_split_gain': 0.1} loss:0.209325\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7} train loss: 0.207786, valid loss:0.208842, loss_diff:0.001056\n",
      "{'colsample_bytree': 0.7} train loss: 0.207601, valid loss:0.209568, loss_diff:0.001967\n",
      "{'colsample_bytree': 0.7} train loss: 0.207868, valid loss:0.208521, loss_diff:0.000653\n",
      "{'colsample_bytree': 0.7} train loss: 0.207817, valid loss:0.208786, loss_diff:0.000969\n",
      "{'colsample_bytree': 0.7} train loss: 0.207611, valid loss:0.209465, loss_diff:0.001854\n",
      "=================>{'colsample_bytree': 0.7} loss:0.209036\n",
      "{'colsample_bytree': 0.8} train loss: 0.207777, valid loss:0.208878, loss_diff:0.001101\n",
      "{'colsample_bytree': 0.8} train loss: 0.207576, valid loss:0.209557, loss_diff:0.001982\n",
      "{'colsample_bytree': 0.8} train loss: 0.207803, valid loss:0.208481, loss_diff:0.000678\n",
      "{'colsample_bytree': 0.8} train loss: 0.207753, valid loss:0.208760, loss_diff:0.001007\n",
      "{'colsample_bytree': 0.8} train loss: 0.207593, valid loss:0.209485, loss_diff:0.001892\n",
      "=================>{'colsample_bytree': 0.8} loss:0.209032\n",
      "{'colsample_bytree': 0.9} train loss: 0.207727, valid loss:0.208827, loss_diff:0.001101\n",
      "{'colsample_bytree': 0.9} train loss: 0.207562, valid loss:0.209529, loss_diff:0.001967\n",
      "{'colsample_bytree': 0.9} train loss: 0.207811, valid loss:0.208478, loss_diff:0.000667\n",
      "{'colsample_bytree': 0.9} train loss: 0.207770, valid loss:0.208766, loss_diff:0.000996\n",
      "{'colsample_bytree': 0.9} train loss: 0.207568, valid loss:0.209448, loss_diff:0.001880\n",
      "=================>{'colsample_bytree': 0.9} loss:0.209010\n",
      "Best params: {'colsample_bytree': 0.9} \tbest loss: 0.209009837344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'colsample_bytree': 0.7}</td>\n",
       "      <td>0.209036</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'colsample_bytree': 0.8}</td>\n",
       "      <td>0.209032</td>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'colsample_bytree': 0.9}</td>\n",
       "      <td>0.209010</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       param  val_loss_mean  val_loss_std\n",
       "0  {'colsample_bytree': 0.7}       0.209036      0.000408\n",
       "1  {'colsample_bytree': 0.8}       0.209032      0.000420\n",
       "2  {'colsample_bytree': 0.9}       0.209010      0.000409"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "# 1.0: 0.209025\n",
    "try_params = {\n",
    "    'colsample_bytree':[i/10.0 for i in range(7,10)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.7} train loss: 0.207751, valid loss:0.208873, loss_diff:0.001122\n",
      "{'subsample': 0.7} train loss: 0.207616, valid loss:0.209654, loss_diff:0.002038\n",
      "{'subsample': 0.7} train loss: 0.207830, valid loss:0.208497, loss_diff:0.000667\n",
      "{'subsample': 0.7} train loss: 0.207769, valid loss:0.208789, loss_diff:0.001020\n",
      "{'subsample': 0.7} train loss: 0.207594, valid loss:0.209526, loss_diff:0.001932\n",
      "=================>{'subsample': 0.7} loss:0.209068\n",
      "{'subsample': 0.8} train loss: 0.207735, valid loss:0.208928, loss_diff:0.001193\n",
      "{'subsample': 0.8} train loss: 0.207583, valid loss:0.209582, loss_diff:0.001998\n",
      "{'subsample': 0.8} train loss: 0.207815, valid loss:0.208513, loss_diff:0.000698\n",
      "{'subsample': 0.8} train loss: 0.207759, valid loss:0.208773, loss_diff:0.001014\n",
      "{'subsample': 0.8} train loss: 0.207580, valid loss:0.209517, loss_diff:0.001937\n",
      "=================>{'subsample': 0.8} loss:0.209062\n",
      "{'subsample': 0.9} train loss: 0.207729, valid loss:0.208872, loss_diff:0.001143\n",
      "{'subsample': 0.9} train loss: 0.207561, valid loss:0.209583, loss_diff:0.002022\n",
      "{'subsample': 0.9} train loss: 0.207814, valid loss:0.208532, loss_diff:0.000718\n",
      "{'subsample': 0.9} train loss: 0.207747, valid loss:0.208748, loss_diff:0.001001\n",
      "{'subsample': 0.9} train loss: 0.207592, valid loss:0.209491, loss_diff:0.001900\n",
      "=================>{'subsample': 0.9} loss:0.209045\n",
      "Best params: {'subsample': 0.9} \tbest loss: 0.209045236567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.7}</td>\n",
       "      <td>0.209068</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.8}</td>\n",
       "      <td>0.209062</td>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'subsample': 0.9}</td>\n",
       "      <td>0.209045</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'subsample': 0.7}       0.209068      0.000446\n",
       "1  {'subsample': 0.8}       0.209062      0.000420\n",
       "2  {'subsample': 0.9}       0.209045      0.000417"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':.9, \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "# subsample 1.0 => cv: 0.209122  new: 0.209010\n",
    "try_params = {\n",
    "    'subsample':[i/10.0 for i in range(7,10)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 1.0} train loss: 0.207717, valid loss:0.208923, loss_diff:0.001206\n",
      "{'reg_alpha': 1.0} train loss: 0.207541, valid loss:0.209613, loss_diff:0.002072\n",
      "{'reg_alpha': 1.0} train loss: 0.207771, valid loss:0.208505, loss_diff:0.000734\n",
      "{'reg_alpha': 1.0} train loss: 0.207712, valid loss:0.208783, loss_diff:0.001072\n",
      "{'reg_alpha': 1.0} train loss: 0.207519, valid loss:0.209447, loss_diff:0.001928\n",
      "=================>{'reg_alpha': 1.0} loss:0.209054\n",
      "{'reg_alpha': 1.5} train loss: 0.207708, valid loss:0.208872, loss_diff:0.001164\n",
      "{'reg_alpha': 1.5} train loss: 0.207541, valid loss:0.209611, loss_diff:0.002070\n",
      "{'reg_alpha': 1.5} train loss: 0.207790, valid loss:0.208473, loss_diff:0.000684\n",
      "{'reg_alpha': 1.5} train loss: 0.207738, valid loss:0.208749, loss_diff:0.001011\n",
      "{'reg_alpha': 1.5} train loss: 0.207546, valid loss:0.209477, loss_diff:0.001931\n",
      "=================>{'reg_alpha': 1.5} loss:0.209036\n",
      "{'reg_alpha': 2.5} train loss: 0.207741, valid loss:0.208882, loss_diff:0.001141\n",
      "{'reg_alpha': 2.5} train loss: 0.207576, valid loss:0.209557, loss_diff:0.001981\n",
      "{'reg_alpha': 2.5} train loss: 0.207838, valid loss:0.208477, loss_diff:0.000639\n",
      "{'reg_alpha': 2.5} train loss: 0.207747, valid loss:0.208763, loss_diff:0.001015\n",
      "{'reg_alpha': 2.5} train loss: 0.207581, valid loss:0.209452, loss_diff:0.001871\n",
      "=================>{'reg_alpha': 2.5} loss:0.209026\n",
      "{'reg_alpha': 3.0} train loss: 0.207764, valid loss:0.208846, loss_diff:0.001082\n",
      "{'reg_alpha': 3.0} train loss: 0.207578, valid loss:0.209541, loss_diff:0.001963\n",
      "{'reg_alpha': 3.0} train loss: 0.207821, valid loss:0.208455, loss_diff:0.000633\n",
      "{'reg_alpha': 3.0} train loss: 0.207776, valid loss:0.208779, loss_diff:0.001003\n",
      "{'reg_alpha': 3.0} train loss: 0.207582, valid loss:0.209458, loss_diff:0.001876\n",
      "=================>{'reg_alpha': 3.0} loss:0.209016\n",
      "Best params: {'reg_alpha': 3.0} \tbest loss: 0.209015616311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'reg_alpha': 1.0}</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'reg_alpha': 1.5}</td>\n",
       "      <td>0.209036</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'reg_alpha': 2.5}</td>\n",
       "      <td>0.209026</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'reg_alpha': 3.0}</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'reg_alpha': 1.0}       0.209054      0.000414\n",
       "1  {'reg_alpha': 1.5}       0.209036      0.000436\n",
       "2  {'reg_alpha': 2.5}       0.209026      0.000413\n",
       "3  {'reg_alpha': 3.0}       0.209016      0.000417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':.9, \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "# 2.0: cv 0.209052306045, new: 0.209010\n",
    "try_params = {\n",
    "    'reg_alpha':[1.0, 1.5, 2.5, 3.0]\n",
    "} \n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 3.5} train loss: 0.207790, valid loss:0.208848, loss_diff:0.001058\n",
      "{'reg_alpha': 3.5} train loss: 0.207620, valid loss:0.209600, loss_diff:0.001980\n",
      "{'reg_alpha': 3.5} train loss: 0.207859, valid loss:0.208476, loss_diff:0.000617\n",
      "{'reg_alpha': 3.5} train loss: 0.207780, valid loss:0.208757, loss_diff:0.000977\n",
      "{'reg_alpha': 3.5} train loss: 0.207595, valid loss:0.209449, loss_diff:0.001854\n",
      "=================>{'reg_alpha': 3.5} loss:0.209026\n",
      "{'reg_alpha': 4.0} train loss: 0.207794, valid loss:0.208861, loss_diff:0.001067\n",
      "{'reg_alpha': 4.0} train loss: 0.207608, valid loss:0.209546, loss_diff:0.001938\n",
      "{'reg_alpha': 4.0} train loss: 0.207833, valid loss:0.208444, loss_diff:0.000611\n",
      "{'reg_alpha': 4.0} train loss: 0.207805, valid loss:0.208773, loss_diff:0.000968\n",
      "{'reg_alpha': 4.0} train loss: 0.207614, valid loss:0.209456, loss_diff:0.001842\n",
      "=================>{'reg_alpha': 4.0} loss:0.209016\n",
      "{'reg_alpha': 4.5} train loss: 0.207790, valid loss:0.208847, loss_diff:0.001057\n",
      "{'reg_alpha': 4.5} train loss: 0.207613, valid loss:0.209574, loss_diff:0.001960\n",
      "{'reg_alpha': 4.5} train loss: 0.207855, valid loss:0.208467, loss_diff:0.000612\n",
      "{'reg_alpha': 4.5} train loss: 0.207814, valid loss:0.208746, loss_diff:0.000932\n",
      "{'reg_alpha': 4.5} train loss: 0.207616, valid loss:0.209439, loss_diff:0.001823\n",
      "=================>{'reg_alpha': 4.5} loss:0.209015\n",
      "Best params: {'reg_alpha': 4.5} \tbest loss: 0.209014536685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'reg_alpha': 3.5}</td>\n",
       "      <td>0.209026</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'reg_alpha': 4.0}</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'reg_alpha': 4.5}</td>\n",
       "      <td>0.209015</td>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'reg_alpha': 3.5}       0.209026      0.000428\n",
       "1  {'reg_alpha': 4.0}       0.209016      0.000421\n",
       "2  {'reg_alpha': 4.5}       0.209015      0.000423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':.9, \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_alpha':[3.5, 4.0, 4.5]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 5.0} train loss: 0.207808, valid loss:0.208846, loss_diff:0.001039\n",
      "{'reg_alpha': 5.0} train loss: 0.207638, valid loss:0.209516, loss_diff:0.001878\n",
      "{'reg_alpha': 5.0} train loss: 0.207882, valid loss:0.208444, loss_diff:0.000563\n",
      "{'reg_alpha': 5.0} train loss: 0.207833, valid loss:0.208766, loss_diff:0.000933\n",
      "{'reg_alpha': 5.0} train loss: 0.207638, valid loss:0.209462, loss_diff:0.001824\n",
      "=================>{'reg_alpha': 5.0} loss:0.209007\n",
      "{'reg_alpha': 5.5} train loss: 0.207810, valid loss:0.208814, loss_diff:0.001005\n",
      "{'reg_alpha': 5.5} train loss: 0.207641, valid loss:0.209524, loss_diff:0.001883\n",
      "{'reg_alpha': 5.5} train loss: 0.207892, valid loss:0.208459, loss_diff:0.000567\n",
      "{'reg_alpha': 5.5} train loss: 0.207840, valid loss:0.208743, loss_diff:0.000903\n",
      "{'reg_alpha': 5.5} train loss: 0.207646, valid loss:0.209441, loss_diff:0.001795\n",
      "=================>{'reg_alpha': 5.5} loss:0.208996\n",
      "{'reg_alpha': 6.0} train loss: 0.207814, valid loss:0.208857, loss_diff:0.001042\n",
      "{'reg_alpha': 6.0} train loss: 0.207632, valid loss:0.209519, loss_diff:0.001886\n",
      "{'reg_alpha': 6.0} train loss: 0.207930, valid loss:0.208425, loss_diff:0.000495\n",
      "{'reg_alpha': 6.0} train loss: 0.207825, valid loss:0.208732, loss_diff:0.000907\n",
      "{'reg_alpha': 6.0} train loss: 0.207680, valid loss:0.209454, loss_diff:0.001774\n",
      "=================>{'reg_alpha': 6.0} loss:0.208997\n",
      "Best params: {'reg_alpha': 5.5} \tbest loss: 0.208996368394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'reg_alpha': 5.0}</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'reg_alpha': 5.5}</td>\n",
       "      <td>0.208996</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'reg_alpha': 6.0}</td>\n",
       "      <td>0.208997</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'reg_alpha': 5.0}       0.209007      0.000416\n",
       "1  {'reg_alpha': 5.5}       0.208996      0.000415\n",
       "2  {'reg_alpha': 6.0}       0.208997      0.000424"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':.9, \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_alpha':[5.0, 5.5, 6.]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 0.1} train loss: 0.207796, valid loss:0.208817, loss_diff:0.001021\n",
      "{'reg_lambda': 0.1} train loss: 0.207639, valid loss:0.209526, loss_diff:0.001887\n",
      "{'reg_lambda': 0.1} train loss: 0.207892, valid loss:0.208459, loss_diff:0.000567\n",
      "{'reg_lambda': 0.1} train loss: 0.207847, valid loss:0.208756, loss_diff:0.000909\n",
      "{'reg_lambda': 0.1} train loss: 0.207640, valid loss:0.209425, loss_diff:0.001785\n",
      "=================>{'reg_lambda': 0.1} loss:0.208997\n",
      "{'reg_lambda': 0.2} train loss: 0.207809, valid loss:0.208841, loss_diff:0.001032\n",
      "{'reg_lambda': 0.2} train loss: 0.207640, valid loss:0.209526, loss_diff:0.001887\n",
      "{'reg_lambda': 0.2} train loss: 0.207892, valid loss:0.208459, loss_diff:0.000567\n",
      "{'reg_lambda': 0.2} train loss: 0.207847, valid loss:0.208756, loss_diff:0.000909\n",
      "{'reg_lambda': 0.2} train loss: 0.207645, valid loss:0.209449, loss_diff:0.001803\n",
      "=================>{'reg_lambda': 0.2} loss:0.209006\n",
      "{'reg_lambda': 0.3} train loss: 0.207809, valid loss:0.208842, loss_diff:0.001032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fc502b7cb404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mfit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_eval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Kaggle Competitions\\Kaggle-avito-demand-prediction\\GridSearcher.py\u001b[0m in \u001b[0;36mfit_params\u001b[1;34m(X, y, model_loader, default_params, try_params, use_eval_set, fit_params, seed, loss_func, predict_proba)\u001b[0m\n\u001b[0;32m    303\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    610\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    457\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    197\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1437\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1438\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'objective': 'xentropy',\n",
    "    'num_leaves':31, \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':.9, \n",
    "    'reg_alpha':5.5, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 4\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "# reg_lambda 0.0: 0.209121440793  new: Best params: {'reg_alpha': 5.5} \tbest loss: 0.208996368394\n",
    "try_params = {\n",
    "    'reg_lambda':[i/10.0 for i in range(1,4)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'gbdt', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.02, \n",
    "    'n_estimators':3000, \n",
    "    'min_split_gain':0.1, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':.7,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':1.5, \n",
    "    'reg_lambda':0.7, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = {\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose': 100,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "_, ret_test, _ = get_oof_predictions(train, train_y, test, ml, \n",
    "                                     default_params, seed=19, fit_params=fit_param, use_eval_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\", usecols=['item_id'])\n",
    "pd.DataFrame(np.clip(ret_test,0,1), \n",
    "             index=test_df.item_id,\n",
    "             columns=['deal_probability']).to_csv('lgb_meta_no_bagging_exclude_knn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm-dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_split_gain': 0.0} train loss: 0.213927, valid loss:0.214264, loss_diff:0.000337\n",
      "{'min_split_gain': 0.0} train loss: 0.213748, valid loss:0.215104, loss_diff:0.001356\n",
      "{'min_split_gain': 0.0} train loss: 0.214077, valid loss:0.213627, loss_diff:-0.000450\n",
      "{'min_split_gain': 0.0} train loss: 0.214023, valid loss:0.213778, loss_diff:-0.000245\n",
      "{'min_split_gain': 0.0} train loss: 0.213804, valid loss:0.214721, loss_diff:0.000917\n",
      "=================>{'min_split_gain': 0.0} loss:0.214299\n",
      "{'min_split_gain': 0.1} train loss: 0.213920, valid loss:0.214252, loss_diff:0.000331\n",
      "{'min_split_gain': 0.1} train loss: 0.213755, valid loss:0.215107, loss_diff:0.001352\n",
      "{'min_split_gain': 0.1} train loss: 0.214055, valid loss:0.213606, loss_diff:-0.000449\n",
      "{'min_split_gain': 0.1} train loss: 0.214021, valid loss:0.213776, loss_diff:-0.000245\n",
      "{'min_split_gain': 0.1} train loss: 0.213790, valid loss:0.214729, loss_diff:0.000938\n",
      "=================>{'min_split_gain': 0.1} loss:0.214294\n",
      "{'min_split_gain': 0.2} train loss: 0.213925, valid loss:0.214274, loss_diff:0.000349\n",
      "{'min_split_gain': 0.2} train loss: 0.213742, valid loss:0.215098, loss_diff:0.001357\n",
      "{'min_split_gain': 0.2} train loss: 0.214065, valid loss:0.213638, loss_diff:-0.000427\n",
      "{'min_split_gain': 0.2} train loss: 0.214018, valid loss:0.213760, loss_diff:-0.000258\n",
      "{'min_split_gain': 0.2} train loss: 0.213804, valid loss:0.214729, loss_diff:0.000925\n",
      "=================>{'min_split_gain': 0.2} loss:0.214300\n",
      "{'min_split_gain': 0.3} train loss: 0.213934, valid loss:0.214260, loss_diff:0.000327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-debc7f84c536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m }\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mfit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_eval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Kaggle Competitions\\Kaggle-avito-demand-prediction\\GridSearcher.py\u001b[0m in \u001b[0;36mfit_params\u001b[1;34m(X, y, model_loader, default_params, try_params, use_eval_set, fit_params, seed, loss_func, predict_proba)\u001b[0m\n\u001b[0;32m    303\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    610\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    457\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    197\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1437\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1438\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'dart', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.0, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'min_split_gain': [.0, .1, .2, .3, .4]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6} train loss: 0.212777, valid loss:0.212907, loss_diff:0.000130\n",
      "{'colsample_bytree': 0.6} train loss: 0.212682, valid loss:0.213379, loss_diff:0.000696\n",
      "{'colsample_bytree': 0.6} train loss: 0.212666, valid loss:0.213448, loss_diff:0.000782\n",
      "{'colsample_bytree': 0.6} train loss: 0.212721, valid loss:0.213123, loss_diff:0.000403\n",
      "{'colsample_bytree': 0.6} train loss: 0.212778, valid loss:0.212892, loss_diff:0.000114\n",
      "=================>{'colsample_bytree': 0.6} loss:0.213150\n",
      "{'colsample_bytree': 0.7} train loss: 0.212761, valid loss:0.212934, loss_diff:0.000172\n",
      "{'colsample_bytree': 0.7} train loss: 0.212644, valid loss:0.213358, loss_diff:0.000714\n",
      "{'colsample_bytree': 0.7} train loss: 0.212643, valid loss:0.213420, loss_diff:0.000777\n",
      "{'colsample_bytree': 0.7} train loss: 0.212692, valid loss:0.213109, loss_diff:0.000417\n",
      "{'colsample_bytree': 0.7} train loss: 0.212771, valid loss:0.212889, loss_diff:0.000118\n",
      "=================>{'colsample_bytree': 0.7} loss:0.213142\n",
      "{'colsample_bytree': 0.8} train loss: 0.212740, valid loss:0.212878, loss_diff:0.000138\n",
      "{'colsample_bytree': 0.8} train loss: 0.212634, valid loss:0.213355, loss_diff:0.000721\n",
      "{'colsample_bytree': 0.8} train loss: 0.212615, valid loss:0.213405, loss_diff:0.000790\n",
      "{'colsample_bytree': 0.8} train loss: 0.212686, valid loss:0.213088, loss_diff:0.000401\n",
      "{'colsample_bytree': 0.8} train loss: 0.212766, valid loss:0.212889, loss_diff:0.000123\n",
      "=================>{'colsample_bytree': 0.8} loss:0.213123\n",
      "{'colsample_bytree': 0.9} train loss: 0.212744, valid loss:0.212931, loss_diff:0.000187\n",
      "{'colsample_bytree': 0.9} train loss: 0.212640, valid loss:0.213351, loss_diff:0.000711\n",
      "{'colsample_bytree': 0.9} train loss: 0.212613, valid loss:0.213417, loss_diff:0.000803\n",
      "{'colsample_bytree': 0.9} train loss: 0.212687, valid loss:0.213103, loss_diff:0.000417\n",
      "{'colsample_bytree': 0.9} train loss: 0.212759, valid loss:0.212897, loss_diff:0.000139\n",
      "=================>{'colsample_bytree': 0.9} loss:0.213140\n",
      "{'colsample_bytree': 1.0} train loss: 0.212707, valid loss:0.212882, loss_diff:0.000174\n",
      "{'colsample_bytree': 1.0} train loss: 0.212610, valid loss:0.213326, loss_diff:0.000716\n",
      "{'colsample_bytree': 1.0} train loss: 0.212597, valid loss:0.213393, loss_diff:0.000795\n",
      "{'colsample_bytree': 1.0} train loss: 0.212668, valid loss:0.213069, loss_diff:0.000401\n",
      "{'colsample_bytree': 1.0} train loss: 0.212739, valid loss:0.212878, loss_diff:0.000139\n",
      "=================>{'colsample_bytree': 1.0} loss:0.213110\n",
      "Best params: {'colsample_bytree': 1.0} \tbest loss: 0.213109551841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'colsample_bytree': 0.6}</td>\n",
       "      <td>0.213150</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'colsample_bytree': 0.7}</td>\n",
       "      <td>0.213142</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'colsample_bytree': 0.8}</td>\n",
       "      <td>0.213123</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'colsample_bytree': 0.9}</td>\n",
       "      <td>0.213140</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'colsample_bytree': 1.0}</td>\n",
       "      <td>0.213110</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       param  val_loss_mean  val_loss_std\n",
       "0  {'colsample_bytree': 0.6}       0.213150      0.000231\n",
       "1  {'colsample_bytree': 0.7}       0.213142      0.000216\n",
       "2  {'colsample_bytree': 0.8}       0.213123      0.000223\n",
       "3  {'colsample_bytree': 0.9}       0.213140      0.000212\n",
       "4  {'colsample_bytree': 1.0}       0.213110      0.000217"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'dart', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.3, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6} train loss: 0.212709, valid loss:0.212853, loss_diff:0.000144\n",
      "{'subsample': 0.6} train loss: 0.212645, valid loss:0.213329, loss_diff:0.000684\n",
      "{'subsample': 0.6} train loss: 0.212630, valid loss:0.213384, loss_diff:0.000754\n",
      "{'subsample': 0.6} train loss: 0.212655, valid loss:0.213066, loss_diff:0.000410\n",
      "{'subsample': 0.6} train loss: 0.212758, valid loss:0.212853, loss_diff:0.000095\n",
      "=================>{'subsample': 0.6} loss:0.213097\n",
      "{'subsample': 0.7} train loss: 0.212711, valid loss:0.212867, loss_diff:0.000157\n",
      "{'subsample': 0.7} train loss: 0.212632, valid loss:0.213330, loss_diff:0.000698\n",
      "{'subsample': 0.7} train loss: 0.212620, valid loss:0.213375, loss_diff:0.000755\n",
      "{'subsample': 0.7} train loss: 0.212664, valid loss:0.213054, loss_diff:0.000390\n",
      "{'subsample': 0.7} train loss: 0.212737, valid loss:0.212844, loss_diff:0.000107\n",
      "=================>{'subsample': 0.7} loss:0.213094\n",
      "{'subsample': 0.8} train loss: 0.212731, valid loss:0.212885, loss_diff:0.000154\n",
      "{'subsample': 0.8} train loss: 0.212635, valid loss:0.213348, loss_diff:0.000713\n",
      "{'subsample': 0.8} train loss: 0.212602, valid loss:0.213379, loss_diff:0.000777\n",
      "{'subsample': 0.8} train loss: 0.212661, valid loss:0.213069, loss_diff:0.000408\n",
      "{'subsample': 0.8} train loss: 0.212738, valid loss:0.212860, loss_diff:0.000122\n",
      "=================>{'subsample': 0.8} loss:0.213108\n",
      "{'subsample': 0.9} train loss: 0.212753, valid loss:0.212929, loss_diff:0.000176\n",
      "{'subsample': 0.9} train loss: 0.212634, valid loss:0.213344, loss_diff:0.000710\n",
      "{'subsample': 0.9} train loss: 0.212616, valid loss:0.213407, loss_diff:0.000791\n",
      "{'subsample': 0.9} train loss: 0.212685, valid loss:0.213092, loss_diff:0.000407\n",
      "{'subsample': 0.9} train loss: 0.212733, valid loss:0.212856, loss_diff:0.000123\n",
      "=================>{'subsample': 0.9} loss:0.213126\n",
      "{'subsample': 1.0} train loss: 0.212707, valid loss:0.212882, loss_diff:0.000174\n",
      "{'subsample': 1.0} train loss: 0.212610, valid loss:0.213326, loss_diff:0.000716\n",
      "{'subsample': 1.0} train loss: 0.212597, valid loss:0.213393, loss_diff:0.000795\n",
      "{'subsample': 1.0} train loss: 0.212668, valid loss:0.213069, loss_diff:0.000401\n",
      "{'subsample': 1.0} train loss: 0.212739, valid loss:0.212878, loss_diff:0.000139\n",
      "=================>{'subsample': 1.0} loss:0.213110\n",
      "Best params: {'subsample': 0.7} \tbest loss: 0.213094093686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.6}</td>\n",
       "      <td>0.213097</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.7}</td>\n",
       "      <td>0.213094</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'subsample': 0.8}</td>\n",
       "      <td>0.213108</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'subsample': 0.9}</td>\n",
       "      <td>0.213126</td>\n",
       "      <td>0.000219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'subsample': 1.0}</td>\n",
       "      <td>0.213110</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'subsample': 0.6}       0.213097      0.000226\n",
       "1  {'subsample': 0.7}       0.213094      0.000223\n",
       "2  {'subsample': 0.8}       0.213108      0.000221\n",
       "3  {'subsample': 0.9}       0.213126      0.000219\n",
       "4  {'subsample': 1.0}       0.213110      0.000217"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'dart', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.3, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'subsample':[i/10.0 for i in range(6,11)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 1.0} train loss: 0.212702, valid loss:0.212864, loss_diff:0.000162\n",
      "{'reg_alpha': 1.0} train loss: 0.212614, valid loss:0.213305, loss_diff:0.000691\n",
      "{'reg_alpha': 1.0} train loss: 0.212582, valid loss:0.213371, loss_diff:0.000788\n",
      "{'reg_alpha': 1.0} train loss: 0.212675, valid loss:0.213072, loss_diff:0.000397\n",
      "{'reg_alpha': 1.0} train loss: 0.212702, valid loss:0.212821, loss_diff:0.000118\n",
      "=================>{'reg_alpha': 1.0} loss:0.213086\n",
      "{'reg_alpha': 1.5} train loss: 0.212732, valid loss:0.212871, loss_diff:0.000139\n",
      "{'reg_alpha': 1.5} train loss: 0.212631, valid loss:0.213312, loss_diff:0.000681\n",
      "{'reg_alpha': 1.5} train loss: 0.212605, valid loss:0.213374, loss_diff:0.000770\n",
      "{'reg_alpha': 1.5} train loss: 0.212669, valid loss:0.213057, loss_diff:0.000388\n",
      "{'reg_alpha': 1.5} train loss: 0.212743, valid loss:0.212854, loss_diff:0.000111\n",
      "=================>{'reg_alpha': 1.5} loss:0.213093\n",
      "{'reg_alpha': 2.0} train loss: 0.212711, valid loss:0.212867, loss_diff:0.000157\n",
      "{'reg_alpha': 2.0} train loss: 0.212632, valid loss:0.213330, loss_diff:0.000698\n",
      "{'reg_alpha': 2.0} train loss: 0.212620, valid loss:0.213375, loss_diff:0.000755\n",
      "{'reg_alpha': 2.0} train loss: 0.212664, valid loss:0.213054, loss_diff:0.000390\n",
      "{'reg_alpha': 2.0} train loss: 0.212737, valid loss:0.212844, loss_diff:0.000107\n",
      "=================>{'reg_alpha': 2.0} loss:0.213094\n",
      "{'reg_alpha': 2.5} train loss: 0.212723, valid loss:0.212877, loss_diff:0.000154\n",
      "{'reg_alpha': 2.5} train loss: 0.212632, valid loss:0.213304, loss_diff:0.000672\n",
      "{'reg_alpha': 2.5} train loss: 0.212617, valid loss:0.213390, loss_diff:0.000773\n",
      "{'reg_alpha': 2.5} train loss: 0.212677, valid loss:0.213087, loss_diff:0.000410\n",
      "{'reg_alpha': 2.5} train loss: 0.212740, valid loss:0.212861, loss_diff:0.000122\n",
      "=================>{'reg_alpha': 2.5} loss:0.213104\n",
      "{'reg_alpha': 3.0} train loss: 0.212738, valid loss:0.212883, loss_diff:0.000145\n",
      "{'reg_alpha': 3.0} train loss: 0.212641, valid loss:0.213324, loss_diff:0.000683\n",
      "{'reg_alpha': 3.0} train loss: 0.212635, valid loss:0.213402, loss_diff:0.000767\n",
      "{'reg_alpha': 3.0} train loss: 0.212694, valid loss:0.213084, loss_diff:0.000390\n",
      "{'reg_alpha': 3.0} train loss: 0.212756, valid loss:0.212859, loss_diff:0.000103\n",
      "=================>{'reg_alpha': 3.0} loss:0.213110\n",
      "Best params: {'reg_alpha': 1.0} \tbest loss: 0.213086329661\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'reg_alpha': 1.0}</td>\n",
       "      <td>0.213086</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'reg_alpha': 1.5}</td>\n",
       "      <td>0.213093</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'reg_alpha': 2.0}</td>\n",
       "      <td>0.213094</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'reg_alpha': 2.5}</td>\n",
       "      <td>0.213104</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'reg_alpha': 3.0}</td>\n",
       "      <td>0.213110</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param  val_loss_mean  val_loss_std\n",
       "0  {'reg_alpha': 1.0}       0.213086      0.000223\n",
       "1  {'reg_alpha': 1.5}       0.213093      0.000217\n",
       "2  {'reg_alpha': 2.0}       0.213094      0.000223\n",
       "3  {'reg_alpha': 2.5}       0.213104      0.000216\n",
       "4  {'reg_alpha': 3.0}       0.213110      0.000222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'dart', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.3, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':.7,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_alpha':[1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 0.0} train loss: 0.212702, valid loss:0.212864, loss_diff:0.000162\n",
      "{'reg_lambda': 0.0} train loss: 0.212614, valid loss:0.213305, loss_diff:0.000691\n",
      "{'reg_lambda': 0.0} train loss: 0.212582, valid loss:0.213371, loss_diff:0.000788\n",
      "{'reg_lambda': 0.0} train loss: 0.212675, valid loss:0.213072, loss_diff:0.000397\n",
      "{'reg_lambda': 0.0} train loss: 0.212702, valid loss:0.212821, loss_diff:0.000118\n",
      "=================>{'reg_lambda': 0.0} loss:0.213086\n",
      "{'reg_lambda': 0.1} train loss: 0.212705, valid loss:0.212876, loss_diff:0.000171\n",
      "{'reg_lambda': 0.1} train loss: 0.212607, valid loss:0.213300, loss_diff:0.000693\n",
      "{'reg_lambda': 0.1} train loss: 0.212582, valid loss:0.213371, loss_diff:0.000788\n",
      "{'reg_lambda': 0.1} train loss: 0.212675, valid loss:0.213072, loss_diff:0.000397\n",
      "{'reg_lambda': 0.1} train loss: 0.212718, valid loss:0.212836, loss_diff:0.000118\n",
      "=================>{'reg_lambda': 0.1} loss:0.213091\n",
      "{'reg_lambda': 0.2} train loss: 0.212700, valid loss:0.212859, loss_diff:0.000159\n",
      "{'reg_lambda': 0.2} train loss: 0.212611, valid loss:0.213313, loss_diff:0.000701\n",
      "{'reg_lambda': 0.2} train loss: 0.212601, valid loss:0.213387, loss_diff:0.000786\n",
      "{'reg_lambda': 0.2} train loss: 0.212661, valid loss:0.213062, loss_diff:0.000401\n",
      "{'reg_lambda': 0.2} train loss: 0.212728, valid loss:0.212852, loss_diff:0.000124\n",
      "=================>{'reg_lambda': 0.2} loss:0.213094\n",
      "{'reg_lambda': 0.3} train loss: 0.212700, valid loss:0.212859, loss_diff:0.000159\n",
      "{'reg_lambda': 0.3} train loss: 0.212606, valid loss:0.213308, loss_diff:0.000701\n",
      "{'reg_lambda': 0.3} train loss: 0.212595, valid loss:0.213378, loss_diff:0.000783\n",
      "{'reg_lambda': 0.3} train loss: 0.212668, valid loss:0.213075, loss_diff:0.000406\n",
      "{'reg_lambda': 0.3} train loss: 0.212719, valid loss:0.212839, loss_diff:0.000120\n",
      "=================>{'reg_lambda': 0.3} loss:0.213092\n",
      "{'reg_lambda': 0.4} train loss: 0.212717, valid loss:0.212890, loss_diff:0.000173\n",
      "{'reg_lambda': 0.4} train loss: 0.212604, valid loss:0.213312, loss_diff:0.000708\n",
      "{'reg_lambda': 0.4} train loss: 0.212588, valid loss:0.213375, loss_diff:0.000787\n",
      "{'reg_lambda': 0.4} train loss: 0.212668, valid loss:0.213075, loss_diff:0.000406\n",
      "{'reg_lambda': 0.4} train loss: 0.212718, valid loss:0.212833, loss_diff:0.000115\n",
      "=================>{'reg_lambda': 0.4} loss:0.213097\n",
      "{'reg_lambda': 0.5} train loss: 0.212698, valid loss:0.212876, loss_diff:0.000178\n",
      "{'reg_lambda': 0.5} train loss: 0.212606, valid loss:0.213309, loss_diff:0.000703\n",
      "{'reg_lambda': 0.5} train loss: 0.212587, valid loss:0.213374, loss_diff:0.000787\n",
      "{'reg_lambda': 0.5} train loss: 0.212657, valid loss:0.213066, loss_diff:0.000409\n",
      "{'reg_lambda': 0.5} train loss: 0.212725, valid loss:0.212845, loss_diff:0.000121\n",
      "=================>{'reg_lambda': 0.5} loss:0.213094\n",
      "{'reg_lambda': 0.6} train loss: 0.212715, valid loss:0.212878, loss_diff:0.000163\n",
      "{'reg_lambda': 0.6} train loss: 0.212618, valid loss:0.213318, loss_diff:0.000700\n",
      "{'reg_lambda': 0.6} train loss: 0.212605, valid loss:0.213366, loss_diff:0.000761\n",
      "{'reg_lambda': 0.6} train loss: 0.212670, valid loss:0.213075, loss_diff:0.000405\n",
      "{'reg_lambda': 0.6} train loss: 0.212734, valid loss:0.212846, loss_diff:0.000112\n",
      "=================>{'reg_lambda': 0.6} loss:0.213097\n",
      "{'reg_lambda': 0.7} train loss: 0.212704, valid loss:0.212867, loss_diff:0.000162\n",
      "{'reg_lambda': 0.7} train loss: 0.212616, valid loss:0.213310, loss_diff:0.000695\n",
      "{'reg_lambda': 0.7} train loss: 0.212588, valid loss:0.213362, loss_diff:0.000774\n",
      "{'reg_lambda': 0.7} train loss: 0.212660, valid loss:0.213078, loss_diff:0.000418\n",
      "{'reg_lambda': 0.7} train loss: 0.212742, valid loss:0.212861, loss_diff:0.000119\n",
      "=================>{'reg_lambda': 0.7} loss:0.213096\n",
      "{'reg_lambda': 0.8} train loss: 0.212705, valid loss:0.212866, loss_diff:0.000161\n",
      "{'reg_lambda': 0.8} train loss: 0.212618, valid loss:0.213323, loss_diff:0.000705\n",
      "{'reg_lambda': 0.8} train loss: 0.212589, valid loss:0.213362, loss_diff:0.000774\n",
      "{'reg_lambda': 0.8} train loss: 0.212647, valid loss:0.213074, loss_diff:0.000427\n",
      "{'reg_lambda': 0.8} train loss: 0.212713, valid loss:0.212831, loss_diff:0.000118\n",
      "=================>{'reg_lambda': 0.8} loss:0.213091\n",
      "{'reg_lambda': 0.9} train loss: 0.212715, valid loss:0.212878, loss_diff:0.000163\n",
      "{'reg_lambda': 0.9} train loss: 0.212607, valid loss:0.213290, loss_diff:0.000683\n",
      "{'reg_lambda': 0.9} train loss: 0.212589, valid loss:0.213362, loss_diff:0.000774\n",
      "{'reg_lambda': 0.9} train loss: 0.212635, valid loss:0.213059, loss_diff:0.000424\n",
      "{'reg_lambda': 0.9} train loss: 0.212719, valid loss:0.212825, loss_diff:0.000106\n",
      "=================>{'reg_lambda': 0.9} loss:0.213083\n",
      "{'reg_lambda': 1.0} train loss: 0.212703, valid loss:0.212847, loss_diff:0.000144\n",
      "{'reg_lambda': 1.0} train loss: 0.212619, valid loss:0.213316, loss_diff:0.000697\n",
      "{'reg_lambda': 1.0} train loss: 0.212577, valid loss:0.213344, loss_diff:0.000767\n",
      "{'reg_lambda': 1.0} train loss: 0.212635, valid loss:0.213059, loss_diff:0.000424\n",
      "{'reg_lambda': 1.0} train loss: 0.212732, valid loss:0.212845, loss_diff:0.000113\n",
      "=================>{'reg_lambda': 1.0} loss:0.213082\n",
      "Best params: {'reg_lambda': 1.0} \tbest loss: 0.213082108106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'reg_lambda': 0.0}</td>\n",
       "      <td>0.213086</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'reg_lambda': 0.1}</td>\n",
       "      <td>0.213091</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'reg_lambda': 0.2}</td>\n",
       "      <td>0.213094</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'reg_lambda': 0.3}</td>\n",
       "      <td>0.213092</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'reg_lambda': 0.4}</td>\n",
       "      <td>0.213097</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'reg_lambda': 0.5}</td>\n",
       "      <td>0.213094</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'reg_lambda': 0.6}</td>\n",
       "      <td>0.213097</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'reg_lambda': 0.7}</td>\n",
       "      <td>0.213096</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'reg_lambda': 0.8}</td>\n",
       "      <td>0.213091</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'reg_lambda': 0.9}</td>\n",
       "      <td>0.213083</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'reg_lambda': 1.0}</td>\n",
       "      <td>0.213082</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  param  val_loss_mean  val_loss_std\n",
       "0   {'reg_lambda': 0.0}       0.213086      0.000223\n",
       "1   {'reg_lambda': 0.1}       0.213091      0.000216\n",
       "2   {'reg_lambda': 0.2}       0.213094      0.000223\n",
       "3   {'reg_lambda': 0.3}       0.213092      0.000222\n",
       "4   {'reg_lambda': 0.4}       0.213097      0.000217\n",
       "5   {'reg_lambda': 0.5}       0.213094      0.000217\n",
       "6   {'reg_lambda': 0.6}       0.213097      0.000216\n",
       "7   {'reg_lambda': 0.7}       0.213096      0.000212\n",
       "8   {'reg_lambda': 0.8}       0.213091      0.000222\n",
       "9   {'reg_lambda': 0.9}       0.213083      0.000214\n",
       "10  {'reg_lambda': 1.0}       0.213082      0.000217"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {\n",
    "    'boosting_type':'dart', \n",
    "    'num_leaves':31, \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'min_split_gain':0.3, \n",
    "    'min_child_weight':0.001, \n",
    "    'min_child_samples':20, \n",
    "    'subsample':.7,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':1.0, \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_lambda':[i/10.0 for i in range(0,11,1)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB-gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'min_child_weight':[0.001, 0.1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'gamma':[.0, .1, .2, .3, .4]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'subsample':[i/10.0 for i in range(6,11)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_alpha':[1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = model_loader(model_type='xgb')\n",
    "\n",
    "default_params = {\n",
    "    'booster':'gbtree', \n",
    "    'max_depth':5, \n",
    "    'learning_rate':0.1, \n",
    "    'n_estimators':100, \n",
    "    'gamma':0.0, \n",
    "    'min_child_weight':0.001,\n",
    "    'subsample':1.,  \n",
    "    'colsample_bytree':1., \n",
    "    'reg_alpha':2., \n",
    "    'reg_lambda':0.0, \n",
    "    'random_state':SEED, \n",
    "    'n_jobs': 3\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'reg_lambda':[i/10.0 for i in range(0,11,1)]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1} train loss: 0.208715, valid loss:0.208575, loss_diff:-0.000140\n",
      "{'alpha': 1} train loss: 0.208544, valid loss:0.209267, loss_diff:0.000723\n",
      "{'alpha': 1} train loss: 0.208741, valid loss:0.208355, loss_diff:-0.000386\n",
      "{'alpha': 1} train loss: 0.208740, valid loss:0.208457, loss_diff:-0.000283\n",
      "{'alpha': 1} train loss: 0.208566, valid loss:0.209163, loss_diff:0.000597\n",
      "=================>{'alpha': 1} loss:0.208764\n",
      "Best params: {'alpha': 1} \tbest loss: 0.208763611475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.208764</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          param  val_loss_mean  val_loss_std\n",
       "0  {'alpha': 1}       0.208764      0.000377"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = model_loader(model_type='rg')\n",
    "\n",
    "default_params = {\n",
    "    'alpha': 1.0, \n",
    "    'fit_intercept': True, \n",
    "    'normalize': False, \n",
    "    'copy_X': True, \n",
    "    'max_iter': None, \n",
    "    'tol': 0.001, \n",
    "    'solver':'auto', \n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'alpha':[1,]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.05} train loss: 0.208980, valid loss:0.208786, loss_diff:-0.000193\n",
      "{'alpha': 0.05} train loss: 0.208807, valid loss:0.209493, loss_diff:0.000686\n",
      "{'alpha': 0.05} train loss: 0.208991, valid loss:0.208590, loss_diff:-0.000402\n",
      "{'alpha': 0.05} train loss: 0.209001, valid loss:0.208670, loss_diff:-0.000330\n",
      "{'alpha': 0.05} train loss: 0.208833, valid loss:0.209363, loss_diff:0.000529\n",
      "=================>{'alpha': 0.05} loss:0.208980\n",
      "{'alpha': 0.1} train loss: 0.208980, valid loss:0.208786, loss_diff:-0.000193\n",
      "{'alpha': 0.1} train loss: 0.208807, valid loss:0.209493, loss_diff:0.000686\n",
      "{'alpha': 0.1} train loss: 0.208992, valid loss:0.208590, loss_diff:-0.000402\n",
      "{'alpha': 0.1} train loss: 0.209001, valid loss:0.208670, loss_diff:-0.000330\n",
      "{'alpha': 0.1} train loss: 0.208833, valid loss:0.209363, loss_diff:0.000530\n",
      "=================>{'alpha': 0.1} loss:0.208980\n",
      "{'alpha': 0.5} train loss: 0.208981, valid loss:0.208788, loss_diff:-0.000193\n",
      "{'alpha': 0.5} train loss: 0.208808, valid loss:0.209492, loss_diff:0.000684\n",
      "{'alpha': 0.5} train loss: 0.208993, valid loss:0.208591, loss_diff:-0.000402\n",
      "{'alpha': 0.5} train loss: 0.209002, valid loss:0.208671, loss_diff:-0.000330\n",
      "{'alpha': 0.5} train loss: 0.208835, valid loss:0.209365, loss_diff:0.000530\n",
      "=================>{'alpha': 0.5} loss:0.208981\n",
      "Best params: {'alpha': 0.05} \tbest loss: 0.208980368389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>0.208980</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.208980</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>0.208981</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param  val_loss_mean  val_loss_std\n",
       "0  {'alpha': 0.05}       0.208980      0.000373\n",
       "1   {'alpha': 0.1}       0.208980      0.000373\n",
       "2   {'alpha': 0.5}       0.208981      0.000372"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = model_loader(model_type='rg')\n",
    "\n",
    "default_params = {\n",
    "    'alpha': 1.0, \n",
    "    'fit_intercept': True, \n",
    "    'normalize': False, \n",
    "    'copy_X': True, \n",
    "    'max_iter': None, \n",
    "    'tol': 0.001, \n",
    "    'solver':'auto', \n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'alpha':[0.05, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "fit_params(train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging + Ultimate Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [9910019]\n",
    "config = {\n",
    "    'lgb_xenp': {\n",
    "        'ml': model_loader(model_type='lgb'),\n",
    "        'param': {\n",
    "            'boosting_type':'gbdt', \n",
    "            'objective': 'xentropy',\n",
    "            'num_leaves':31, \n",
    "            'max_depth':8, \n",
    "            'learning_rate':0.02, \n",
    "            'n_estimators':5000, \n",
    "            'min_split_gain':0.0, \n",
    "            'min_child_weight':0.001, \n",
    "            'min_child_samples':20, \n",
    "            'subsample':1.,  \n",
    "            'colsample_bytree':.9, \n",
    "            'reg_alpha':5.5, \n",
    "            'reg_lambda':0.0, \n",
    "            'random_state':SEED, \n",
    "            'n_jobs': 4\n",
    "        },\n",
    "        'fit_param': {\n",
    "            'early_stopping_rounds': 100,\n",
    "            'verbose': 100,\n",
    "            'eval_metric': 'rmse'\n",
    "        }\n",
    "    },\n",
    "    'lgb_gbdt':{\n",
    "        'ml': model_loader(model_type='lgb'),\n",
    "        'param': {\n",
    "            'boosting_type':'gbdt', \n",
    "            'num_leaves':31, \n",
    "            'max_depth':5, \n",
    "            'learning_rate':0.02, \n",
    "            'n_estimators':5000, \n",
    "            'min_split_gain':0.0, \n",
    "            'min_child_weight':0.001, \n",
    "            'min_child_samples':20, \n",
    "            'subsample':1.,  \n",
    "            'colsample_bytree':1., \n",
    "            'reg_alpha':2.5, \n",
    "            'reg_lambda':0.1, \n",
    "            'random_state':SEED, \n",
    "            'n_jobs': 4\n",
    "        },\n",
    "        'fit_param': {\n",
    "            'early_stopping_rounds': 100,\n",
    "            'verbose': 100,\n",
    "            'eval_metric': 'rmse'\n",
    "        }\n",
    "    },\n",
    "    'ridge':{\n",
    "        'ml': model_loader(model_type='rg'),\n",
    "        'param': {\n",
    "            'alpha': .5, \n",
    "            'fit_intercept': True, \n",
    "            'normalize': False, \n",
    "            'copy_X': True, \n",
    "            'max_iter': None, \n",
    "            'tol': 0.001, \n",
    "            'solver':'auto', \n",
    "            'random_state': SEED\n",
    "        },\n",
    "        'fit_param': None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training & bagging:  lgb_xenp\n",
      "Training seed = 9910019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211218\tvalid's rmse: 0.211431\n",
      "[200]\ttrain's rmse: 0.209117\tvalid's rmse: 0.20949\n",
      "[300]\ttrain's rmse: 0.208521\tvalid's rmse: 0.209112\n",
      "[400]\ttrain's rmse: 0.208123\tvalid's rmse: 0.20892\n",
      "[500]\ttrain's rmse: 0.207773\tvalid's rmse: 0.208795\n",
      "[600]\ttrain's rmse: 0.20747\tvalid's rmse: 0.208709\n",
      "[700]\ttrain's rmse: 0.207195\tvalid's rmse: 0.20865\n",
      "[800]\ttrain's rmse: 0.206926\tvalid's rmse: 0.208597\n",
      "[900]\ttrain's rmse: 0.206667\tvalid's rmse: 0.208562\n",
      "[1000]\ttrain's rmse: 0.206412\tvalid's rmse: 0.208522\n",
      "[1100]\ttrain's rmse: 0.206177\tvalid's rmse: 0.208494\n",
      "[1200]\ttrain's rmse: 0.205939\tvalid's rmse: 0.208471\n",
      "[1300]\ttrain's rmse: 0.205717\tvalid's rmse: 0.208451\n",
      "[1400]\ttrain's rmse: 0.20549\tvalid's rmse: 0.208426\n",
      "[1500]\ttrain's rmse: 0.205266\tvalid's rmse: 0.208401\n",
      "[1600]\ttrain's rmse: 0.205053\tvalid's rmse: 0.208374\n",
      "[1700]\ttrain's rmse: 0.204829\tvalid's rmse: 0.20835\n",
      "[1800]\ttrain's rmse: 0.204607\tvalid's rmse: 0.208326\n",
      "[1900]\ttrain's rmse: 0.204397\tvalid's rmse: 0.208308\n",
      "[2000]\ttrain's rmse: 0.204196\tvalid's rmse: 0.208298\n",
      "[2100]\ttrain's rmse: 0.203992\tvalid's rmse: 0.208284\n",
      "[2200]\ttrain's rmse: 0.203793\tvalid's rmse: 0.208278\n",
      "[2300]\ttrain's rmse: 0.203582\tvalid's rmse: 0.208263\n",
      "[2400]\ttrain's rmse: 0.203393\tvalid's rmse: 0.208254\n",
      "[2500]\ttrain's rmse: 0.20319\tvalid's rmse: 0.208245\n",
      "[2600]\ttrain's rmse: 0.202989\tvalid's rmse: 0.208232\n",
      "[2700]\ttrain's rmse: 0.2028\tvalid's rmse: 0.208222\n",
      "[2800]\ttrain's rmse: 0.202608\tvalid's rmse: 0.208213\n",
      "[2900]\ttrain's rmse: 0.202408\tvalid's rmse: 0.208204\n",
      "[3000]\ttrain's rmse: 0.202216\tvalid's rmse: 0.208194\n",
      "[3100]\ttrain's rmse: 0.202024\tvalid's rmse: 0.208184\n",
      "[3200]\ttrain's rmse: 0.201841\tvalid's rmse: 0.208179\n",
      "[3300]\ttrain's rmse: 0.201652\tvalid's rmse: 0.208176\n",
      "[3400]\ttrain's rmse: 0.201466\tvalid's rmse: 0.208167\n",
      "[3500]\ttrain's rmse: 0.201288\tvalid's rmse: 0.208166\n",
      "Early stopping, best iteration is:\n",
      "[3465]\ttrain's rmse: 0.201355\tvalid's rmse: 0.208164\n",
      "Fold 1 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211014\tvalid's rmse: 0.212086\n",
      "[200]\ttrain's rmse: 0.208921\tvalid's rmse: 0.210209\n",
      "[300]\ttrain's rmse: 0.208339\tvalid's rmse: 0.209828\n",
      "[400]\ttrain's rmse: 0.207949\tvalid's rmse: 0.209641\n",
      "[500]\ttrain's rmse: 0.207605\tvalid's rmse: 0.209519\n",
      "[600]\ttrain's rmse: 0.207301\tvalid's rmse: 0.20944\n",
      "[700]\ttrain's rmse: 0.207029\tvalid's rmse: 0.209383\n",
      "[800]\ttrain's rmse: 0.20677\tvalid's rmse: 0.209336\n",
      "[900]\ttrain's rmse: 0.206518\tvalid's rmse: 0.209294\n",
      "[1000]\ttrain's rmse: 0.206277\tvalid's rmse: 0.209264\n",
      "[1100]\ttrain's rmse: 0.206044\tvalid's rmse: 0.209237\n",
      "[1200]\ttrain's rmse: 0.205805\tvalid's rmse: 0.209209\n",
      "[1300]\ttrain's rmse: 0.205562\tvalid's rmse: 0.209174\n",
      "[1400]\ttrain's rmse: 0.205331\tvalid's rmse: 0.209146\n",
      "[1500]\ttrain's rmse: 0.2051\tvalid's rmse: 0.209123\n",
      "[1600]\ttrain's rmse: 0.204885\tvalid's rmse: 0.209105\n",
      "[1700]\ttrain's rmse: 0.204665\tvalid's rmse: 0.209087\n",
      "[1800]\ttrain's rmse: 0.204458\tvalid's rmse: 0.209065\n",
      "[1900]\ttrain's rmse: 0.204247\tvalid's rmse: 0.209049\n",
      "[2000]\ttrain's rmse: 0.204029\tvalid's rmse: 0.20902\n",
      "[2100]\ttrain's rmse: 0.203819\tvalid's rmse: 0.209009\n",
      "[2200]\ttrain's rmse: 0.20362\tvalid's rmse: 0.208991\n",
      "[2300]\ttrain's rmse: 0.203414\tvalid's rmse: 0.208972\n",
      "[2400]\ttrain's rmse: 0.203211\tvalid's rmse: 0.208959\n",
      "[2500]\ttrain's rmse: 0.203016\tvalid's rmse: 0.20895\n",
      "[2600]\ttrain's rmse: 0.202818\tvalid's rmse: 0.208946\n",
      "[2700]\ttrain's rmse: 0.202617\tvalid's rmse: 0.208938\n",
      "[2800]\ttrain's rmse: 0.202427\tvalid's rmse: 0.208929\n",
      "[2900]\ttrain's rmse: 0.202231\tvalid's rmse: 0.208919\n",
      "[3000]\ttrain's rmse: 0.202039\tvalid's rmse: 0.208916\n",
      "[3100]\ttrain's rmse: 0.20185\tvalid's rmse: 0.208909\n",
      "[3200]\ttrain's rmse: 0.201663\tvalid's rmse: 0.208901\n",
      "[3300]\ttrain's rmse: 0.201466\tvalid's rmse: 0.2089\n",
      "[3400]\ttrain's rmse: 0.201281\tvalid's rmse: 0.208894\n",
      "[3500]\ttrain's rmse: 0.201096\tvalid's rmse: 0.208894\n",
      "Early stopping, best iteration is:\n",
      "[3416]\ttrain's rmse: 0.201251\tvalid's rmse: 0.208892\n",
      "Fold 2 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211292\tvalid's rmse: 0.210938\n",
      "[200]\ttrain's rmse: 0.209184\tvalid's rmse: 0.209084\n",
      "[300]\ttrain's rmse: 0.208586\tvalid's rmse: 0.208708\n",
      "[400]\ttrain's rmse: 0.208195\tvalid's rmse: 0.20852\n",
      "[500]\ttrain's rmse: 0.207847\tvalid's rmse: 0.208394\n",
      "[600]\ttrain's rmse: 0.207545\tvalid's rmse: 0.208313\n",
      "[700]\ttrain's rmse: 0.207262\tvalid's rmse: 0.20825\n",
      "[800]\ttrain's rmse: 0.206997\tvalid's rmse: 0.208211\n",
      "[900]\ttrain's rmse: 0.20674\tvalid's rmse: 0.208181\n",
      "[1000]\ttrain's rmse: 0.206493\tvalid's rmse: 0.208153\n",
      "[1100]\ttrain's rmse: 0.206247\tvalid's rmse: 0.208124\n",
      "[1200]\ttrain's rmse: 0.206014\tvalid's rmse: 0.2081\n",
      "[1300]\ttrain's rmse: 0.205779\tvalid's rmse: 0.208074\n",
      "[1400]\ttrain's rmse: 0.205556\tvalid's rmse: 0.208056\n",
      "[1500]\ttrain's rmse: 0.205334\tvalid's rmse: 0.208033\n",
      "[1600]\ttrain's rmse: 0.205106\tvalid's rmse: 0.208005\n",
      "[1700]\ttrain's rmse: 0.204883\tvalid's rmse: 0.207977\n",
      "[1800]\ttrain's rmse: 0.20467\tvalid's rmse: 0.207964\n",
      "[1900]\ttrain's rmse: 0.204448\tvalid's rmse: 0.207938\n",
      "[2000]\ttrain's rmse: 0.204236\tvalid's rmse: 0.207915\n",
      "[2100]\ttrain's rmse: 0.20403\tvalid's rmse: 0.207895\n",
      "[2200]\ttrain's rmse: 0.203828\tvalid's rmse: 0.207884\n",
      "[2300]\ttrain's rmse: 0.203619\tvalid's rmse: 0.207875\n",
      "[2400]\ttrain's rmse: 0.203412\tvalid's rmse: 0.207863\n",
      "[2500]\ttrain's rmse: 0.203202\tvalid's rmse: 0.207858\n",
      "[2600]\ttrain's rmse: 0.203008\tvalid's rmse: 0.207847\n",
      "[2700]\ttrain's rmse: 0.202812\tvalid's rmse: 0.207841\n",
      "[2800]\ttrain's rmse: 0.202631\tvalid's rmse: 0.207835\n",
      "[2900]\ttrain's rmse: 0.202437\tvalid's rmse: 0.207831\n",
      "[3000]\ttrain's rmse: 0.202252\tvalid's rmse: 0.207821\n",
      "[3100]\ttrain's rmse: 0.202061\tvalid's rmse: 0.207818\n",
      "[3200]\ttrain's rmse: 0.201865\tvalid's rmse: 0.207812\n",
      "[3300]\ttrain's rmse: 0.201679\tvalid's rmse: 0.20781\n",
      "[3400]\ttrain's rmse: 0.201491\tvalid's rmse: 0.207804\n",
      "[3500]\ttrain's rmse: 0.201298\tvalid's rmse: 0.207801\n",
      "Early stopping, best iteration is:\n",
      "[3464]\ttrain's rmse: 0.201369\tvalid's rmse: 0.207799\n",
      "Fold 3 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211229\tvalid's rmse: 0.211112\n",
      "[200]\ttrain's rmse: 0.20912\tvalid's rmse: 0.209309\n",
      "[300]\ttrain's rmse: 0.208516\tvalid's rmse: 0.208961\n",
      "[400]\ttrain's rmse: 0.208129\tvalid's rmse: 0.208794\n",
      "[500]\ttrain's rmse: 0.207789\tvalid's rmse: 0.208683\n",
      "[600]\ttrain's rmse: 0.207488\tvalid's rmse: 0.20861\n",
      "[700]\ttrain's rmse: 0.20721\tvalid's rmse: 0.20855\n",
      "[800]\ttrain's rmse: 0.206943\tvalid's rmse: 0.208511\n",
      "[900]\ttrain's rmse: 0.206685\tvalid's rmse: 0.208476\n",
      "[1000]\ttrain's rmse: 0.206438\tvalid's rmse: 0.208449\n",
      "[1100]\ttrain's rmse: 0.206192\tvalid's rmse: 0.208423\n",
      "[1200]\ttrain's rmse: 0.205958\tvalid's rmse: 0.208405\n",
      "[1300]\ttrain's rmse: 0.205731\tvalid's rmse: 0.208387\n",
      "[1400]\ttrain's rmse: 0.205502\tvalid's rmse: 0.208369\n",
      "[1500]\ttrain's rmse: 0.205267\tvalid's rmse: 0.20835\n",
      "[1600]\ttrain's rmse: 0.205043\tvalid's rmse: 0.208329\n",
      "[1700]\ttrain's rmse: 0.204814\tvalid's rmse: 0.208305\n",
      "[1800]\ttrain's rmse: 0.204602\tvalid's rmse: 0.208292\n",
      "[1900]\ttrain's rmse: 0.20439\tvalid's rmse: 0.208275\n",
      "[2000]\ttrain's rmse: 0.204174\tvalid's rmse: 0.208253\n",
      "[2100]\ttrain's rmse: 0.203971\tvalid's rmse: 0.208236\n",
      "[2200]\ttrain's rmse: 0.203763\tvalid's rmse: 0.208216\n",
      "[2300]\ttrain's rmse: 0.203577\tvalid's rmse: 0.208207\n",
      "[2400]\ttrain's rmse: 0.203381\tvalid's rmse: 0.208196\n",
      "[2500]\ttrain's rmse: 0.203175\tvalid's rmse: 0.208186\n",
      "[2600]\ttrain's rmse: 0.20299\tvalid's rmse: 0.208176\n",
      "[2700]\ttrain's rmse: 0.20279\tvalid's rmse: 0.208171\n",
      "[2800]\ttrain's rmse: 0.202595\tvalid's rmse: 0.208161\n",
      "[2900]\ttrain's rmse: 0.2024\tvalid's rmse: 0.208152\n",
      "[3000]\ttrain's rmse: 0.202211\tvalid's rmse: 0.208144\n",
      "[3100]\ttrain's rmse: 0.202009\tvalid's rmse: 0.20814\n",
      "[3200]\ttrain's rmse: 0.201822\tvalid's rmse: 0.208136\n",
      "[3300]\ttrain's rmse: 0.201641\tvalid's rmse: 0.208136\n",
      "[3400]\ttrain's rmse: 0.201451\tvalid's rmse: 0.208133\n",
      "[3500]\ttrain's rmse: 0.201275\tvalid's rmse: 0.208124\n",
      "[3600]\ttrain's rmse: 0.201085\tvalid's rmse: 0.208121\n",
      "[3700]\ttrain's rmse: 0.200887\tvalid's rmse: 0.208118\n",
      "Early stopping, best iteration is:\n",
      "[3664]\ttrain's rmse: 0.200962\tvalid's rmse: 0.208114\n",
      "Fold 4 completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.21104\tvalid's rmse: 0.2118\n",
      "[200]\ttrain's rmse: 0.208938\tvalid's rmse: 0.210024\n",
      "[300]\ttrain's rmse: 0.208351\tvalid's rmse: 0.209699\n",
      "[400]\ttrain's rmse: 0.20796\tvalid's rmse: 0.209526\n",
      "[500]\ttrain's rmse: 0.207608\tvalid's rmse: 0.209412\n",
      "[600]\ttrain's rmse: 0.207295\tvalid's rmse: 0.209342\n",
      "[700]\ttrain's rmse: 0.207005\tvalid's rmse: 0.209283\n",
      "[800]\ttrain's rmse: 0.206744\tvalid's rmse: 0.209234\n",
      "[900]\ttrain's rmse: 0.20649\tvalid's rmse: 0.209198\n",
      "[1000]\ttrain's rmse: 0.206246\tvalid's rmse: 0.209173\n",
      "[1100]\ttrain's rmse: 0.206006\tvalid's rmse: 0.209143\n",
      "[1200]\ttrain's rmse: 0.205775\tvalid's rmse: 0.20912\n",
      "[1300]\ttrain's rmse: 0.205541\tvalid's rmse: 0.209101\n",
      "[1400]\ttrain's rmse: 0.205318\tvalid's rmse: 0.209081\n",
      "[1500]\ttrain's rmse: 0.20511\tvalid's rmse: 0.209071\n",
      "[1600]\ttrain's rmse: 0.204892\tvalid's rmse: 0.20905\n",
      "[1700]\ttrain's rmse: 0.204666\tvalid's rmse: 0.209032\n",
      "[1800]\ttrain's rmse: 0.204455\tvalid's rmse: 0.209013\n",
      "[1900]\ttrain's rmse: 0.204251\tvalid's rmse: 0.209004\n",
      "[2000]\ttrain's rmse: 0.204037\tvalid's rmse: 0.208988\n",
      "[2100]\ttrain's rmse: 0.203834\tvalid's rmse: 0.208971\n",
      "[2200]\ttrain's rmse: 0.203634\tvalid's rmse: 0.208964\n",
      "[2300]\ttrain's rmse: 0.203427\tvalid's rmse: 0.20895\n",
      "[2400]\ttrain's rmse: 0.203225\tvalid's rmse: 0.208937\n",
      "[2500]\ttrain's rmse: 0.203017\tvalid's rmse: 0.208926\n",
      "[2600]\ttrain's rmse: 0.202812\tvalid's rmse: 0.208913\n",
      "[2700]\ttrain's rmse: 0.202624\tvalid's rmse: 0.20891\n",
      "[2800]\ttrain's rmse: 0.202437\tvalid's rmse: 0.208904\n",
      "[2900]\ttrain's rmse: 0.202245\tvalid's rmse: 0.208897\n",
      "[3000]\ttrain's rmse: 0.20206\tvalid's rmse: 0.208883\n",
      "[3100]\ttrain's rmse: 0.201874\tvalid's rmse: 0.208875\n",
      "[3200]\ttrain's rmse: 0.201694\tvalid's rmse: 0.208867\n",
      "[3300]\ttrain's rmse: 0.201501\tvalid's rmse: 0.208858\n",
      "[3400]\ttrain's rmse: 0.201315\tvalid's rmse: 0.208854\n",
      "[3500]\ttrain's rmse: 0.201136\tvalid's rmse: 0.20885\n",
      "[3600]\ttrain's rmse: 0.200952\tvalid's rmse: 0.208841\n",
      "[3700]\ttrain's rmse: 0.200767\tvalid's rmse: 0.208838\n",
      "[3800]\ttrain's rmse: 0.200585\tvalid's rmse: 0.208837\n",
      "[3900]\ttrain's rmse: 0.200416\tvalid's rmse: 0.208837\n",
      "[4000]\ttrain's rmse: 0.200249\tvalid's rmse: 0.208833\n",
      "[4100]\ttrain's rmse: 0.200066\tvalid's rmse: 0.20883\n",
      "[4200]\ttrain's rmse: 0.199886\tvalid's rmse: 0.208824\n",
      "[4300]\ttrain's rmse: 0.199708\tvalid's rmse: 0.208821\n",
      "[4400]\ttrain's rmse: 0.199532\tvalid's rmse: 0.208817\n",
      "[4500]\ttrain's rmse: 0.199363\tvalid's rmse: 0.208819\n",
      "Early stopping, best iteration is:\n",
      "[4426]\ttrain's rmse: 0.199489\tvalid's rmse: 0.208816\n",
      "Fold 5 completed.\n",
      "Training & bagging:  lgb_gbdt\n",
      "Training seed = 9910019\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211351\tvalid's rmse: 0.211525\n",
      "[200]\ttrain's rmse: 0.209284\tvalid's rmse: 0.209628\n",
      "[300]\ttrain's rmse: 0.208724\tvalid's rmse: 0.209296\n",
      "[400]\ttrain's rmse: 0.208325\tvalid's rmse: 0.209091\n",
      "[500]\ttrain's rmse: 0.207949\tvalid's rmse: 0.208931\n",
      "[600]\ttrain's rmse: 0.207634\tvalid's rmse: 0.20882\n",
      "[700]\ttrain's rmse: 0.207339\tvalid's rmse: 0.20874\n",
      "[800]\ttrain's rmse: 0.207078\tvalid's rmse: 0.20868\n",
      "[900]\ttrain's rmse: 0.206831\tvalid's rmse: 0.208628\n",
      "[1000]\ttrain's rmse: 0.206588\tvalid's rmse: 0.208585\n",
      "[1100]\ttrain's rmse: 0.206355\tvalid's rmse: 0.208546\n",
      "[1200]\ttrain's rmse: 0.206129\tvalid's rmse: 0.208517\n",
      "[1300]\ttrain's rmse: 0.205909\tvalid's rmse: 0.208487\n",
      "[1400]\ttrain's rmse: 0.205693\tvalid's rmse: 0.20845\n",
      "[1500]\ttrain's rmse: 0.205495\tvalid's rmse: 0.208418\n",
      "[1600]\ttrain's rmse: 0.205278\tvalid's rmse: 0.208387\n",
      "[1700]\ttrain's rmse: 0.205073\tvalid's rmse: 0.20837\n",
      "[1800]\ttrain's rmse: 0.204865\tvalid's rmse: 0.20836\n",
      "[1900]\ttrain's rmse: 0.20466\tvalid's rmse: 0.208349\n",
      "[2000]\ttrain's rmse: 0.204465\tvalid's rmse: 0.208337\n",
      "[2100]\ttrain's rmse: 0.204269\tvalid's rmse: 0.208328\n",
      "[2200]\ttrain's rmse: 0.204071\tvalid's rmse: 0.208318\n",
      "[2300]\ttrain's rmse: 0.203876\tvalid's rmse: 0.208297\n",
      "[2400]\ttrain's rmse: 0.203683\tvalid's rmse: 0.208282\n",
      "[2500]\ttrain's rmse: 0.203489\tvalid's rmse: 0.208276\n",
      "[2600]\ttrain's rmse: 0.203297\tvalid's rmse: 0.208262\n",
      "[2700]\ttrain's rmse: 0.203104\tvalid's rmse: 0.208249\n",
      "[2800]\ttrain's rmse: 0.202915\tvalid's rmse: 0.208245\n",
      "[2900]\ttrain's rmse: 0.202734\tvalid's rmse: 0.208237\n",
      "[3000]\ttrain's rmse: 0.202543\tvalid's rmse: 0.208238\n",
      "Early stopping, best iteration is:\n",
      "[2920]\ttrain's rmse: 0.202701\tvalid's rmse: 0.208235\n",
      "Fold 1 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.21115\tvalid's rmse: 0.212199\n",
      "[200]\ttrain's rmse: 0.209086\tvalid's rmse: 0.210349\n",
      "[300]\ttrain's rmse: 0.208541\tvalid's rmse: 0.210018\n",
      "[400]\ttrain's rmse: 0.208136\tvalid's rmse: 0.209801\n",
      "[500]\ttrain's rmse: 0.207774\tvalid's rmse: 0.20964\n",
      "[600]\ttrain's rmse: 0.207472\tvalid's rmse: 0.209553\n",
      "[700]\ttrain's rmse: 0.207196\tvalid's rmse: 0.209476\n",
      "[800]\ttrain's rmse: 0.206939\tvalid's rmse: 0.209417\n",
      "[900]\ttrain's rmse: 0.206695\tvalid's rmse: 0.209361\n",
      "[1000]\ttrain's rmse: 0.206452\tvalid's rmse: 0.209303\n",
      "[1100]\ttrain's rmse: 0.206213\tvalid's rmse: 0.209267\n",
      "[1200]\ttrain's rmse: 0.205983\tvalid's rmse: 0.20924\n",
      "[1300]\ttrain's rmse: 0.205754\tvalid's rmse: 0.209208\n",
      "[1400]\ttrain's rmse: 0.20553\tvalid's rmse: 0.209181\n",
      "[1500]\ttrain's rmse: 0.205326\tvalid's rmse: 0.209164\n",
      "[1600]\ttrain's rmse: 0.205105\tvalid's rmse: 0.209132\n",
      "[1700]\ttrain's rmse: 0.204903\tvalid's rmse: 0.209106\n",
      "[1800]\ttrain's rmse: 0.204706\tvalid's rmse: 0.209091\n",
      "[1900]\ttrain's rmse: 0.204498\tvalid's rmse: 0.209065\n",
      "[2000]\ttrain's rmse: 0.204298\tvalid's rmse: 0.209047\n",
      "[2100]\ttrain's rmse: 0.204092\tvalid's rmse: 0.209026\n",
      "[2200]\ttrain's rmse: 0.203898\tvalid's rmse: 0.209005\n",
      "[2300]\ttrain's rmse: 0.203707\tvalid's rmse: 0.208992\n",
      "[2400]\ttrain's rmse: 0.203514\tvalid's rmse: 0.208983\n",
      "[2500]\ttrain's rmse: 0.20333\tvalid's rmse: 0.208977\n",
      "[2600]\ttrain's rmse: 0.203148\tvalid's rmse: 0.208968\n",
      "[2700]\ttrain's rmse: 0.202967\tvalid's rmse: 0.208954\n",
      "[2800]\ttrain's rmse: 0.202782\tvalid's rmse: 0.208946\n",
      "[2900]\ttrain's rmse: 0.202587\tvalid's rmse: 0.208941\n",
      "[3000]\ttrain's rmse: 0.202406\tvalid's rmse: 0.208937\n",
      "[3100]\ttrain's rmse: 0.202227\tvalid's rmse: 0.208933\n",
      "[3200]\ttrain's rmse: 0.202055\tvalid's rmse: 0.208931\n",
      "[3300]\ttrain's rmse: 0.201874\tvalid's rmse: 0.20892\n",
      "[3400]\ttrain's rmse: 0.201691\tvalid's rmse: 0.20892\n",
      "Early stopping, best iteration is:\n",
      "[3311]\ttrain's rmse: 0.201856\tvalid's rmse: 0.208917\n",
      "Fold 2 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.211437\tvalid's rmse: 0.211079\n",
      "[200]\ttrain's rmse: 0.209353\tvalid's rmse: 0.209244\n",
      "[300]\ttrain's rmse: 0.208785\tvalid's rmse: 0.208905\n",
      "[400]\ttrain's rmse: 0.208382\tvalid's rmse: 0.208706\n",
      "[500]\ttrain's rmse: 0.208019\tvalid's rmse: 0.208551\n",
      "[600]\ttrain's rmse: 0.207714\tvalid's rmse: 0.208453\n",
      "[700]\ttrain's rmse: 0.207422\tvalid's rmse: 0.208378\n",
      "[800]\ttrain's rmse: 0.207152\tvalid's rmse: 0.208317\n",
      "[900]\ttrain's rmse: 0.206901\tvalid's rmse: 0.208278\n",
      "[1000]\ttrain's rmse: 0.206664\tvalid's rmse: 0.208245\n",
      "[1100]\ttrain's rmse: 0.206435\tvalid's rmse: 0.208216\n",
      "[1200]\ttrain's rmse: 0.206205\tvalid's rmse: 0.208182\n",
      "[1300]\ttrain's rmse: 0.205974\tvalid's rmse: 0.208144\n",
      "[1400]\ttrain's rmse: 0.205756\tvalid's rmse: 0.20813\n",
      "[1500]\ttrain's rmse: 0.205551\tvalid's rmse: 0.208105\n",
      "[1600]\ttrain's rmse: 0.205344\tvalid's rmse: 0.208087\n",
      "[1700]\ttrain's rmse: 0.205137\tvalid's rmse: 0.208071\n",
      "[1800]\ttrain's rmse: 0.204935\tvalid's rmse: 0.208056\n",
      "[1900]\ttrain's rmse: 0.20473\tvalid's rmse: 0.208032\n",
      "[2000]\ttrain's rmse: 0.204518\tvalid's rmse: 0.208013\n",
      "[2100]\ttrain's rmse: 0.20432\tvalid's rmse: 0.208003\n",
      "[2200]\ttrain's rmse: 0.204121\tvalid's rmse: 0.207992\n",
      "[2300]\ttrain's rmse: 0.203918\tvalid's rmse: 0.207983\n",
      "[2400]\ttrain's rmse: 0.203726\tvalid's rmse: 0.207975\n",
      "[2500]\ttrain's rmse: 0.203542\tvalid's rmse: 0.207965\n",
      "[2600]\ttrain's rmse: 0.203352\tvalid's rmse: 0.207956\n",
      "[2700]\ttrain's rmse: 0.203158\tvalid's rmse: 0.20795\n",
      "[2800]\ttrain's rmse: 0.202972\tvalid's rmse: 0.207945\n",
      "[2900]\ttrain's rmse: 0.202777\tvalid's rmse: 0.207944\n",
      "[3000]\ttrain's rmse: 0.202609\tvalid's rmse: 0.207938\n",
      "[3100]\ttrain's rmse: 0.20243\tvalid's rmse: 0.207934\n",
      "Early stopping, best iteration is:\n",
      "[3085]\ttrain's rmse: 0.202458\tvalid's rmse: 0.207932\n",
      "Fold 3 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 0.21138\tvalid's rmse: 0.211231\n",
      "[200]\ttrain's rmse: 0.209303\tvalid's rmse: 0.209448\n",
      "[300]\ttrain's rmse: 0.208722\tvalid's rmse: 0.209122\n",
      "[400]\ttrain's rmse: 0.208321\tvalid's rmse: 0.208935\n",
      "[500]\ttrain's rmse: 0.207959\tvalid's rmse: 0.208796\n",
      "[600]\ttrain's rmse: 0.20765\tvalid's rmse: 0.208712\n",
      "[700]\ttrain's rmse: 0.207356\tvalid's rmse: 0.208633\n",
      "[800]\ttrain's rmse: 0.20709\tvalid's rmse: 0.208569\n",
      "[900]\ttrain's rmse: 0.20684\tvalid's rmse: 0.208517\n",
      "[1000]\ttrain's rmse: 0.206593\tvalid's rmse: 0.208468\n",
      "[1100]\ttrain's rmse: 0.206354\tvalid's rmse: 0.20843\n",
      "[1200]\ttrain's rmse: 0.206133\tvalid's rmse: 0.208408\n",
      "[1300]\ttrain's rmse: 0.205902\tvalid's rmse: 0.208372\n",
      "[1400]\ttrain's rmse: 0.205672\tvalid's rmse: 0.208341\n",
      "[1500]\ttrain's rmse: 0.205458\tvalid's rmse: 0.20832\n",
      "[1600]\ttrain's rmse: 0.205247\tvalid's rmse: 0.208303\n",
      "[1700]\ttrain's rmse: 0.205043\tvalid's rmse: 0.208287\n",
      "[1800]\ttrain's rmse: 0.204835\tvalid's rmse: 0.208273\n",
      "[1900]\ttrain's rmse: 0.204634\tvalid's rmse: 0.208252\n",
      "[2000]\ttrain's rmse: 0.204431\tvalid's rmse: 0.208237\n",
      "[2100]\ttrain's rmse: 0.204236\tvalid's rmse: 0.208227\n",
      "[2200]\ttrain's rmse: 0.204034\tvalid's rmse: 0.208213\n",
      "[2300]\ttrain's rmse: 0.20384\tvalid's rmse: 0.208205\n",
      "[2400]\ttrain's rmse: 0.20365\tvalid's rmse: 0.208195\n",
      "[2500]\ttrain's rmse: 0.203457\tvalid's rmse: 0.208189\n",
      "[2600]\ttrain's rmse: 0.203265\tvalid's rmse: 0.208182\n",
      "[2700]\ttrain's rmse: 0.203082\tvalid's rmse: 0.208177\n",
      "[2800]\ttrain's rmse: 0.202897\tvalid's rmse: 0.208172\n",
      "[2900]\ttrain's rmse: 0.202717\tvalid's rmse: 0.208169\n",
      "[3000]\ttrain's rmse: 0.202531\tvalid's rmse: 0.208162\n",
      "[3100]\ttrain's rmse: 0.20235\tvalid's rmse: 0.208158\n",
      "[3200]\ttrain's rmse: 0.202171\tvalid's rmse: 0.208154\n",
      "Early stopping, best iteration is:\n",
      "[3195]\ttrain's rmse: 0.20218\tvalid's rmse: 0.208153\n",
      "Fold 4 completed.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 0.2112\tvalid's rmse: 0.211908\n",
      "[200]\ttrain's rmse: 0.209121\tvalid's rmse: 0.210153\n",
      "[300]\ttrain's rmse: 0.208554\tvalid's rmse: 0.209833\n",
      "[400]\ttrain's rmse: 0.208153\tvalid's rmse: 0.209655\n",
      "[500]\ttrain's rmse: 0.207797\tvalid's rmse: 0.209511\n",
      "[600]\ttrain's rmse: 0.207481\tvalid's rmse: 0.209413\n",
      "[700]\ttrain's rmse: 0.207186\tvalid's rmse: 0.209346\n",
      "[800]\ttrain's rmse: 0.206917\tvalid's rmse: 0.209293\n",
      "[900]\ttrain's rmse: 0.206658\tvalid's rmse: 0.209249\n",
      "[1000]\ttrain's rmse: 0.206421\tvalid's rmse: 0.209209\n",
      "[1100]\ttrain's rmse: 0.206189\tvalid's rmse: 0.209168\n",
      "[1200]\ttrain's rmse: 0.205971\tvalid's rmse: 0.209145\n",
      "[1300]\ttrain's rmse: 0.205752\tvalid's rmse: 0.209121\n",
      "[1400]\ttrain's rmse: 0.20554\tvalid's rmse: 0.209102\n",
      "[1500]\ttrain's rmse: 0.205317\tvalid's rmse: 0.209064\n",
      "[1600]\ttrain's rmse: 0.205109\tvalid's rmse: 0.20904\n",
      "[1700]\ttrain's rmse: 0.204896\tvalid's rmse: 0.209014\n",
      "[1800]\ttrain's rmse: 0.204699\tvalid's rmse: 0.208996\n",
      "[1900]\ttrain's rmse: 0.204508\tvalid's rmse: 0.20899\n",
      "[2000]\ttrain's rmse: 0.204292\tvalid's rmse: 0.20897\n",
      "[2100]\ttrain's rmse: 0.204103\tvalid's rmse: 0.208958\n",
      "[2200]\ttrain's rmse: 0.203918\tvalid's rmse: 0.208956\n",
      "[2300]\ttrain's rmse: 0.20373\tvalid's rmse: 0.208948\n",
      "[2400]\ttrain's rmse: 0.203537\tvalid's rmse: 0.208939\n",
      "[2500]\ttrain's rmse: 0.203351\tvalid's rmse: 0.208934\n",
      "[2600]\ttrain's rmse: 0.203174\tvalid's rmse: 0.208926\n",
      "[2700]\ttrain's rmse: 0.202992\tvalid's rmse: 0.20892\n",
      "[2800]\ttrain's rmse: 0.202801\tvalid's rmse: 0.208911\n",
      "[2900]\ttrain's rmse: 0.202617\tvalid's rmse: 0.208902\n",
      "[3000]\ttrain's rmse: 0.202436\tvalid's rmse: 0.208902\n",
      "[3100]\ttrain's rmse: 0.202258\tvalid's rmse: 0.208895\n",
      "[3200]\ttrain's rmse: 0.202094\tvalid's rmse: 0.208895\n",
      "[3300]\ttrain's rmse: 0.201921\tvalid's rmse: 0.20889\n",
      "Early stopping, best iteration is:\n",
      "[3262]\ttrain's rmse: 0.201988\tvalid's rmse: 0.208888\n",
      "Fold 5 completed.\n",
      "Training & bagging:  ridge\n",
      "Training seed = 9910019\n",
      "Fold 1 completed.\n",
      "Fold 2 completed.\n",
      "Fold 3 completed.\n",
      "Fold 4 completed.\n",
      "Fold 5 completed.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for k,v in config.items():\n",
    "    print('Training & bagging: ', k)\n",
    "    res = {\n",
    "        'val_oof': np.zeros((len(train_y),)),\n",
    "        'test_oof': np.zeros((test.shape[0],))\n",
    "    }\n",
    "    \n",
    "    for seed in seeds:\n",
    "        print('Training seed =', seed)\n",
    "        if 'random_state' in v['param']:\n",
    "            v['param']['random_state'] = seed\n",
    "            \n",
    "        oof_val_pred, oof_test_pred, _ = get_oof_predictions(train, train_y, test, v['ml'], \n",
    "                                                          v['param'], seed=SEED, fit_params=v['fit_param'], \n",
    "                                                          use_eval_set= v['fit_param'] is not None)\n",
    "        \n",
    "        res['val_oof'] += oof_val_pred\n",
    "        res['test_oof'] += oof_test_pred\n",
    "    \n",
    "    res['val_oof'] /= len(seeds)\n",
    "    res['test_oof'] /= len(seeds)\n",
    "    \n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_oof': array([ 0.44134881,  0.13818581,  0.18065408, ...,  0.05846316,\n",
       "          0.46645003,  0.11934828]),\n",
       "  'val_oof': array([ 0.04269062,  0.02786759,  0.04589495, ...,  0.32469264,\n",
       "          0.44411177,  0.33554076])},\n",
       " {'test_oof': array([ 0.45260529,  0.14440085,  0.18600401, ...,  0.05801202,\n",
       "          0.45661804,  0.11927631]),\n",
       "  'val_oof': array([ 0.0431904 ,  0.03153727,  0.04552802, ...,  0.27872548,\n",
       "          0.51625873,  0.39307008])},\n",
       " {'test_oof': array([ 0.41481393,  0.17201893,  0.19537803, ...,  0.05836198,\n",
       "          0.5179934 ,  0.13196116]),\n",
       "  'val_oof': array([ 0.04396407,  0.04514281,  0.05289709, ...,  0.26401559,\n",
       "          0.27708091,  0.24400375])}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results, open('411_meta_oof_result', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results[1:], open('411_meta_oof_result_ver2', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.208262, depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1} train loss: 0.208249, valid loss:0.208026, loss_diff:-0.000223\n",
      "{'alpha': 1} train loss: 0.208074, valid loss:0.208732, loss_diff:0.000659\n",
      "{'alpha': 1} train loss: 0.208334, valid loss:0.207688, loss_diff:-0.000646\n",
      "{'alpha': 1} train loss: 0.208270, valid loss:0.207946, loss_diff:-0.000323\n",
      "{'alpha': 1} train loss: 0.208095, valid loss:0.208643, loss_diff:0.000548\n",
      "=================>{'alpha': 1} loss:0.208207\n",
      "{'alpha': 2} train loss: 0.208249, valid loss:0.208026, loss_diff:-0.000223\n",
      "{'alpha': 2} train loss: 0.208074, valid loss:0.208732, loss_diff:0.000658\n",
      "{'alpha': 2} train loss: 0.208334, valid loss:0.207688, loss_diff:-0.000646\n",
      "{'alpha': 2} train loss: 0.208270, valid loss:0.207946, loss_diff:-0.000324\n",
      "{'alpha': 2} train loss: 0.208095, valid loss:0.208643, loss_diff:0.000548\n",
      "=================>{'alpha': 2} loss:0.208207\n",
      "{'alpha': 4} train loss: 0.208249, valid loss:0.208027, loss_diff:-0.000223\n",
      "{'alpha': 4} train loss: 0.208074, valid loss:0.208731, loss_diff:0.000658\n",
      "{'alpha': 4} train loss: 0.208334, valid loss:0.207688, loss_diff:-0.000645\n",
      "{'alpha': 4} train loss: 0.208270, valid loss:0.207946, loss_diff:-0.000324\n",
      "{'alpha': 4} train loss: 0.208095, valid loss:0.208643, loss_diff:0.000548\n",
      "=================>{'alpha': 4} loss:0.208207\n",
      "{'alpha': 8} train loss: 0.208249, valid loss:0.208027, loss_diff:-0.000223\n",
      "{'alpha': 8} train loss: 0.208074, valid loss:0.208731, loss_diff:0.000657\n",
      "{'alpha': 8} train loss: 0.208334, valid loss:0.207689, loss_diff:-0.000644\n",
      "{'alpha': 8} train loss: 0.208270, valid loss:0.207946, loss_diff:-0.000324\n",
      "{'alpha': 8} train loss: 0.208096, valid loss:0.208644, loss_diff:0.000548\n",
      "=================>{'alpha': 8} loss:0.208207\n",
      "Best params: {'alpha': 4} \tbest loss: 0.208207151629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 4}</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 8}</td>\n",
       "      <td>0.208207</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          param  val_loss_mean  val_loss_std\n",
       "0  {'alpha': 1}       0.208207      0.000409\n",
       "1  {'alpha': 2}       0.208207      0.000409\n",
       "2  {'alpha': 4}       0.208207      0.000409\n",
       "3  {'alpha': 8}       0.208207      0.000408"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = pd.DataFrame()\n",
    "new_test = pd.DataFrame()\n",
    "\n",
    "new_train['f1'] = results[0]['val_oof']\n",
    "new_train['f2'] = results[1]['val_oof']\n",
    "new_train['f3'] = results[2]['val_oof']\n",
    "\n",
    "new_test['f1'] = results[0]['test_oof']\n",
    "new_test['f2'] = results[1]['test_oof']\n",
    "new_test['f3'] = results[2]['test_oof']\n",
    "\n",
    "ml = model_loader(model_type='rg')\n",
    "default_params = {\n",
    "    'alpha': 1.0, \n",
    "    'fit_intercept': True, \n",
    "    'normalize': False, \n",
    "    'copy_X': True, \n",
    "    'max_iter': None, \n",
    "    'tol': 0.001, \n",
    "    'solver':'auto', \n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "fit_param = None\n",
    "\n",
    "try_params = {\n",
    "    'alpha':[1,2,4,8]\n",
    "}\n",
    "\n",
    "fit_params(new_train, train_y, ml, default_params, try_params, fit_params=fit_param, seed=SEED, use_eval_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.987907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.998125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>0.987907</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3\n",
       "f1  1.000000  0.998125  0.987907\n",
       "f2  0.998125  1.000000  0.988439\n",
       "f3  0.987907  0.988439  1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[['f1', 'f2', 'f3']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed.\n",
      "Fold 2 completed.\n",
      "Fold 3 completed.\n",
      "Fold 4 completed.\n",
      "Fold 5 completed.\n"
     ]
    }
   ],
   "source": [
    "default_params = {\n",
    "    'alpha': 1.0, \n",
    "    'fit_intercept': True, \n",
    "    'normalize': False, \n",
    "    'copy_X': True, \n",
    "    'max_iter': None, \n",
    "    'tol': 0.001, \n",
    "    'solver':'auto', \n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "oof_val_pred, oof_test_pred, _ = get_oof_predictions( new_train, train_y, new_test, ml, \n",
    "                                                      default_params, seed=SEED, fit_params=fit_param, \n",
    "                                                      use_eval_set= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\", usecols=['item_id'])\n",
    "pd.DataFrame(np.clip(oof_test_pred,0,1), \n",
    "             index=test_df.item_id,\n",
    "             columns=['deal_probability']).to_csv('stack_bagging_blending_411_complex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.clip(oof_val_pred,0,1), \n",
    "             columns=['deal_probability']).to_csv('stack_bagging_blending_411_complex_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                       | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score updated: 0.209618  coefficient=> 0.01, 0.01, 0.98\n",
      "best score updated: 0.209601  coefficient=> 0.01, 0.02, 0.97\n",
      "best score updated: 0.209584  coefficient=> 0.01, 0.03, 0.96\n",
      "best score updated: 0.209568  coefficient=> 0.01, 0.04, 0.95\n",
      "best score updated: 0.209552  coefficient=> 0.01, 0.05, 0.94\n",
      "best score updated: 0.209536  coefficient=> 0.01, 0.060000000000000005, 0.9299999999999999\n",
      "best score updated: 0.209520  coefficient=> 0.01, 0.06999999999999999, 0.92\n",
      "best score updated: 0.209504  coefficient=> 0.01, 0.08, 0.91\n",
      "best score updated: 0.209489  coefficient=> 0.01, 0.09, 0.9\n",
      "best score updated: 0.209473  coefficient=> 0.01, 0.09999999999999999, 0.89\n",
      "best score updated: 0.209458  coefficient=> 0.01, 0.11, 0.88\n",
      "best score updated: 0.209444  coefficient=> 0.01, 0.12, 0.87\n",
      "best score updated: 0.209429  coefficient=> 0.01, 0.13, 0.86\n",
      "best score updated: 0.209414  coefficient=> 0.01, 0.14, 0.85\n",
      "best score updated: 0.209400  coefficient=> 0.01, 0.15000000000000002, 0.84\n",
      "best score updated: 0.209386  coefficient=> 0.01, 0.16, 0.83\n",
      "best score updated: 0.209372  coefficient=> 0.01, 0.17, 0.82\n",
      "best score updated: 0.209358  coefficient=> 0.01, 0.18000000000000002, 0.8099999999999999\n",
      "best score updated: 0.209345  coefficient=> 0.01, 0.19, 0.8\n",
      "best score updated: 0.209332  coefficient=> 0.01, 0.2, 0.79\n",
      "best score updated: 0.209319  coefficient=> 0.01, 0.21000000000000002, 0.78\n",
      "best score updated: 0.209306  coefficient=> 0.01, 0.22, 0.77\n",
      "best score updated: 0.209293  coefficient=> 0.01, 0.23, 0.76\n",
      "best score updated: 0.209281  coefficient=> 0.01, 0.24000000000000002, 0.75\n",
      "best score updated: 0.209268  coefficient=> 0.01, 0.25, 0.74\n",
      "best score updated: 0.209256  coefficient=> 0.01, 0.26, 0.73\n",
      "best score updated: 0.209244  coefficient=> 0.01, 0.27, 0.72\n",
      "best score updated: 0.209233  coefficient=> 0.01, 0.28, 0.71\n",
      "best score updated: 0.209221  coefficient=> 0.01, 0.29000000000000004, 0.7\n",
      "best score updated: 0.209210  coefficient=> 0.01, 0.3, 0.69\n",
      "best score updated: 0.209199  coefficient=> 0.01, 0.31, 0.6799999999999999\n",
      "best score updated: 0.209188  coefficient=> 0.01, 0.32, 0.6699999999999999\n",
      "best score updated: 0.209178  coefficient=> 0.01, 0.33, 0.6599999999999999\n",
      "best score updated: 0.209167  coefficient=> 0.01, 0.34, 0.6499999999999999\n",
      "best score updated: 0.209157  coefficient=> 0.01, 0.35000000000000003, 0.6399999999999999\n",
      "best score updated: 0.209147  coefficient=> 0.01, 0.36000000000000004, 0.6299999999999999\n",
      "best score updated: 0.209137  coefficient=> 0.01, 0.37, 0.62\n",
      "best score updated: 0.209128  coefficient=> 0.01, 0.38, 0.61\n",
      "best score updated: 0.209118  coefficient=> 0.01, 0.39, 0.6\n",
      "best score updated: 0.209109  coefficient=> 0.01, 0.4, 0.59\n",
      "best score updated: 0.209100  coefficient=> 0.01, 0.41000000000000003, 0.58\n",
      "best score updated: 0.209092  coefficient=> 0.01, 0.42000000000000004, 0.57\n",
      "best score updated: 0.209083  coefficient=> 0.01, 0.43, 0.56\n",
      "best score updated: 0.209075  coefficient=> 0.01, 0.44, 0.55\n",
      "best score updated: 0.209067  coefficient=> 0.01, 0.45, 0.54\n",
      "best score updated: 0.209059  coefficient=> 0.01, 0.46, 0.53\n",
      "best score updated: 0.209051  coefficient=> 0.01, 0.47000000000000003, 0.52\n",
      "best score updated: 0.209044  coefficient=> 0.01, 0.48000000000000004, 0.51\n",
      "best score updated: 0.209037  coefficient=> 0.01, 0.49, 0.5\n",
      "best score updated: 0.209030  coefficient=> 0.01, 0.5, 0.49\n",
      "best score updated: 0.209023  coefficient=> 0.01, 0.51, 0.48\n",
      "best score updated: 0.209016  coefficient=> 0.01, 0.52, 0.47\n",
      "best score updated: 0.209010  coefficient=> 0.01, 0.53, 0.45999999999999996\n",
      "best score updated: 0.209004  coefficient=> 0.01, 0.54, 0.44999999999999996\n",
      "best score updated: 0.208998  coefficient=> 0.01, 0.55, 0.43999999999999995\n",
      "best score updated: 0.208992  coefficient=> 0.01, 0.56, 0.42999999999999994\n",
      "best score updated: 0.208987  coefficient=> 0.01, 0.5700000000000001, 0.41999999999999993\n",
      "best score updated: 0.208982  coefficient=> 0.01, 0.5800000000000001, 0.4099999999999999\n",
      "best score updated: 0.208977  coefficient=> 0.01, 0.59, 0.4\n",
      "best score updated: 0.208972  coefficient=> 0.01, 0.6, 0.39\n",
      "best score updated: 0.208967  coefficient=> 0.01, 0.61, 0.38\n",
      "best score updated: 0.208963  coefficient=> 0.01, 0.62, 0.37\n",
      "best score updated: 0.208959  coefficient=> 0.01, 0.63, 0.36\n",
      "best score updated: 0.208955  coefficient=> 0.01, 0.64, 0.35\n",
      "best score updated: 0.208951  coefficient=> 0.01, 0.65, 0.33999999999999997\n",
      "best score updated: 0.208948  coefficient=> 0.01, 0.66, 0.32999999999999996\n",
      "best score updated: 0.208944  coefficient=> 0.01, 0.67, 0.31999999999999995\n",
      "best score updated: 0.208941  coefficient=> 0.01, 0.68, 0.30999999999999994\n",
      "best score updated: 0.208939  coefficient=> 0.01, 0.6900000000000001, 0.29999999999999993\n",
      "best score updated: 0.208936  coefficient=> 0.01, 0.7000000000000001, 0.2899999999999999\n",
      "best score updated: 0.208934  coefficient=> 0.01, 0.7100000000000001, 0.2799999999999999\n",
      "best score updated: 0.208932  coefficient=> 0.01, 0.72, 0.27\n",
      "best score updated: 0.208930  coefficient=> 0.01, 0.73, 0.26\n",
      "best score updated: 0.208928  coefficient=> 0.01, 0.74, 0.25\n",
      "best score updated: 0.208927  coefficient=> 0.01, 0.75, 0.24\n",
      "best score updated: 0.208925  coefficient=> 0.01, 0.76, 0.22999999999999998\n",
      "best score updated: 0.208924  coefficient=> 0.01, 0.77, 0.21999999999999997\n",
      "best score updated: 0.208924  coefficient=> 0.01, 0.78, 0.20999999999999996\n",
      "best score updated: 0.208923  coefficient=> 0.01, 0.79, 0.19999999999999996\n",
      "best score updated: 0.208923  coefficient=> 0.01, 0.8, 0.18999999999999995\n",
      "best score updated: 0.208923  coefficient=> 0.01, 0.81, 0.17999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [03:51<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "best_blend_test = None\n",
    "best_score = None\n",
    "min_w = 0.01\n",
    "for a in tqdm(np.arange(min_w, 1+min_w-min_w*2, min_w)):\n",
    "    for b in np.arange(min_w, 1-a+min_w-min_w*1, min_w):\n",
    "        c = 1-a-b\n",
    "        combined_res = a*results[0]['val_oof'] + \\\n",
    "                       b*results[1]['val_oof'] + \\\n",
    "                       c*results[2]['val_oof']\n",
    "\n",
    "        score = clip_rmse(train_y, combined_res)\n",
    "        if best_score is None or score < best_score:\n",
    "            best_score = score\n",
    "            print('best score updated: {:.6f}'.format(best_score), ' coefficient=> {}, {}, {}'.format(a, b, c))\n",
    "            best_blend_test =  a*results[0]['test_oof'] + \\\n",
    "                               b*results[1]['test_oof'] + \\\n",
    "                               c*results[2]['test_oof']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_blend_test = None\n",
    "best_score = None\n",
    "min_w = 0.01\n",
    "for a in np.arange(min_w, 1+min_w-min_w*4, min_w):\n",
    "    for b in np.arange(min_w, 1-a+min_w-min_w*3, min_w):\n",
    "        for c in np.arange(min_w, 1-a-b+min_w-min_w*2, min_w):\n",
    "            for d in np.arange(min_w, 1-a-b-c+min_w-min_w*1, min_w):\n",
    "                e = 1-a-b-c-d\n",
    "                combined_res = a*results[0]['val_oof'] + \\\n",
    "                               b*results[1]['val_oof'] + \\\n",
    "                               c*results[2]['val_oof'] + \\\n",
    "                               d*results[3]['val_oof'] + \\ \n",
    "                               e*results[4]['val_oof']\n",
    "                \n",
    "                score = clip_rmse(train_y, combined_res)\n",
    "                if best_score is None or score < best_score:\n",
    "                    best_score = score\n",
    "                    print('best score updated:', best_score)\n",
    "                    best_blend_test =  a*results[0]['test_oof'] + \\\n",
    "                                       b*results[1]['test_oof'] + \\\n",
    "                                       c*results[2]['test_oof'] + \\\n",
    "                                       d*results[3]['test_oof'] + \\ \n",
    "                                       e*results[4]['test_oof']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\", usecols=['item_id'])\n",
    "pd.DataFrame(np.clip(best_blend_test,0,1), \n",
    "             index=test_df.item_id,\n",
    "             columns=['deal_probability']).to_csv('stack_bagging_blend_no_xgb_meta.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
